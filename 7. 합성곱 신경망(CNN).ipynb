{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7.4 합성곱/풀링 계층 구현하기\n",
    "# 7.4.1 4차원 배열"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "x = np.random.rand(10, 1, 28, 28)  # 무작위 데이터 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 1, 28, 28)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 28, 28)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 28, 28)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[1].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.4.3 합성곱 계층 구현하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def im2col(input_data, filter_h, filter_w, stride=1, pad=0):\n",
    "    \"\"\"다수의 이미지를 입력받아 2차원 배열로 변환한다(평탄화).\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    input_data : 4차원 배열 형태의 입력 데이터(이미지 수, 채널 수, 높이, 너비)\n",
    "    filter_h : 필터의 높이\n",
    "    filter_w : 필터의 너비\n",
    "    stride : 스트라이드\n",
    "    pad : 패딩\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    col : 2차원 배열\n",
    "    \"\"\"\n",
    "    N, C, H, W = input_data.shape\n",
    "    out_h = (H + 2*pad - filter_h)//stride + 1\n",
    "    out_w = (W + 2*pad - filter_w)//stride + 1\n",
    "\n",
    "    img = np.pad(input_data, [(0,0), (0,0), (pad, pad), (pad, pad)], 'constant')\n",
    "    col = np.zeros((N, C, filter_h, filter_w, out_h, out_w))\n",
    "\n",
    "    for y in range(filter_h):\n",
    "        y_max = y + stride*out_h\n",
    "        for x in range(filter_w):\n",
    "            x_max = x + stride*out_w\n",
    "            col[:, :, y, x, :, :] = img[:, :, y:y_max:stride, x:x_max:stride]\n",
    "\n",
    "    col = col.transpose(0, 4, 5, 1, 2, 3).reshape(N*out_h*out_w, -1)\n",
    "    return col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9, 75)\n"
     ]
    }
   ],
   "source": [
    "import sys, os\n",
    "sys.path.append(os.pardir)\n",
    "from common.util import im2col\n",
    "\n",
    "x1 = np.random.rand(1, 3, 7, 7)    # (데이터 수, 채널 수, 높이, 너비)\n",
    "col1 = im2col(x1, 5, 5, stride=1, pad=0)\n",
    "print(col1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(90, 75)\n"
     ]
    }
   ],
   "source": [
    "x2 = np.random.rand(10, 3, 7, 7)    # 데이터 10개\n",
    "col2 = im2col(x2, 5, 5, stride=1, pad=0)\n",
    "print(col2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Consulution:\n",
    "    def __init__(self, W, b, stride=1, pad=0):\n",
    "        self.W = W\n",
    "        self.b = b\n",
    "        self.stride = stride\n",
    "        sel.pad = pad\n",
    "        \n",
    "    def forward(self, x):\n",
    "        FN, C, FH, FW = self.W.shape\n",
    "        N, C, H, W = x.shape\n",
    "        out_h = int(1 + (H + 2*self.pad - FH) / self.stride)\n",
    "        out_w = int(1 + (W + 2*self.pad - FW) / self.stride)\n",
    "        \n",
    "        col = im2col(x, FH, FW, self.stride, self.pad)\n",
    "        col_W = self.W.reshape(FN, -1).T   # 필터 전개\n",
    "        out = np.dot(col, col_W) + self.b\n",
    "        \n",
    "        out = out.reshape(N, out_h, out_w, -1).transpose(0, 3, 1, 2)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Poolint:\n",
    "    def __init__(self, pool_h, pool_w, stride=1, pad=0):\n",
    "        self.pool_h = pool_h\n",
    "        self.pool_w = pool_w\n",
    "        self.stride = stride\n",
    "        sel.pad = pad\n",
    "        \n",
    "    def forward(self, x):\n",
    "        N, C, H, W = x.shape\n",
    "        out_h = int(1 + (H - self.pool_h) / self.stride)\n",
    "        out_w = int(1 + (W - self.pool_w) / self.stride)\n",
    "        \n",
    "        # 전개 (1)\n",
    "        col = im2col(x, self.pool_h, self.pool_w, self.stride, self.pad)\n",
    "        col = col.reshape(-1, self.pool_h*self.pool_w)\n",
    "        \n",
    "        # 최댓값 (2)\n",
    "        out = np.max(col, axis=1)\n",
    "        \n",
    "        # 성형 (3)\n",
    "        out = out.reshpe(N, out_h, out_w, C).transpose(0, 3, 1, 2)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.4.4 풀링 계층 구현하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Pooling:\n",
    "    def __init__(self, pool_h, pool_w, stride=1, pad=0):\n",
    "        self.pool_h = pool_h\n",
    "        self.pool_w = pool_w\n",
    "        self.stride = stride\n",
    "        self.pad = pad\n",
    "        \n",
    "    def forward(self, x):\n",
    "        N, C, H, W = x.shape\n",
    "        out_h = int(1 + (H - self.pool_h) / self.stride)\n",
    "        out_w = int(1 + (W - self.pool_w) / self.stride)\n",
    "        \n",
    "        # 전개 (1)\n",
    "        col = im2col(x, self.pool_h, self.pool_w, self.stride, self.pad)\n",
    "        col = col.reshape(-1, self.pool_h*self.pool_w)\n",
    "        \n",
    "        # 최댓갑 (2)\n",
    "        out = np.max(col, axis=1)\n",
    "        \n",
    "        # 성형 (3)\n",
    "        out = out.shape(N, out_h, out_w, C).transpose(0, 3, 1, 2)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7.5 CNN 구현하기\n",
    "- “Convolution-ReLU-Pooling-Affine-ReLU-Affine-Softmax” 순으로 흐르는 단순한 합성곱 신경망(CNN)입니다.\n",
    "- SimpleConvNet으로 MNIST 데이터셋을 학습합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coding: utf-8\n",
    "import sys, os\n",
    "sys.path.append(os.pardir)  # 부모 디렉터리의 파일을 가져올 수 있도록 설정\n",
    "import pickle\n",
    "import numpy as np\n",
    "from collections import OrderedDict\n",
    "from common.layers import *\n",
    "from common.gradient import numerical_gradient\n",
    "\n",
    "\n",
    "class SimpleConvNet:\n",
    "    \"\"\"단순한 합성곱 신경망\n",
    "    \n",
    "    conv - relu - pool - affine - relu - affine - softmax\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    input_size : 입력 크기（MNIST의 경우엔 784）\n",
    "    hidden_size_list : 각 은닉층의 뉴런 수를 담은 리스트（e.g. [100, 100, 100]）\n",
    "    output_size : 출력 크기（MNIST의 경우엔 10）\n",
    "    activation : 활성화 함수 - 'relu' 혹은 'sigmoid'\n",
    "    weight_init_std : 가중치의 표준편차 지정（e.g. 0.01）\n",
    "        'relu'나 'he'로 지정하면 'He 초깃값'으로 설정\n",
    "        'sigmoid'나 'xavier'로 지정하면 'Xavier 초깃값'으로 설정\n",
    "    \"\"\"\n",
    "    def __init__(self, input_dim=(1, 28, 28), \n",
    "                 conv_param={'filter_num':30, 'filter_size':5, 'pad':0, 'stride':1},\n",
    "                 hidden_size=100, output_size=10, weight_init_std=0.01):\n",
    "        filter_num = conv_param['filter_num']\n",
    "        filter_size = conv_param['filter_size']\n",
    "        filter_pad = conv_param['pad']\n",
    "        filter_stride = conv_param['stride']\n",
    "        input_size = input_dim[1]\n",
    "        conv_output_size = (input_size - filter_size + 2*filter_pad) / filter_stride + 1\n",
    "        pool_output_size = int(filter_num * (conv_output_size/2) * (conv_output_size/2))\n",
    "\n",
    "        # 가중치 초기화\n",
    "        self.params = {}\n",
    "        self.params['W1'] = weight_init_std * \\\n",
    "                            np.random.randn(filter_num, input_dim[0], filter_size, filter_size)\n",
    "        self.params['b1'] = np.zeros(filter_num)\n",
    "        self.params['W2'] = weight_init_std * \\\n",
    "                            np.random.randn(pool_output_size, hidden_size)\n",
    "        self.params['b2'] = np.zeros(hidden_size)\n",
    "        self.params['W3'] = weight_init_std * \\\n",
    "                            np.random.randn(hidden_size, output_size)\n",
    "        self.params['b3'] = np.zeros(output_size)\n",
    "\n",
    "        # 계층 생성\n",
    "        self.layers = OrderedDict()\n",
    "        self.layers['Conv1'] = Convolution(self.params['W1'], self.params['b1'],\n",
    "                                           conv_param['stride'], conv_param['pad'])\n",
    "        self.layers['Relu1'] = Relu()\n",
    "        self.layers['Pool1'] = Pooling(pool_h=2, pool_w=2, stride=2)\n",
    "        self.layers['Affine1'] = Affine(self.params['W2'], self.params['b2'])\n",
    "        self.layers['Relu2'] = Relu()\n",
    "        self.layers['Affine2'] = Affine(self.params['W3'], self.params['b3'])\n",
    "\n",
    "        self.last_layer = SoftmaxWithLoss()\n",
    "\n",
    "    def predict(self, x):\n",
    "        for layer in self.layers.values():\n",
    "            x = layer.forward(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "    def loss(self, x, t):\n",
    "        \"\"\"손실 함수를 구한다.\n",
    "        Parameters\n",
    "        ----------\n",
    "        x : 입력 데이터\n",
    "        t : 정답 레이블\n",
    "        \"\"\"\n",
    "        y = self.predict(x)\n",
    "        return self.last_layer.forward(y, t)\n",
    "\n",
    "    def accuracy(self, x, t, batch_size=100):\n",
    "        if t.ndim != 1 : t = np.argmax(t, axis=1)\n",
    "        \n",
    "        acc = 0.0\n",
    "        \n",
    "        for i in range(int(x.shape[0] / batch_size)):\n",
    "            tx = x[i*batch_size:(i+1)*batch_size]\n",
    "            tt = t[i*batch_size:(i+1)*batch_size]\n",
    "            y = self.predict(tx)\n",
    "            y = np.argmax(y, axis=1)\n",
    "            acc += np.sum(y == tt) \n",
    "        \n",
    "        return acc / x.shape[0]\n",
    "\n",
    "    def numerical_gradient(self, x, t):\n",
    "        \"\"\"기울기를 구한다（수치미분）.\n",
    "        Parameters\n",
    "        ----------\n",
    "        x : 입력 데이터\n",
    "        t : 정답 레이블\n",
    "        Returns\n",
    "        -------\n",
    "        각 층의 기울기를 담은 사전(dictionary) 변수\n",
    "            grads['W1']、grads['W2']、... 각 층의 가중치\n",
    "            grads['b1']、grads['b2']、... 각 층의 편향\n",
    "        \"\"\"\n",
    "        loss_w = lambda w: self.loss(x, t)\n",
    "\n",
    "        grads = {}\n",
    "        for idx in (1, 2, 3):\n",
    "            grads['W' + str(idx)] = numerical_gradient(loss_w, self.params['W' + str(idx)])\n",
    "            grads['b' + str(idx)] = numerical_gradient(loss_w, self.params['b' + str(idx)])\n",
    "\n",
    "        return grads\n",
    "\n",
    "    def gradient(self, x, t):\n",
    "        \"\"\"기울기를 구한다(오차역전파법).\n",
    "        Parameters\n",
    "        ----------\n",
    "        x : 입력 데이터\n",
    "        t : 정답 레이블\n",
    "        Returns\n",
    "        -------\n",
    "        각 층의 기울기를 담은 사전(dictionary) 변수\n",
    "            grads['W1']、grads['W2']、... 각 층의 가중치\n",
    "            grads['b1']、grads['b2']、... 각 층의 편향\n",
    "        \"\"\"\n",
    "        # forward\n",
    "        self.loss(x, t)\n",
    "\n",
    "        # backward\n",
    "        dout = 1\n",
    "        dout = self.last_layer.backward(dout)\n",
    "\n",
    "        layers = list(self.layers.values())\n",
    "        layers.reverse()\n",
    "        for layer in layers:\n",
    "            dout = layer.backward(dout)\n",
    "\n",
    "        # 결과 저장\n",
    "        grads = {}\n",
    "        grads['W1'], grads['b1'] = self.layers['Conv1'].dW, self.layers['Conv1'].db\n",
    "        grads['W2'], grads['b2'] = self.layers['Affine1'].dW, self.layers['Affine1'].db\n",
    "        grads['W3'], grads['b3'] = self.layers['Affine2'].dW, self.layers['Affine2'].db\n",
    "\n",
    "        return grads\n",
    "        \n",
    "    def save_params(self, file_name=\"params.pkl\"):\n",
    "        params = {}\n",
    "        for key, val in self.params.items():\n",
    "            params[key] = val\n",
    "        with open(file_name, 'wb') as f:\n",
    "            pickle.dump(params, f)\n",
    "\n",
    "    def load_params(self, file_name=\"params.pkl\"):\n",
    "        with open(file_name, 'rb') as f:\n",
    "            params = pickle.load(f)\n",
    "        for key, val in params.items():\n",
    "            self.params[key] = val\n",
    "\n",
    "        for i, key in enumerate(['Conv1', 'Affine1', 'Affine2']):\n",
    "            self.layers[key].W = self.params['W' + str(i+1)]\n",
    "            self.layers[key].b = self.params['b' + str(i+1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:2.2994582807281407\n",
      "=== epoch:1, train acc:0.242, test acc:0.238 ===\n",
      "train loss:2.2959218356808773\n",
      "train loss:2.289701937817784\n",
      "train loss:2.2782506888742162\n",
      "train loss:2.2737238057671703\n",
      "train loss:2.2585140285863994\n",
      "train loss:2.2376957782042353\n",
      "train loss:2.2217835319884816\n",
      "train loss:2.1993104681820244\n",
      "train loss:2.1726666874570797\n",
      "train loss:2.1371434382367562\n",
      "train loss:2.0880821846590325\n",
      "train loss:2.0324871435333396\n",
      "train loss:2.0078712730924426\n",
      "train loss:1.883394221985196\n",
      "train loss:1.8648245946732838\n",
      "train loss:1.7620063718384629\n",
      "train loss:1.6821863755253512\n",
      "train loss:1.6578533440412582\n",
      "train loss:1.5088511067668602\n",
      "train loss:1.4949602719209432\n",
      "train loss:1.4237215589196044\n",
      "train loss:1.3180568700390105\n",
      "train loss:1.2240356003102146\n",
      "train loss:1.1687577546963706\n",
      "train loss:1.389800537204415\n",
      "train loss:1.1195212763313849\n",
      "train loss:0.9502667369598342\n",
      "train loss:1.0269164559131514\n",
      "train loss:0.8923465439504671\n",
      "train loss:0.9079854113414825\n",
      "train loss:0.711170197541719\n",
      "train loss:0.598415790524507\n",
      "train loss:0.8107732263490626\n",
      "train loss:0.8132225567153494\n",
      "train loss:0.7374362814437011\n",
      "train loss:0.7053028535392815\n",
      "train loss:0.6652374295588852\n",
      "train loss:0.5866408847355341\n",
      "train loss:0.7456700615835105\n",
      "train loss:0.6096928829410597\n",
      "train loss:0.601733048150891\n",
      "train loss:0.8393672932399353\n",
      "train loss:0.5523581650811127\n",
      "train loss:0.6400730170250991\n",
      "train loss:0.6736127711317087\n",
      "train loss:0.4707710221034256\n",
      "train loss:0.5060657058693963\n",
      "train loss:0.8262129112828346\n",
      "train loss:0.6121830098672867\n",
      "train loss:0.6506855258191512\n",
      "train loss:0.5805308160764056\n",
      "train loss:0.515948143401546\n",
      "train loss:0.6299804357239942\n",
      "train loss:0.42099078077950614\n",
      "train loss:0.5219692635301605\n",
      "train loss:0.4009831203260237\n",
      "train loss:0.44233517350227153\n",
      "train loss:0.37596786695994205\n",
      "train loss:0.4466978750836935\n",
      "train loss:0.41328775437247023\n",
      "train loss:0.4659649484543603\n",
      "train loss:0.47078022668105995\n",
      "train loss:0.4855052217448071\n",
      "train loss:0.45667946984399577\n",
      "train loss:0.4527977832889676\n",
      "train loss:0.5228780780874276\n",
      "train loss:0.3524905187070372\n",
      "train loss:0.506892031551989\n",
      "train loss:0.6068584265567137\n",
      "train loss:0.3247732585441998\n",
      "train loss:0.3855467158187168\n",
      "train loss:0.23070915936560812\n",
      "train loss:0.44027608876363644\n",
      "train loss:0.5925848438950865\n",
      "train loss:0.3085933671038843\n",
      "train loss:0.4150291704861425\n",
      "train loss:0.30835872504272394\n",
      "train loss:0.4215525124560953\n",
      "train loss:0.32263435630217235\n",
      "train loss:0.3126777242648251\n",
      "train loss:0.5361807369012138\n",
      "train loss:0.2643893788223326\n",
      "train loss:0.44671909444769314\n",
      "train loss:0.36980181385560884\n",
      "train loss:0.3802331062911037\n",
      "train loss:0.5299724555116212\n",
      "train loss:0.41160061041268486\n",
      "train loss:0.668162164837801\n",
      "train loss:0.3522124957944858\n",
      "train loss:0.3580499247502465\n",
      "train loss:0.3414986567490228\n",
      "train loss:0.266380177485239\n",
      "train loss:0.3361339176699771\n",
      "train loss:0.4522202643299164\n",
      "train loss:0.3539155750358532\n",
      "train loss:0.35385715781410104\n",
      "train loss:0.32861267378482206\n",
      "train loss:0.3909676869462394\n",
      "train loss:0.4259559995734413\n",
      "train loss:0.36298903872399835\n",
      "train loss:0.35530744866723063\n",
      "train loss:0.3163409556810448\n",
      "train loss:0.38339043374608905\n",
      "train loss:0.3911565907340212\n",
      "train loss:0.3498314208189217\n",
      "train loss:0.376734198079872\n",
      "train loss:0.3740474133496592\n",
      "train loss:0.5030125546875979\n",
      "train loss:0.5419950436078731\n",
      "train loss:0.4240434976260313\n",
      "train loss:0.36194539588605273\n",
      "train loss:0.27876234536457056\n",
      "train loss:0.5419107283726385\n",
      "train loss:0.44251194362059537\n",
      "train loss:0.2835711795169017\n",
      "train loss:0.33713254013327715\n",
      "train loss:0.44228654370493325\n",
      "train loss:0.28426931734950317\n",
      "train loss:0.5063180860074683\n",
      "train loss:0.2879038137708115\n",
      "train loss:0.40138903727009784\n",
      "train loss:0.31962460779930285\n",
      "train loss:0.5038485236966715\n",
      "train loss:0.3391180298801433\n",
      "train loss:0.3026246798115186\n",
      "train loss:0.2287136337846122\n",
      "train loss:0.34111791447122386\n",
      "train loss:0.392786563776195\n",
      "train loss:0.2655028315666217\n",
      "train loss:0.3631770141303825\n",
      "train loss:0.3987714711294432\n",
      "train loss:0.4257004243181494\n",
      "train loss:0.3686399781663237\n",
      "train loss:0.5082078152923808\n",
      "train loss:0.32716972296758406\n",
      "train loss:0.49684150095359897\n",
      "train loss:0.32767132189185927\n",
      "train loss:0.2965225417810108\n",
      "train loss:0.4205186238737247\n",
      "train loss:0.36926426602477264\n",
      "train loss:0.37692124201180877\n",
      "train loss:0.23402427473797827\n",
      "train loss:0.38060143444547434\n",
      "train loss:0.45678902665698756\n",
      "train loss:0.33034772143670815\n",
      "train loss:0.29323360818759703\n",
      "train loss:0.26018653426716276\n",
      "train loss:0.2156942934874698\n",
      "train loss:0.2401760103559827\n",
      "train loss:0.43246383207776573\n",
      "train loss:0.36360410253761377\n",
      "train loss:0.1630542380949461\n",
      "train loss:0.40798977949013115\n",
      "train loss:0.3319938191805363\n",
      "train loss:0.2065768899206113\n",
      "train loss:0.33871618193894093\n",
      "train loss:0.3649567510226558\n",
      "train loss:0.4357329770687743\n",
      "train loss:0.306645410668473\n",
      "train loss:0.33915513278443166\n",
      "train loss:0.2310786805223262\n",
      "train loss:0.32302466208365493\n",
      "train loss:0.17052344904627628\n",
      "train loss:0.3753661028974337\n",
      "train loss:0.21770659120137437\n",
      "train loss:0.20319558574154864\n",
      "train loss:0.2687903555436457\n",
      "train loss:0.33071480002430514\n",
      "train loss:0.2700807923258211\n",
      "train loss:0.2665256935179797\n",
      "train loss:0.31639594574716595\n",
      "train loss:0.22604445796867906\n",
      "train loss:0.22169210533862757\n",
      "train loss:0.43423776906098005\n",
      "train loss:0.26170565328079254\n",
      "train loss:0.3940810149011813\n",
      "train loss:0.23160764180422086\n",
      "train loss:0.2522702171761035\n",
      "train loss:0.3512187168751864\n",
      "train loss:0.22568787798475254\n",
      "train loss:0.332848932143975\n",
      "train loss:0.3205493544398709\n",
      "train loss:0.2926780583713675\n",
      "train loss:0.2543889933319304\n",
      "train loss:0.412466220852178\n",
      "train loss:0.2775326899510257\n",
      "train loss:0.4441123904982656\n",
      "train loss:0.29720276355439407\n",
      "train loss:0.39448606904982325\n",
      "train loss:0.3012764109978143\n",
      "train loss:0.40755355368516405\n",
      "train loss:0.20298979715622248\n",
      "train loss:0.25939385839511603\n",
      "train loss:0.24614090822454193\n",
      "train loss:0.18591008585919344\n",
      "train loss:0.22157363844371658\n",
      "train loss:0.30259955370432035\n",
      "train loss:0.18303433107307537\n",
      "train loss:0.3145781189125207\n",
      "train loss:0.3328301207879138\n",
      "train loss:0.3311649566070639\n",
      "train loss:0.3608618834526712\n",
      "train loss:0.18422023398387882\n",
      "train loss:0.3763597133869449\n",
      "train loss:0.2672632093892884\n",
      "train loss:0.36267802330073096\n",
      "train loss:0.26933370328506784\n",
      "train loss:0.3129501276377464\n",
      "train loss:0.3747222005773183\n",
      "train loss:0.28914418346738563\n",
      "train loss:0.20961335253145727\n",
      "train loss:0.3243578232579607\n",
      "train loss:0.23852991898431872\n",
      "train loss:0.35932997053072546\n",
      "train loss:0.3393165169134115\n",
      "train loss:0.38306421334663804\n",
      "train loss:0.2562407073956241\n",
      "train loss:0.3630748667285327\n",
      "train loss:0.3420861488984114\n",
      "train loss:0.20850482763993905\n",
      "train loss:0.2430496990552478\n",
      "train loss:0.209696759338054\n",
      "train loss:0.2905804863913779\n",
      "train loss:0.2835252924103764\n",
      "train loss:0.2473772777928054\n",
      "train loss:0.24401867789196463\n",
      "train loss:0.3583615848611305\n",
      "train loss:0.27146777128101635\n",
      "train loss:0.35068619043784\n",
      "train loss:0.30449605651103023\n",
      "train loss:0.26179418009491773\n",
      "train loss:0.20241856051048215\n",
      "train loss:0.46230375110447747\n",
      "train loss:0.46743502103698453\n",
      "train loss:0.2713428095133332\n",
      "train loss:0.18509672485910036\n",
      "train loss:0.21834506499351444\n",
      "train loss:0.20014187525857266\n",
      "train loss:0.2569898658699908\n",
      "train loss:0.2588001300903542\n",
      "train loss:0.2866315961744357\n",
      "train loss:0.15847138544283298\n",
      "train loss:0.2809110412547343\n",
      "train loss:0.25320651358779794\n",
      "train loss:0.21943315518745865\n",
      "train loss:0.47956589511084025\n",
      "train loss:0.4320304637029747\n",
      "train loss:0.2293514048159375\n",
      "train loss:0.39612405798329836\n",
      "train loss:0.20979900024835538\n",
      "train loss:0.3279674274667706\n",
      "train loss:0.1485520474472064\n",
      "train loss:0.15300533913945666\n",
      "train loss:0.32042761445270107\n",
      "train loss:0.2435618036282911\n",
      "train loss:0.2372306126817338\n",
      "train loss:0.1905165124804756\n",
      "train loss:0.19025122330685534\n",
      "train loss:0.3019903631487369\n",
      "train loss:0.4610109878601363\n",
      "train loss:0.29696019770869564\n",
      "train loss:0.2701449430678451\n",
      "train loss:0.34145841821606737\n",
      "train loss:0.3173920818270708\n",
      "train loss:0.14318847984194757\n",
      "train loss:0.26200407100550277\n",
      "train loss:0.2644408692725341\n",
      "train loss:0.20080668579618843\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.33569139853120994\n",
      "train loss:0.18002306917457578\n",
      "train loss:0.3055820986503982\n",
      "train loss:0.16923385906536492\n",
      "train loss:0.3645874756085098\n",
      "train loss:0.22682678930355027\n",
      "train loss:0.251993628542234\n",
      "train loss:0.1245267450701613\n",
      "train loss:0.1970563727391443\n",
      "train loss:0.21603473698081274\n",
      "train loss:0.19979617710805336\n",
      "train loss:0.21432881617882116\n",
      "train loss:0.25803112675125883\n",
      "train loss:0.22545783623982377\n",
      "train loss:0.241303966125314\n",
      "train loss:0.16736995833611423\n",
      "train loss:0.5162470543066161\n",
      "train loss:0.29172354162881164\n",
      "train loss:0.2683394856888997\n",
      "train loss:0.13513399564842973\n",
      "train loss:0.20540456463674928\n",
      "train loss:0.2032632107404681\n",
      "train loss:0.23677699560467735\n",
      "train loss:0.20982925529497337\n",
      "train loss:0.3530516618333646\n",
      "train loss:0.20973875793081537\n",
      "train loss:0.18095064410612674\n",
      "train loss:0.11346654277409755\n",
      "train loss:0.20695358753752707\n",
      "train loss:0.2277402192481452\n",
      "train loss:0.2174045839012237\n",
      "train loss:0.21346668813073755\n",
      "train loss:0.13533274799864053\n",
      "train loss:0.25613673712286344\n",
      "train loss:0.15361910908638\n",
      "train loss:0.26561949042555144\n",
      "train loss:0.24443464086170189\n",
      "train loss:0.286241245564474\n",
      "train loss:0.18118450636434852\n",
      "train loss:0.19190332017587214\n",
      "train loss:0.2787969136131451\n",
      "train loss:0.21651889416290462\n",
      "train loss:0.143805996439196\n",
      "train loss:0.2105847429256727\n",
      "train loss:0.13707222249832265\n",
      "train loss:0.13245068823607167\n",
      "train loss:0.16509463758871815\n",
      "train loss:0.21300030431657663\n",
      "train loss:0.23329707178515857\n",
      "train loss:0.1735057422644881\n",
      "train loss:0.3961069582478385\n",
      "train loss:0.25653164607186624\n",
      "train loss:0.2910943265167849\n",
      "train loss:0.31987194514894723\n",
      "train loss:0.15987807586596753\n",
      "train loss:0.15434717924967953\n",
      "train loss:0.2500058277865958\n",
      "train loss:0.2009217094427673\n",
      "train loss:0.22797308703859023\n",
      "train loss:0.3122417158335085\n",
      "train loss:0.19241056468160045\n",
      "train loss:0.284947173360867\n",
      "train loss:0.28571133088885614\n",
      "train loss:0.17652594307270295\n",
      "train loss:0.16525286984814488\n",
      "train loss:0.16870779261999735\n",
      "train loss:0.16344463607606055\n",
      "train loss:0.19777188969674395\n",
      "train loss:0.2589241546794316\n",
      "train loss:0.22601917084534123\n",
      "train loss:0.14711640990918018\n",
      "train loss:0.12123981864089708\n",
      "train loss:0.19002068174127953\n",
      "train loss:0.09323186762009124\n",
      "train loss:0.09386272999758281\n",
      "train loss:0.10180729995387529\n",
      "train loss:0.18862100318359343\n",
      "train loss:0.23279623943108166\n",
      "train loss:0.19902744566021455\n",
      "train loss:0.42089628746137137\n",
      "train loss:0.2081831673289813\n",
      "train loss:0.13563670115651202\n",
      "train loss:0.23602037907356752\n",
      "train loss:0.2851180605918103\n",
      "train loss:0.14851764718876764\n",
      "train loss:0.2188977639227758\n",
      "train loss:0.23204136571222894\n",
      "train loss:0.06871250808580402\n",
      "train loss:0.15360843761093743\n",
      "train loss:0.1720467447107581\n",
      "train loss:0.30434374673986786\n",
      "train loss:0.23092859081132883\n",
      "train loss:0.2724226533857443\n",
      "train loss:0.13774865221209487\n",
      "train loss:0.20168518093661053\n",
      "train loss:0.15484213294206814\n",
      "train loss:0.16533763547988672\n",
      "train loss:0.22863113021470988\n",
      "train loss:0.11406841535734888\n",
      "train loss:0.14317880920298692\n",
      "train loss:0.15074550826223493\n",
      "train loss:0.18657975176733646\n",
      "train loss:0.1808335748389454\n",
      "train loss:0.21913042374987549\n",
      "train loss:0.0970799320696027\n",
      "train loss:0.1883919549781587\n",
      "train loss:0.1858048572354159\n",
      "train loss:0.10963328174732634\n",
      "train loss:0.1426970086964977\n",
      "train loss:0.23004368034986622\n",
      "train loss:0.13464475961190103\n",
      "train loss:0.16386281143681697\n",
      "train loss:0.09689240367622728\n",
      "train loss:0.1860074587833117\n",
      "train loss:0.14331857405962276\n",
      "train loss:0.17864218614903557\n",
      "train loss:0.09495679950012349\n",
      "train loss:0.14592960276983014\n",
      "train loss:0.12090907962491641\n",
      "train loss:0.13737690798309077\n",
      "train loss:0.23287504477822016\n",
      "train loss:0.24286523560134463\n",
      "train loss:0.13635536250363262\n",
      "train loss:0.10918981125317277\n",
      "train loss:0.25732157984030535\n",
      "train loss:0.20377318277953027\n",
      "train loss:0.3747121049868863\n",
      "train loss:0.07246855390249758\n",
      "train loss:0.13488363987108198\n",
      "train loss:0.2098173158256945\n",
      "train loss:0.11488855437818862\n",
      "train loss:0.21045107884251257\n",
      "train loss:0.11897018243137669\n",
      "train loss:0.10245867430598292\n",
      "train loss:0.12074465167810151\n",
      "train loss:0.2157376506750271\n",
      "train loss:0.10613447953821392\n",
      "train loss:0.26917233858397666\n",
      "train loss:0.12117738410123026\n",
      "train loss:0.20034252692064564\n",
      "train loss:0.13324049831503634\n",
      "train loss:0.10100391376676306\n",
      "train loss:0.12334675088313425\n",
      "train loss:0.09541693888344562\n",
      "train loss:0.07879729509722208\n",
      "train loss:0.17977734822291935\n",
      "train loss:0.31196625757365615\n",
      "train loss:0.18570942062361145\n",
      "train loss:0.13649233804272712\n",
      "train loss:0.15919560717304815\n",
      "train loss:0.1455836404662483\n",
      "train loss:0.19992347300167299\n",
      "train loss:0.22144859369685554\n",
      "train loss:0.14562128617063305\n",
      "train loss:0.12018248937228566\n",
      "train loss:0.16155458063411193\n",
      "train loss:0.19199846403895704\n",
      "train loss:0.19101243586631805\n",
      "train loss:0.1753706103977085\n",
      "train loss:0.10080638093663792\n",
      "train loss:0.19808493817403877\n",
      "train loss:0.13206281476342896\n",
      "train loss:0.15012989612625322\n",
      "train loss:0.05173183346360827\n",
      "train loss:0.09263011311842774\n",
      "train loss:0.16557516312307302\n",
      "train loss:0.2105185471569236\n",
      "train loss:0.11682224873444358\n",
      "train loss:0.15357923527761777\n",
      "train loss:0.1560412330386098\n",
      "train loss:0.156511754025453\n",
      "train loss:0.11087556086416217\n",
      "train loss:0.08190293980894461\n",
      "train loss:0.18886658308839718\n",
      "train loss:0.10365557340987264\n",
      "train loss:0.18231398116464453\n",
      "train loss:0.06361317332033449\n",
      "train loss:0.153344829193916\n",
      "train loss:0.12017080600843681\n",
      "train loss:0.1659711219658162\n",
      "train loss:0.07694821066435041\n",
      "train loss:0.12200746821266575\n",
      "train loss:0.0874224968706453\n",
      "train loss:0.08640565074963995\n",
      "train loss:0.09613879915267098\n",
      "train loss:0.15034649791798674\n",
      "train loss:0.10705275052503671\n",
      "train loss:0.12513015178744846\n",
      "train loss:0.13293761173814161\n",
      "train loss:0.12705202044048797\n",
      "train loss:0.20002750798676255\n",
      "train loss:0.22139532962041764\n",
      "train loss:0.10395109429598572\n",
      "train loss:0.14455658322420017\n",
      "train loss:0.10115330252562744\n",
      "train loss:0.15327584716507558\n",
      "train loss:0.11256641309689357\n",
      "train loss:0.1887258928851169\n",
      "train loss:0.11651453865813093\n",
      "train loss:0.19857254464543814\n",
      "train loss:0.11781298006940119\n",
      "train loss:0.1635286029358164\n",
      "train loss:0.13894702896906527\n",
      "train loss:0.10197604443531524\n",
      "train loss:0.12422958391221804\n",
      "train loss:0.12042951435730641\n",
      "train loss:0.1958139164763953\n",
      "train loss:0.21325087398124168\n",
      "train loss:0.1004713838981563\n",
      "train loss:0.08958287745225377\n",
      "train loss:0.09083705289998818\n",
      "train loss:0.13985651109708852\n",
      "train loss:0.16958870978362028\n",
      "train loss:0.149806607540742\n",
      "train loss:0.09141644941941776\n",
      "train loss:0.11971905206459059\n",
      "train loss:0.09268896357004575\n",
      "train loss:0.09199135745022076\n",
      "train loss:0.15131008891513173\n",
      "train loss:0.11739116755410955\n",
      "train loss:0.15854514002060835\n",
      "train loss:0.1974780657250415\n",
      "train loss:0.11000007314303378\n",
      "train loss:0.24999433274941482\n",
      "train loss:0.0958828056500515\n",
      "train loss:0.13327005666020952\n",
      "train loss:0.16027941965445572\n",
      "train loss:0.12670868138988556\n",
      "train loss:0.09733573986103806\n",
      "train loss:0.1995239189859954\n",
      "train loss:0.14325503878541077\n",
      "train loss:0.20993217548189325\n",
      "train loss:0.13806440558179983\n",
      "train loss:0.09715745373402893\n",
      "train loss:0.16128524693062268\n",
      "train loss:0.17320520676168613\n",
      "train loss:0.14996915228229796\n",
      "train loss:0.14690596745662457\n",
      "train loss:0.07940411831026861\n",
      "train loss:0.16283909168458188\n",
      "train loss:0.12875331187569747\n",
      "train loss:0.2157551458277941\n",
      "train loss:0.22143479008275285\n",
      "train loss:0.10253610094773498\n",
      "train loss:0.15555856646765728\n",
      "train loss:0.2632447948428194\n",
      "train loss:0.09372408467723436\n",
      "train loss:0.14580158691736816\n",
      "train loss:0.07367101770686374\n",
      "train loss:0.17366852131752455\n",
      "train loss:0.27168095264840736\n",
      "train loss:0.18204039301134312\n",
      "train loss:0.0688041622352449\n",
      "train loss:0.05473815526771991\n",
      "train loss:0.1904962361277003\n",
      "train loss:0.07719678854100073\n",
      "train loss:0.11506270705758644\n",
      "train loss:0.15897659393904517\n",
      "train loss:0.15399769420517992\n",
      "train loss:0.11017068252753937\n",
      "train loss:0.22796251015896046\n",
      "train loss:0.09827978596743855\n",
      "train loss:0.050435455125308726\n",
      "train loss:0.07566729030308288\n",
      "train loss:0.1085853661601649\n",
      "train loss:0.13173568446550038\n",
      "train loss:0.17220021420631274\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.1395942254644691\n",
      "train loss:0.13110930501537713\n",
      "train loss:0.13409674963356577\n",
      "train loss:0.0918884331490616\n",
      "train loss:0.1865349656007512\n",
      "train loss:0.1151676468249786\n",
      "train loss:0.19105833454461899\n",
      "train loss:0.08082486030658856\n",
      "train loss:0.11452908325064967\n",
      "train loss:0.2131480869122452\n",
      "train loss:0.15928068772668313\n",
      "train loss:0.19599568023540026\n",
      "train loss:0.1425509212909091\n",
      "train loss:0.16962205233258237\n",
      "train loss:0.08189853277626154\n",
      "train loss:0.08150694469846295\n",
      "train loss:0.09778255354793756\n",
      "train loss:0.1864946525142309\n",
      "train loss:0.041761723816310804\n",
      "train loss:0.27261427493246104\n",
      "train loss:0.22703940842428794\n",
      "train loss:0.12718881415628153\n",
      "train loss:0.06629434941152172\n",
      "train loss:0.08999820173685111\n",
      "train loss:0.2198242592489477\n",
      "train loss:0.2250108638764401\n",
      "train loss:0.12456451816569672\n",
      "train loss:0.09432365391277511\n",
      "train loss:0.06092670971526738\n",
      "train loss:0.12427106892222865\n",
      "train loss:0.15401198829493049\n",
      "train loss:0.08051153439884906\n",
      "train loss:0.1066520374565306\n",
      "train loss:0.07484440737669909\n",
      "train loss:0.08731650295978609\n",
      "train loss:0.11458368988076187\n",
      "train loss:0.07135717998721144\n",
      "train loss:0.11739824658704563\n",
      "train loss:0.11537094354214354\n",
      "train loss:0.08012013930085049\n",
      "train loss:0.2721843310600905\n",
      "train loss:0.14833850984583064\n",
      "train loss:0.046286446604417435\n",
      "train loss:0.17278159476149527\n",
      "train loss:0.14391735518745136\n",
      "train loss:0.07241958208760002\n",
      "train loss:0.10898092816745793\n",
      "train loss:0.21118102479210346\n",
      "train loss:0.15158188563950226\n",
      "train loss:0.09113315694965919\n",
      "train loss:0.1676140358990804\n",
      "train loss:0.08957602239285693\n",
      "train loss:0.057446254816547505\n",
      "train loss:0.1446832028621581\n",
      "train loss:0.07696318754436325\n",
      "train loss:0.16343570674954258\n",
      "train loss:0.07610335440118836\n",
      "train loss:0.11329031942500882\n",
      "train loss:0.11093008453784214\n",
      "train loss:0.12030403167160958\n",
      "train loss:0.08191687221344625\n",
      "train loss:0.09018597463138142\n",
      "train loss:0.10311625175919283\n",
      "train loss:0.03647763719407621\n",
      "train loss:0.10241387789601991\n",
      "=== epoch:2, train acc:0.964, test acc:0.96 ===\n",
      "train loss:0.22483709461465357\n",
      "train loss:0.09167575712914798\n",
      "train loss:0.05812764743374637\n",
      "train loss:0.07932011099789996\n",
      "train loss:0.07799576188030924\n",
      "train loss:0.15932821428196584\n",
      "train loss:0.131452087519609\n",
      "train loss:0.14427024904312005\n",
      "train loss:0.06037176870517404\n",
      "train loss:0.1943898187437461\n",
      "train loss:0.06125626422104435\n",
      "train loss:0.10392530772132322\n",
      "train loss:0.3139350322452291\n",
      "train loss:0.24016808553059138\n",
      "train loss:0.0743317766023386\n",
      "train loss:0.157714929895533\n",
      "train loss:0.11781180321132192\n",
      "train loss:0.09316210731751234\n",
      "train loss:0.05708801641362192\n",
      "train loss:0.05552894466004857\n",
      "train loss:0.13554759675326122\n",
      "train loss:0.15546124293590977\n",
      "train loss:0.06639506289117464\n",
      "train loss:0.08858736624322525\n",
      "train loss:0.12581258257843633\n",
      "train loss:0.07363222955143806\n",
      "train loss:0.04231966898449885\n",
      "train loss:0.1578188408290094\n",
      "train loss:0.09352344433051472\n",
      "train loss:0.05612822721863445\n",
      "train loss:0.09041957277519573\n",
      "train loss:0.06552929745499943\n",
      "train loss:0.11106897141376304\n",
      "train loss:0.1226748667390204\n",
      "train loss:0.11623432053824229\n",
      "train loss:0.15213884616445708\n",
      "train loss:0.0604223638810465\n",
      "train loss:0.03808064008878406\n",
      "train loss:0.04572564036758374\n",
      "train loss:0.08440383894133331\n",
      "train loss:0.1318259599607517\n",
      "train loss:0.03757883376773101\n",
      "train loss:0.07238004670104742\n",
      "train loss:0.06794901140207762\n",
      "train loss:0.08305008720563305\n",
      "train loss:0.08809824612083884\n",
      "train loss:0.14667553896558036\n",
      "train loss:0.20396025170151696\n",
      "train loss:0.11900339099239153\n",
      "train loss:0.20204444134742933\n",
      "train loss:0.30828024041390306\n",
      "train loss:0.10094305052354131\n",
      "train loss:0.05023661260253988\n",
      "train loss:0.10568294551026312\n",
      "train loss:0.050719181479764675\n",
      "train loss:0.15867593474803493\n",
      "train loss:0.05739852715225267\n",
      "train loss:0.10379733863780079\n",
      "train loss:0.02634692472191926\n",
      "train loss:0.09613895951296059\n",
      "train loss:0.06049082417305269\n",
      "train loss:0.21725308707034327\n",
      "train loss:0.06716599525284388\n",
      "train loss:0.17686860590768838\n",
      "train loss:0.048666632741652595\n",
      "train loss:0.0985764725860961\n",
      "train loss:0.08825745487110356\n",
      "train loss:0.1355941383052127\n",
      "train loss:0.18105671162128217\n",
      "train loss:0.06110590282159206\n",
      "train loss:0.0747712863835771\n",
      "train loss:0.16844732675132978\n",
      "train loss:0.12137147361189408\n",
      "train loss:0.1351560904851478\n",
      "train loss:0.06593079865741382\n",
      "train loss:0.0993108930253417\n",
      "train loss:0.10440316224962241\n",
      "train loss:0.13400956699605573\n",
      "train loss:0.13426872476262555\n",
      "train loss:0.1638319349621107\n",
      "train loss:0.17624756584963344\n",
      "train loss:0.1816291984428779\n",
      "train loss:0.15917475340203643\n",
      "train loss:0.10951036398030159\n",
      "train loss:0.09037480945666339\n",
      "train loss:0.1569490310364645\n",
      "train loss:0.15579966389197095\n",
      "train loss:0.10789626082695847\n",
      "train loss:0.14606034302999468\n",
      "train loss:0.08473811780493158\n",
      "train loss:0.09973652391444164\n",
      "train loss:0.1063124216036708\n",
      "train loss:0.08227941889575409\n",
      "train loss:0.18995262513332126\n",
      "train loss:0.04430031949651109\n",
      "train loss:0.08250169983741047\n",
      "train loss:0.1604697674136734\n",
      "train loss:0.10250892626275782\n",
      "train loss:0.03340380306497135\n",
      "train loss:0.23508671906140738\n",
      "train loss:0.037589446961641654\n",
      "train loss:0.05345455065144897\n",
      "train loss:0.06801416611387605\n",
      "train loss:0.1217692528396259\n",
      "train loss:0.0908557354925498\n",
      "train loss:0.08521128993355638\n",
      "train loss:0.07501628880047356\n",
      "train loss:0.1339529301928068\n",
      "train loss:0.1536354884477661\n",
      "train loss:0.06090694753225087\n",
      "train loss:0.0995131430939951\n",
      "train loss:0.08401165528105235\n",
      "train loss:0.12406862282605088\n",
      "train loss:0.17033890979933466\n",
      "train loss:0.10543549632247293\n",
      "train loss:0.06311059456560734\n",
      "train loss:0.06998769338674381\n",
      "train loss:0.05193954587607801\n",
      "train loss:0.0815439768182798\n",
      "train loss:0.1046711013900528\n",
      "train loss:0.051508110425512864\n",
      "train loss:0.09560658090932328\n",
      "train loss:0.07566313937775124\n",
      "train loss:0.13738284123759384\n",
      "train loss:0.19391964024268124\n",
      "train loss:0.06038709002239677\n",
      "train loss:0.1191841092145153\n",
      "train loss:0.0892439124208917\n",
      "train loss:0.05032739733951079\n",
      "train loss:0.21789809655058928\n",
      "train loss:0.030389781035896207\n",
      "train loss:0.1590970941474229\n",
      "train loss:0.06401714704366329\n",
      "train loss:0.12928169905338932\n",
      "train loss:0.05259007118893294\n",
      "train loss:0.12148351819354165\n",
      "train loss:0.0502018295120106\n",
      "train loss:0.05732284987915863\n",
      "train loss:0.09029355395184073\n",
      "train loss:0.11956684204876195\n",
      "train loss:0.20163560903791955\n",
      "train loss:0.13680733226667166\n",
      "train loss:0.051164838323481704\n",
      "train loss:0.11078333104998697\n",
      "train loss:0.17805274849298885\n",
      "train loss:0.07489505003006541\n",
      "train loss:0.2293268699942359\n",
      "train loss:0.06667685821741598\n",
      "train loss:0.09283560338069942\n",
      "train loss:0.14396999691073448\n",
      "train loss:0.05108233980092398\n",
      "train loss:0.12951296810965038\n",
      "train loss:0.12053870869127756\n",
      "train loss:0.0429872063861762\n",
      "train loss:0.10520861437086855\n",
      "train loss:0.05562902377681162\n",
      "train loss:0.04363070068598086\n",
      "train loss:0.11814491019362071\n",
      "train loss:0.13037173446531514\n",
      "train loss:0.04231996742953498\n",
      "train loss:0.092065420793482\n",
      "train loss:0.12372320511616577\n",
      "train loss:0.05768156588896346\n",
      "train loss:0.07185577611590914\n",
      "train loss:0.14165690488111132\n",
      "train loss:0.07229399630047348\n",
      "train loss:0.10840728956721452\n",
      "train loss:0.05330444120041337\n",
      "train loss:0.07845967324792967\n",
      "train loss:0.087068825301959\n",
      "train loss:0.0645031990213016\n",
      "train loss:0.1643612667796789\n",
      "train loss:0.09985197987714121\n",
      "train loss:0.20187844853858647\n",
      "train loss:0.053179176841645984\n",
      "train loss:0.12617150279143585\n",
      "train loss:0.10055450545299123\n",
      "train loss:0.025269420569549225\n",
      "train loss:0.16058319068362806\n",
      "train loss:0.03860916552243002\n",
      "train loss:0.06653119186691397\n",
      "train loss:0.11320625858646378\n",
      "train loss:0.09116482559127873\n",
      "train loss:0.10590991371006214\n",
      "train loss:0.1274591584603675\n",
      "train loss:0.11141630496410258\n",
      "train loss:0.08401193471117453\n",
      "train loss:0.08268886780989454\n",
      "train loss:0.1160313154099116\n",
      "train loss:0.07797859925333145\n",
      "train loss:0.09954885278420905\n",
      "train loss:0.1283370643150571\n",
      "train loss:0.07345210893972247\n",
      "train loss:0.07294462108768549\n",
      "train loss:0.09838950106991395\n",
      "train loss:0.06323300327371122\n",
      "train loss:0.03273041448351172\n",
      "train loss:0.10425305107329168\n",
      "train loss:0.09365940196857943\n",
      "train loss:0.0686507391999743\n",
      "train loss:0.1381525636148363\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.06252266328643422\n",
      "train loss:0.08573621762435074\n",
      "train loss:0.039253406251955544\n",
      "train loss:0.03797843379269722\n",
      "train loss:0.07645853048664444\n",
      "train loss:0.08291916163809716\n",
      "train loss:0.09921090749631847\n",
      "train loss:0.1529386327246171\n",
      "train loss:0.15161731807273202\n",
      "train loss:0.09793434024257147\n",
      "train loss:0.09580258287896054\n",
      "train loss:0.15665511423140216\n",
      "train loss:0.04496794898283046\n",
      "train loss:0.07549411752354519\n",
      "train loss:0.11722097118986953\n",
      "train loss:0.07488691653902539\n",
      "train loss:0.06732601994954361\n",
      "train loss:0.08994656578536533\n",
      "train loss:0.05525012642342726\n",
      "train loss:0.11638123906493927\n",
      "train loss:0.058235187765220395\n",
      "train loss:0.10390989673054438\n",
      "train loss:0.06024038974186789\n",
      "train loss:0.11505980132335852\n",
      "train loss:0.06946597047673553\n",
      "train loss:0.05090070311661276\n",
      "train loss:0.0692648037096258\n",
      "train loss:0.042691549860123426\n",
      "train loss:0.13701509826125546\n",
      "train loss:0.08498957606000772\n",
      "train loss:0.05234868171983376\n",
      "train loss:0.07946632869109412\n",
      "train loss:0.11555347833785015\n",
      "train loss:0.10291269461596415\n",
      "train loss:0.10377404599376455\n",
      "train loss:0.06383579018085958\n",
      "train loss:0.11724580279139339\n",
      "train loss:0.0634694372957732\n",
      "train loss:0.11119414476165364\n",
      "train loss:0.1281853262294718\n",
      "train loss:0.09136114889130578\n",
      "train loss:0.06367261948516685\n",
      "train loss:0.07990082283915696\n",
      "train loss:0.04894573164043269\n",
      "train loss:0.09992919215020583\n",
      "train loss:0.15538012199908705\n",
      "train loss:0.12224467310961643\n",
      "train loss:0.05911417407902971\n",
      "train loss:0.04331749370120391\n",
      "train loss:0.15178247923708216\n",
      "train loss:0.07873807253344106\n",
      "train loss:0.05498066536422724\n",
      "train loss:0.04746156907449966\n",
      "train loss:0.07493276311746039\n",
      "train loss:0.07537981996493959\n",
      "train loss:0.0962144269736276\n",
      "train loss:0.0658562487829838\n",
      "train loss:0.16014207258520152\n",
      "train loss:0.08546681837933835\n",
      "train loss:0.04211390409545328\n",
      "train loss:0.10003858564256855\n",
      "train loss:0.04435657607620123\n",
      "train loss:0.0550543635344062\n",
      "train loss:0.12764481449980916\n",
      "train loss:0.05063677023842319\n",
      "train loss:0.08909993344522443\n",
      "train loss:0.07456107732594135\n",
      "train loss:0.09286297841784032\n",
      "train loss:0.07734277356542237\n",
      "train loss:0.09826124790491365\n",
      "train loss:0.06826819682195456\n",
      "train loss:0.09666903561157149\n",
      "train loss:0.04750100819383438\n",
      "train loss:0.14797243414738603\n",
      "train loss:0.06953823827216116\n",
      "train loss:0.08930900217794356\n",
      "train loss:0.03425452391679937\n",
      "train loss:0.02658520342333949\n",
      "train loss:0.03242803416090335\n",
      "train loss:0.06450035051425568\n",
      "train loss:0.06059790864229078\n",
      "train loss:0.11012693731753624\n",
      "train loss:0.0648941291350505\n",
      "train loss:0.10829295954186278\n",
      "train loss:0.06872002576402142\n",
      "train loss:0.03360575713529557\n",
      "train loss:0.08851209521338282\n",
      "train loss:0.05158662136018711\n",
      "train loss:0.06994469530009545\n",
      "train loss:0.11633950703953104\n",
      "train loss:0.08361359931573886\n",
      "train loss:0.18144044553354302\n",
      "train loss:0.10618164326177702\n",
      "train loss:0.0664320189571556\n",
      "train loss:0.057544702327200214\n",
      "train loss:0.13475690632190107\n",
      "train loss:0.0676131836997252\n",
      "train loss:0.051672944102157364\n",
      "train loss:0.1117030408102078\n",
      "train loss:0.06769714379365785\n",
      "train loss:0.1432202739251912\n",
      "train loss:0.045189716124109686\n",
      "train loss:0.04588642226285313\n",
      "train loss:0.2264026735557959\n",
      "train loss:0.0821274181504006\n",
      "train loss:0.11396446412578148\n",
      "train loss:0.09150609768781463\n",
      "train loss:0.054111406335805606\n",
      "train loss:0.04611619266175151\n",
      "train loss:0.14502767757618948\n",
      "train loss:0.07991108878167684\n",
      "train loss:0.051905556388932676\n",
      "train loss:0.0353166734357962\n",
      "train loss:0.07874765489679325\n",
      "train loss:0.12157282533596556\n",
      "train loss:0.07090147452432757\n",
      "train loss:0.08127143860859794\n",
      "train loss:0.03500724400300708\n",
      "train loss:0.1564932905554244\n",
      "train loss:0.06912050041827497\n",
      "train loss:0.15261061749311794\n",
      "train loss:0.1047665520419476\n",
      "train loss:0.048692135019813974\n",
      "train loss:0.07745747151371159\n",
      "train loss:0.10701735257673964\n",
      "train loss:0.19945072905593242\n",
      "train loss:0.035126085842838606\n",
      "train loss:0.03963085320314684\n",
      "train loss:0.061719711074949696\n",
      "train loss:0.05921968324801007\n",
      "train loss:0.13371799624250694\n",
      "train loss:0.02728331542481742\n",
      "train loss:0.08128904036854179\n",
      "train loss:0.11879754703692759\n",
      "train loss:0.14696894290290205\n",
      "train loss:0.07866943283178793\n",
      "train loss:0.06641148389604777\n",
      "train loss:0.035077130301548555\n",
      "train loss:0.08360591118161753\n",
      "train loss:0.03795677166333779\n",
      "train loss:0.03903685349277611\n",
      "train loss:0.06714201023598687\n",
      "train loss:0.10897664572446654\n",
      "train loss:0.10290004582367303\n",
      "train loss:0.10663425810614147\n",
      "train loss:0.1605486019908786\n",
      "train loss:0.0366674526516705\n",
      "train loss:0.06032260315994931\n",
      "train loss:0.06349222588694628\n",
      "train loss:0.12405195160467837\n",
      "train loss:0.07166882901354747\n",
      "train loss:0.062226596765209176\n",
      "train loss:0.08496682397867023\n",
      "train loss:0.11191783938601862\n",
      "train loss:0.056291889514062665\n",
      "train loss:0.06849766280538909\n",
      "train loss:0.04982341163655023\n",
      "train loss:0.1264227727381077\n",
      "train loss:0.09672669172388818\n",
      "train loss:0.05915141245322851\n",
      "train loss:0.03872202555057574\n",
      "train loss:0.03915091764116721\n",
      "train loss:0.1381225711465333\n",
      "train loss:0.09693047025764048\n",
      "train loss:0.040806119480554105\n",
      "train loss:0.06312698020978616\n",
      "train loss:0.0734838395343887\n",
      "train loss:0.1292216778043435\n",
      "train loss:0.02833707478530953\n",
      "train loss:0.10929436855740167\n",
      "train loss:0.051935308066977104\n",
      "train loss:0.12557964964390667\n",
      "train loss:0.07556141989158441\n",
      "train loss:0.06115897460438017\n",
      "train loss:0.07503953702009038\n",
      "train loss:0.051462855745864414\n",
      "train loss:0.05705132925578295\n",
      "train loss:0.025897608912336237\n",
      "train loss:0.15590508439799863\n",
      "train loss:0.07837075184502679\n",
      "train loss:0.04207533601943272\n",
      "train loss:0.09027249452723737\n",
      "train loss:0.11824263964125077\n",
      "train loss:0.09420736876532645\n",
      "train loss:0.05587641421580983\n",
      "train loss:0.07043615566190904\n",
      "train loss:0.06910316203905455\n",
      "train loss:0.0704997183433324\n",
      "train loss:0.11100195342725688\n",
      "train loss:0.03760163584990486\n",
      "train loss:0.04844366768464256\n",
      "train loss:0.045432112163794745\n",
      "train loss:0.0518485085068351\n",
      "train loss:0.03495505472405465\n",
      "train loss:0.10763980642360041\n",
      "train loss:0.027986916513325792\n",
      "train loss:0.048023495870623885\n",
      "train loss:0.02013978156082435\n",
      "train loss:0.03646600247936434\n",
      "train loss:0.08891808677100281\n",
      "train loss:0.1260518904179715\n",
      "train loss:0.08878442619544621\n",
      "train loss:0.07377874655748064\n",
      "train loss:0.03726836145115717\n",
      "train loss:0.046781850429678806\n",
      "train loss:0.08388526063637776\n",
      "train loss:0.06958114761739777\n",
      "train loss:0.08582678200928799\n",
      "train loss:0.06659667828869065\n",
      "train loss:0.03717355456839666\n",
      "train loss:0.032249404920817376\n",
      "train loss:0.06211002476876724\n",
      "train loss:0.0730422425311045\n",
      "train loss:0.039948971824889476\n",
      "train loss:0.0645849824339488\n",
      "train loss:0.033512056924368976\n",
      "train loss:0.10752139144223966\n",
      "train loss:0.10955864261547196\n",
      "train loss:0.07994725190004354\n",
      "train loss:0.12136169321797316\n",
      "train loss:0.05771872445259981\n",
      "train loss:0.03425529249751157\n",
      "train loss:0.08850260594098751\n",
      "train loss:0.12269508274959703\n",
      "train loss:0.031091521745964978\n",
      "train loss:0.05608091894660581\n",
      "train loss:0.10945434091411607\n",
      "train loss:0.07192371665390936\n",
      "train loss:0.10052058232453083\n",
      "train loss:0.026927913890808397\n",
      "train loss:0.06894074847879193\n",
      "train loss:0.09025716174247943\n",
      "train loss:0.08906003674054792\n",
      "train loss:0.05891542972234067\n",
      "train loss:0.05240405334947033\n",
      "train loss:0.06604017859789897\n",
      "train loss:0.12767502527035524\n",
      "train loss:0.0959318988352781\n",
      "train loss:0.027389385335713414\n",
      "train loss:0.04216673642640243\n",
      "train loss:0.09520116181687482\n",
      "train loss:0.06127989328100543\n",
      "train loss:0.05307346317484304\n",
      "train loss:0.05921501838784708\n",
      "train loss:0.1534339431418797\n",
      "train loss:0.061886367714224795\n",
      "train loss:0.16553514264228342\n",
      "train loss:0.018098291410089097\n",
      "train loss:0.0776062091635613\n",
      "train loss:0.10922414952063868\n",
      "train loss:0.044767020534178054\n",
      "train loss:0.07937746731248412\n",
      "train loss:0.06033808128671689\n",
      "train loss:0.031032638140362036\n",
      "train loss:0.11093248027041945\n",
      "train loss:0.06577871377758666\n",
      "train loss:0.11029955941897836\n",
      "train loss:0.05574791878447212\n",
      "train loss:0.07069591395103714\n",
      "train loss:0.07365537573679565\n",
      "train loss:0.030440583671344914\n",
      "train loss:0.017934218466806352\n",
      "train loss:0.072895528981436\n",
      "train loss:0.05494617315941646\n",
      "train loss:0.035388427658393076\n",
      "train loss:0.025552016768930822\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.05050910881028143\n",
      "train loss:0.059838880618460176\n",
      "train loss:0.06212132318277362\n",
      "train loss:0.16842408279454746\n",
      "train loss:0.07008664240266554\n",
      "train loss:0.031892925705710645\n",
      "train loss:0.057577497575197055\n",
      "train loss:0.15897362522760408\n",
      "train loss:0.11288721817421737\n",
      "train loss:0.025725509798575366\n",
      "train loss:0.0804613172868704\n",
      "train loss:0.010092713625804885\n",
      "train loss:0.04901703342979685\n",
      "train loss:0.06321910303846275\n",
      "train loss:0.06213365731996113\n",
      "train loss:0.01523906554505986\n",
      "train loss:0.03331674895717842\n",
      "train loss:0.054221089293997354\n",
      "train loss:0.13941755119926336\n",
      "train loss:0.016589581025250186\n",
      "train loss:0.03173848225502403\n",
      "train loss:0.055733226947410106\n",
      "train loss:0.05893221844821827\n",
      "train loss:0.07992185979651975\n",
      "train loss:0.0749734674564808\n",
      "train loss:0.055857427867641335\n",
      "train loss:0.090939973300536\n",
      "train loss:0.07304816409447767\n",
      "train loss:0.02608439036916295\n",
      "train loss:0.040972064055337036\n",
      "train loss:0.043444960350991074\n",
      "train loss:0.03113022709053475\n",
      "train loss:0.04392042810964968\n",
      "train loss:0.039129034480281544\n",
      "train loss:0.056975380203404674\n",
      "train loss:0.06410077853658262\n",
      "train loss:0.025055120182384316\n",
      "train loss:0.03382097768894836\n",
      "train loss:0.06712106041850353\n",
      "train loss:0.08020648319708286\n",
      "train loss:0.04064656936795819\n",
      "train loss:0.11470155523200566\n",
      "train loss:0.06222141254022642\n",
      "train loss:0.13981014562009272\n",
      "train loss:0.051803308136246715\n",
      "train loss:0.0807124829029514\n",
      "train loss:0.09277630743674102\n",
      "train loss:0.1867228106064363\n",
      "train loss:0.03606878386158479\n",
      "train loss:0.017955898186951383\n",
      "train loss:0.026075345164993876\n",
      "train loss:0.04412657418747022\n",
      "train loss:0.03689642241093941\n",
      "train loss:0.044877043808362035\n",
      "train loss:0.047899235066920204\n",
      "train loss:0.06166176417454565\n",
      "train loss:0.036322919558299714\n",
      "train loss:0.021146547137569957\n",
      "train loss:0.1672997113171739\n",
      "train loss:0.06720994987471865\n",
      "train loss:0.018315585335817598\n",
      "train loss:0.018867850199130943\n",
      "train loss:0.024469393829541445\n",
      "train loss:0.09207236492098327\n",
      "train loss:0.04290471224604654\n",
      "train loss:0.02102570722891691\n",
      "train loss:0.04002968650266633\n",
      "train loss:0.013573538214871428\n",
      "train loss:0.019336510229316078\n",
      "train loss:0.07622627537661332\n",
      "train loss:0.02920561102869617\n",
      "train loss:0.0610309864317457\n",
      "train loss:0.04852699777129224\n",
      "train loss:0.06536058555740575\n",
      "train loss:0.03658314765199547\n",
      "train loss:0.15287482906517647\n",
      "train loss:0.050039149714501824\n",
      "train loss:0.18069347943518196\n",
      "train loss:0.057963014801034676\n",
      "train loss:0.03152469420231862\n",
      "train loss:0.042274722051972996\n",
      "train loss:0.034483144404584956\n",
      "train loss:0.08060947558038983\n",
      "train loss:0.02717370160817444\n",
      "train loss:0.07576191925943924\n",
      "train loss:0.04538849632684434\n",
      "train loss:0.03389396400940675\n",
      "train loss:0.05404700436287142\n",
      "train loss:0.03137909188506002\n",
      "train loss:0.08330001717043073\n",
      "train loss:0.14491059000667106\n",
      "train loss:0.08419921430421827\n",
      "train loss:0.04685929695243466\n",
      "train loss:0.08108782572183454\n",
      "train loss:0.04230564559011328\n",
      "train loss:0.07376763387676764\n",
      "train loss:0.08101552918574928\n",
      "train loss:0.062035493502754724\n",
      "train loss:0.014057118254277612\n",
      "train loss:0.0596665627964666\n",
      "train loss:0.010174731651818284\n",
      "train loss:0.055176044063570566\n",
      "train loss:0.036710621665021995\n",
      "train loss:0.07212972924418215\n",
      "train loss:0.042535744312124264\n",
      "train loss:0.07376148655246158\n",
      "train loss:0.02382289782511361\n",
      "train loss:0.05366572634584106\n",
      "train loss:0.022390889070792678\n",
      "train loss:0.058103504492216906\n",
      "train loss:0.1062148407760262\n",
      "train loss:0.06679964872462336\n",
      "train loss:0.075411462335548\n",
      "train loss:0.19574710974913107\n",
      "train loss:0.08741309061779605\n",
      "train loss:0.1565855655355021\n",
      "train loss:0.03260296649063916\n",
      "train loss:0.07673935156027639\n",
      "train loss:0.14077835804697766\n",
      "train loss:0.06060234600285117\n",
      "train loss:0.05779788562112311\n",
      "train loss:0.05287831044904334\n",
      "train loss:0.06202520304306667\n",
      "train loss:0.1983649701082788\n",
      "train loss:0.03416822153752238\n",
      "train loss:0.06893632075376348\n",
      "train loss:0.07698481758063398\n",
      "train loss:0.05925041459136555\n",
      "train loss:0.14289468132160374\n",
      "train loss:0.07910207296117658\n",
      "train loss:0.06716382692853126\n",
      "train loss:0.05321178663042526\n",
      "train loss:0.04086789674458752\n",
      "=== epoch:3, train acc:0.98, test acc:0.976 ===\n",
      "train loss:0.06577953912201123\n",
      "train loss:0.02918175165405928\n",
      "train loss:0.04464176336725819\n",
      "train loss:0.06162926626406234\n",
      "train loss:0.04046755364875902\n",
      "train loss:0.04690516977693596\n",
      "train loss:0.05637966244821147\n",
      "train loss:0.045226284750309285\n",
      "train loss:0.02975673771020425\n",
      "train loss:0.042073403204703076\n",
      "train loss:0.028808746405787934\n",
      "train loss:0.05953993797695494\n",
      "train loss:0.026990698459511648\n",
      "train loss:0.13471669408655595\n",
      "train loss:0.11592127179018483\n",
      "train loss:0.05396566906256561\n",
      "train loss:0.07126707152896558\n",
      "train loss:0.16091753336203546\n",
      "train loss:0.01819333439846048\n",
      "train loss:0.07197809528409733\n",
      "train loss:0.013455584155365139\n",
      "train loss:0.027196434819345524\n",
      "train loss:0.09528794170879312\n",
      "train loss:0.049557833418011\n",
      "train loss:0.05787302153637069\n",
      "train loss:0.031734214381792754\n",
      "train loss:0.02432865983670148\n",
      "train loss:0.025444438996538414\n",
      "train loss:0.10382333521604709\n",
      "train loss:0.05077058759703832\n",
      "train loss:0.022354020281186163\n",
      "train loss:0.0865028864863195\n",
      "train loss:0.06746815030511882\n",
      "train loss:0.02153402691915764\n",
      "train loss:0.07095958275165237\n",
      "train loss:0.0756669293095526\n",
      "train loss:0.06333288628900087\n",
      "train loss:0.03551621388878265\n",
      "train loss:0.024335226026991164\n",
      "train loss:0.04541738811850538\n",
      "train loss:0.05795881913058338\n",
      "train loss:0.024751878001771154\n",
      "train loss:0.04528725789131742\n",
      "train loss:0.033288892165468674\n",
      "train loss:0.08533804754783718\n",
      "train loss:0.011438802674580258\n",
      "train loss:0.06940117639096609\n",
      "train loss:0.02942918659076385\n",
      "train loss:0.05531266042769983\n",
      "train loss:0.041186994220388976\n",
      "train loss:0.03922782240815735\n",
      "train loss:0.03193934250743742\n",
      "train loss:0.058146599956669744\n",
      "train loss:0.034421735666259\n",
      "train loss:0.01744426873005058\n",
      "train loss:0.024752678849311566\n",
      "train loss:0.014785767987247782\n",
      "train loss:0.021271108363123372\n",
      "train loss:0.0303408075470853\n",
      "train loss:0.02235489763196333\n",
      "train loss:0.06949916744460269\n",
      "train loss:0.028230975246430274\n",
      "train loss:0.0345834698951638\n",
      "train loss:0.10887851174054454\n",
      "train loss:0.1255158605133735\n",
      "train loss:0.04776386820999302\n",
      "train loss:0.1123858160027506\n",
      "train loss:0.06679746963996562\n",
      "train loss:0.06511917415661819\n",
      "train loss:0.1352253355827166\n",
      "train loss:0.10380206356860051\n",
      "train loss:0.11891205631487686\n",
      "train loss:0.04812167404818666\n",
      "train loss:0.01635476463350811\n",
      "train loss:0.026259376431118135\n",
      "train loss:0.036391099958986914\n",
      "train loss:0.04048363121884369\n",
      "train loss:0.03788373419781619\n",
      "train loss:0.06431565628439598\n",
      "train loss:0.04044682763340579\n",
      "train loss:0.09598394347138724\n",
      "train loss:0.06724610387548237\n",
      "train loss:0.07397629547044943\n",
      "train loss:0.061834485143247735\n",
      "train loss:0.0405482616774814\n",
      "train loss:0.09047247699917525\n",
      "train loss:0.05939007655165384\n",
      "train loss:0.06083545127900718\n",
      "train loss:0.03384598801364825\n",
      "train loss:0.03330599647888666\n",
      "train loss:0.08279009252556663\n",
      "train loss:0.049869456705405914\n",
      "train loss:0.042724920509542075\n",
      "train loss:0.1079214367012395\n",
      "train loss:0.06138354545216578\n",
      "train loss:0.0494600909351222\n",
      "train loss:0.01815994937015728\n",
      "train loss:0.04894146412652118\n",
      "train loss:0.11211699632384448\n",
      "train loss:0.023043252391745296\n",
      "train loss:0.05033005682770459\n",
      "train loss:0.03463175608610275\n",
      "train loss:0.0924074117537173\n",
      "train loss:0.030431540814558487\n",
      "train loss:0.05291112006979474\n",
      "train loss:0.0508616213293556\n",
      "train loss:0.1107590493205448\n",
      "train loss:0.04604104981971296\n",
      "train loss:0.017594277234022133\n",
      "train loss:0.033418423132016026\n",
      "train loss:0.023796896999590544\n",
      "train loss:0.032180126082556264\n",
      "train loss:0.07339929659405327\n",
      "train loss:0.03245556290773945\n",
      "train loss:0.024836304238658027\n",
      "train loss:0.08843665620674118\n",
      "train loss:0.03220356693686131\n",
      "train loss:0.03455351891847446\n",
      "train loss:0.05571603194890697\n",
      "train loss:0.06841410464649876\n",
      "train loss:0.031355826732668485\n",
      "train loss:0.02341990488985259\n",
      "train loss:0.14508536206226066\n",
      "train loss:0.04414437595636856\n",
      "train loss:0.038613374717819275\n",
      "train loss:0.15916186227977516\n",
      "train loss:0.013589720803314144\n",
      "train loss:0.015453697623611406\n",
      "train loss:0.08240597393515242\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.0815623081254953\n",
      "train loss:0.09237274795461695\n",
      "train loss:0.10484011786123172\n",
      "train loss:0.06790135990656872\n",
      "train loss:0.037825943758992245\n",
      "train loss:0.08126097069323002\n",
      "train loss:0.06317350808927105\n",
      "train loss:0.08186414016320899\n",
      "train loss:0.028266387740308593\n",
      "train loss:0.042713680367017164\n",
      "train loss:0.057593174504014376\n",
      "train loss:0.05501357661891282\n",
      "train loss:0.11308962080920613\n",
      "train loss:0.08952173111621678\n",
      "train loss:0.06647923538955901\n",
      "train loss:0.08770675829820872\n",
      "train loss:0.04544455746060346\n",
      "train loss:0.06226550288932276\n",
      "train loss:0.026822290114613262\n",
      "train loss:0.08378209507087671\n",
      "train loss:0.038955995665360794\n",
      "train loss:0.0746234606418558\n",
      "train loss:0.043421471350325085\n",
      "train loss:0.05153980349726202\n",
      "train loss:0.031823277390753815\n",
      "train loss:0.030894299889754836\n",
      "train loss:0.04555907405344325\n",
      "train loss:0.12582894923157883\n",
      "train loss:0.05798039601307987\n",
      "train loss:0.09036420597682845\n",
      "train loss:0.050174137790230985\n",
      "train loss:0.018198907398878538\n",
      "train loss:0.06657251283842623\n",
      "train loss:0.0374375228315203\n",
      "train loss:0.014982234062940079\n",
      "train loss:0.02955856922985458\n",
      "train loss:0.014412133558481834\n",
      "train loss:0.07770167104358963\n",
      "train loss:0.03101449468295576\n",
      "train loss:0.03316866572824653\n",
      "train loss:0.03953881938088989\n",
      "train loss:0.05402264135586202\n",
      "train loss:0.1502874514884842\n",
      "train loss:0.038736530322241516\n",
      "train loss:0.0693357737098045\n",
      "train loss:0.11436793909778055\n",
      "train loss:0.03371405222531909\n",
      "train loss:0.041742655376298926\n",
      "train loss:0.016117293611998408\n",
      "train loss:0.04248482278858383\n",
      "train loss:0.04255940375440737\n",
      "train loss:0.03794432032987959\n",
      "train loss:0.10030106986865008\n",
      "train loss:0.03180258614763142\n",
      "train loss:0.05633509684855064\n",
      "train loss:0.04264355159817871\n",
      "train loss:0.026354778955155686\n",
      "train loss:0.09246621004916936\n",
      "train loss:0.0695358281807643\n",
      "train loss:0.06444789890011021\n",
      "train loss:0.019354601755815267\n",
      "train loss:0.007990831033215028\n",
      "train loss:0.019482961363127455\n",
      "train loss:0.021364970571514055\n",
      "train loss:0.04003026150422704\n",
      "train loss:0.06957681591022688\n",
      "train loss:0.008991281328802532\n",
      "train loss:0.03350573229158984\n",
      "train loss:0.04764253589329503\n",
      "train loss:0.0336174830775335\n",
      "train loss:0.04896575804057893\n",
      "train loss:0.07022894670358473\n",
      "train loss:0.06241518824469603\n",
      "train loss:0.035215963071311925\n",
      "train loss:0.023736548306191065\n",
      "train loss:0.021223569933136666\n",
      "train loss:0.07146581479563482\n",
      "train loss:0.017677164847071235\n",
      "train loss:0.06850665585457132\n",
      "train loss:0.08440835680087704\n",
      "train loss:0.043952184395321794\n",
      "train loss:0.018838623785552965\n",
      "train loss:0.05323432392407312\n",
      "train loss:0.030962428245698347\n",
      "train loss:0.038826531901063006\n",
      "train loss:0.11554232704956721\n",
      "train loss:0.046095322139367345\n",
      "train loss:0.006551566000087557\n",
      "train loss:0.11096562925357346\n",
      "train loss:0.009606179482741025\n",
      "train loss:0.06774108636672926\n",
      "train loss:0.046775032383892336\n",
      "train loss:0.03956557061357507\n",
      "train loss:0.06105557126022204\n",
      "train loss:0.051095006221409944\n",
      "train loss:0.07202636089033271\n",
      "train loss:0.052204645978131674\n",
      "train loss:0.05484026062486581\n",
      "train loss:0.009871599872514333\n",
      "train loss:0.0227530647680103\n",
      "train loss:0.06905474462425101\n",
      "train loss:0.0339097004785796\n",
      "train loss:0.04649336945973154\n",
      "train loss:0.05956837208537379\n",
      "train loss:0.023521743566952878\n",
      "train loss:0.03376690388126109\n",
      "train loss:0.04118026678197419\n",
      "train loss:0.050243116802933196\n",
      "train loss:0.17151828940529143\n",
      "train loss:0.06909223034867122\n",
      "train loss:0.04446808425004755\n",
      "train loss:0.016381816841722695\n",
      "train loss:0.0795159591471967\n",
      "train loss:0.028425239072959747\n",
      "train loss:0.03241559795472234\n",
      "train loss:0.08481088426559952\n",
      "train loss:0.05004091637963121\n",
      "train loss:0.06221013640355607\n",
      "train loss:0.15746778608826667\n",
      "train loss:0.11481210269798657\n",
      "train loss:0.0776745966978106\n",
      "train loss:0.009435693106530156\n",
      "train loss:0.02941490055375608\n",
      "train loss:0.027912624139532886\n",
      "train loss:0.031016666850008714\n",
      "train loss:0.040415863429631216\n",
      "train loss:0.0638680381591949\n",
      "train loss:0.022851246139297524\n",
      "train loss:0.07713954882308446\n",
      "train loss:0.09528282573056839\n",
      "train loss:0.02102040985965659\n",
      "train loss:0.014810349096488644\n",
      "train loss:0.01902640837612115\n",
      "train loss:0.02613073040163132\n",
      "train loss:0.044889663927854845\n",
      "train loss:0.05176252772009238\n",
      "train loss:0.02788967684640372\n",
      "train loss:0.03818676572941481\n",
      "train loss:0.02325877083485863\n",
      "train loss:0.05809776784827227\n",
      "train loss:0.030108905125347182\n",
      "train loss:0.03126295648473196\n",
      "train loss:0.0518795419144621\n",
      "train loss:0.018710662940212328\n",
      "train loss:0.0790588495781585\n",
      "train loss:0.07828301099290283\n",
      "train loss:0.11802878977796954\n",
      "train loss:0.05561333043511754\n",
      "train loss:0.02411391166191826\n",
      "train loss:0.03330992346379906\n",
      "train loss:0.013428138032178212\n",
      "train loss:0.02233937419252265\n",
      "train loss:0.032709508690923685\n",
      "train loss:0.0638683660470807\n",
      "train loss:0.0570335917845345\n",
      "train loss:0.07854844094400726\n",
      "train loss:0.05692092272971916\n",
      "train loss:0.025870180249707584\n",
      "train loss:0.011920550873990719\n",
      "train loss:0.09703205026251799\n",
      "train loss:0.09672496163381793\n",
      "train loss:0.06185837033116018\n",
      "train loss:0.03733084172080017\n",
      "train loss:0.02902329232974431\n",
      "train loss:0.049960282692606925\n",
      "train loss:0.03792280203459592\n",
      "train loss:0.08465771904538055\n",
      "train loss:0.07891414280073067\n",
      "train loss:0.04025926097473015\n",
      "train loss:0.02215098509593498\n",
      "train loss:0.03413708939287998\n",
      "train loss:0.040349715093464786\n",
      "train loss:0.026903685668711073\n",
      "train loss:0.05342076283094579\n",
      "train loss:0.08784112209472361\n",
      "train loss:0.029734089326767153\n",
      "train loss:0.01363386273420226\n",
      "train loss:0.05764396523567147\n",
      "train loss:0.06863882631070509\n",
      "train loss:0.05863287174780354\n",
      "train loss:0.11458897571700719\n",
      "train loss:0.03549643543523309\n",
      "train loss:0.0653926852086158\n",
      "train loss:0.05717611262397788\n",
      "train loss:0.16659519938786174\n",
      "train loss:0.051365255635210945\n",
      "train loss:0.03976402574784787\n",
      "train loss:0.012600587518934295\n",
      "train loss:0.04533777941600414\n",
      "train loss:0.0646440470015443\n",
      "train loss:0.0426110614247191\n",
      "train loss:0.053050652409793446\n",
      "train loss:0.03239419719543062\n",
      "train loss:0.016452340655526466\n",
      "train loss:0.031880978779313694\n",
      "train loss:0.01859862412628482\n",
      "train loss:0.04922410790364978\n",
      "train loss:0.04955072223185532\n",
      "train loss:0.04780016304785173\n",
      "train loss:0.07969008741667322\n",
      "train loss:0.024622697622923035\n",
      "train loss:0.037077828609350896\n",
      "train loss:0.020222592781400987\n",
      "train loss:0.014482005898304067\n",
      "train loss:0.0374480735794345\n",
      "train loss:0.07628065672546341\n",
      "train loss:0.034460917920597474\n",
      "train loss:0.02844509401955138\n",
      "train loss:0.03397738877174764\n",
      "train loss:0.03049968442273038\n",
      "train loss:0.01319055312275212\n",
      "train loss:0.02646729146683378\n",
      "train loss:0.02648700372144122\n",
      "train loss:0.018483028697865774\n",
      "train loss:0.10872252310760572\n",
      "train loss:0.04321365758568934\n",
      "train loss:0.023910641457877052\n",
      "train loss:0.03758651005873074\n",
      "train loss:0.04111123899657148\n",
      "train loss:0.040278213777855315\n",
      "train loss:0.04064642400787496\n",
      "train loss:0.03432206461181337\n",
      "train loss:0.07513653425370548\n",
      "train loss:0.04079849110738996\n",
      "train loss:0.05724733208595558\n",
      "train loss:0.07391879682486809\n",
      "train loss:0.0603142317750918\n",
      "train loss:0.016943815689100496\n",
      "train loss:0.07714768991923102\n",
      "train loss:0.0921798525663651\n",
      "train loss:0.05035517569948038\n",
      "train loss:0.041443037442436576\n",
      "train loss:0.0305207986954139\n",
      "train loss:0.0917313659044815\n",
      "train loss:0.03208977348538086\n",
      "train loss:0.04639843464942649\n",
      "train loss:0.014958158120120538\n",
      "train loss:0.07411063956593206\n",
      "train loss:0.04130351872046301\n",
      "train loss:0.03932050653366932\n",
      "train loss:0.04219960893831013\n",
      "train loss:0.07777622959646752\n",
      "train loss:0.05550544571498456\n",
      "train loss:0.017178189837794035\n",
      "train loss:0.07434499641679036\n",
      "train loss:0.022970205980256703\n",
      "train loss:0.04009666305973575\n",
      "train loss:0.04726629426114456\n",
      "train loss:0.05196836472810516\n",
      "train loss:0.04993172019366571\n",
      "train loss:0.05308132044599081\n",
      "train loss:0.07288654624086807\n",
      "train loss:0.0603760404617695\n",
      "train loss:0.051572273790732516\n",
      "train loss:0.009721552513371819\n",
      "train loss:0.015779620230275713\n",
      "train loss:0.06572816919629071\n",
      "train loss:0.044130420835755774\n",
      "train loss:0.05636274375624778\n",
      "train loss:0.05376394308520365\n",
      "train loss:0.040058182886201284\n",
      "train loss:0.0055076033509856605\n",
      "train loss:0.06782613816986915\n",
      "train loss:0.051754175992068045\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.027363781773640863\n",
      "train loss:0.02367016854407606\n",
      "train loss:0.06977250810334772\n",
      "train loss:0.013435311959970624\n",
      "train loss:0.04920745260848358\n",
      "train loss:0.025647951981285177\n",
      "train loss:0.08500053514739556\n",
      "train loss:0.021211167381471007\n",
      "train loss:0.012667517119075327\n",
      "train loss:0.04675138602525557\n",
      "train loss:0.027251515108760026\n",
      "train loss:0.012528586561705501\n",
      "train loss:0.07544016563813978\n",
      "train loss:0.06122314454259778\n",
      "train loss:0.10179348053049059\n",
      "train loss:0.040287510295638235\n",
      "train loss:0.016882384745203288\n",
      "train loss:0.039479569040979004\n",
      "train loss:0.04145200116650427\n",
      "train loss:0.01976481890955883\n",
      "train loss:0.0373076990889514\n",
      "train loss:0.009997088796779057\n",
      "train loss:0.05868013900503169\n",
      "train loss:0.013256878290092618\n",
      "train loss:0.024421452313229407\n",
      "train loss:0.029272630783219348\n",
      "train loss:0.01211200616249643\n",
      "train loss:0.041471118879295464\n",
      "train loss:0.1057578412256105\n",
      "train loss:0.08347020240322321\n",
      "train loss:0.04692121972774104\n",
      "train loss:0.05318770824218297\n",
      "train loss:0.020702249156999683\n",
      "train loss:0.02679867236226828\n",
      "train loss:0.03213020728098995\n",
      "train loss:0.013706061573990614\n",
      "train loss:0.0464500340751852\n",
      "train loss:0.10589021469962111\n",
      "train loss:0.023489145703368908\n",
      "train loss:0.030217505334184325\n",
      "train loss:0.03557804130890151\n",
      "train loss:0.07683959784508751\n",
      "train loss:0.04943624270763922\n",
      "train loss:0.04922871932301722\n",
      "train loss:0.02170781290743987\n",
      "train loss:0.023182810794776413\n",
      "train loss:0.02774168518128081\n",
      "train loss:0.037704717906711586\n",
      "train loss:0.04362484536758091\n",
      "train loss:0.03698095691355063\n",
      "train loss:0.051896106125411734\n",
      "train loss:0.017347424076300216\n",
      "train loss:0.07526496067855487\n",
      "train loss:0.033503022180850266\n",
      "train loss:0.03568203049178956\n",
      "train loss:0.024546446991358755\n",
      "train loss:0.026504699070565886\n",
      "train loss:0.0451237909460469\n",
      "train loss:0.028014945692956383\n",
      "train loss:0.03022837940439091\n",
      "train loss:0.06827681533023691\n",
      "train loss:0.06602065861100274\n",
      "train loss:0.017544742185020817\n",
      "train loss:0.04036867082899573\n",
      "train loss:0.01886157102992399\n",
      "train loss:0.015206855606181601\n",
      "train loss:0.06063657260826718\n",
      "train loss:0.056355207140231664\n",
      "train loss:0.012191514769374846\n",
      "train loss:0.04842663922398816\n",
      "train loss:0.0744819412648323\n",
      "train loss:0.018646030527834014\n",
      "train loss:0.06706485726405498\n",
      "train loss:0.029402888874613523\n",
      "train loss:0.08977810616054184\n",
      "train loss:0.06652778867031328\n",
      "train loss:0.08219353884268416\n",
      "train loss:0.03500905581111765\n",
      "train loss:0.047261926138569256\n",
      "train loss:0.06356606741995997\n",
      "train loss:0.06403986690719762\n",
      "train loss:0.020206524738967\n",
      "train loss:0.020584376825621434\n",
      "train loss:0.016020984797880947\n",
      "train loss:0.023730526334832424\n",
      "train loss:0.05361730056609693\n",
      "train loss:0.05593784422197123\n",
      "train loss:0.0233036873650324\n",
      "train loss:0.010947721982331269\n",
      "train loss:0.008362166773009681\n",
      "train loss:0.029745982947032998\n",
      "train loss:0.01654111619619297\n",
      "train loss:0.01294536168759287\n",
      "train loss:0.02778367199017405\n",
      "train loss:0.027336330982196646\n",
      "train loss:0.12294546946687586\n",
      "train loss:0.024391033161608955\n",
      "train loss:0.0650838645051876\n",
      "train loss:0.04280293912747888\n",
      "train loss:0.07392334116218485\n",
      "train loss:0.013346879592272078\n",
      "train loss:0.08941131831210988\n",
      "train loss:0.009292152087736712\n",
      "train loss:0.02398874607835177\n",
      "train loss:0.04566465768155967\n",
      "train loss:0.029139034472968187\n",
      "train loss:0.05765859121014959\n",
      "train loss:0.016001702240256262\n",
      "train loss:0.027581916272923966\n",
      "train loss:0.03028308457141552\n",
      "train loss:0.01582822308276378\n",
      "train loss:0.02826585709228189\n",
      "train loss:0.0207576637266909\n",
      "train loss:0.06748575375700887\n",
      "train loss:0.03684613660049313\n",
      "train loss:0.017200816584745707\n",
      "train loss:0.009524841236191545\n",
      "train loss:0.02507910305630799\n",
      "train loss:0.023168038113010783\n",
      "train loss:0.01587086166993667\n",
      "train loss:0.020594975391583312\n",
      "train loss:0.027972753751812487\n",
      "train loss:0.02845370730563243\n",
      "train loss:0.09880426413185264\n",
      "train loss:0.050178312087992595\n",
      "train loss:0.05283221426408695\n",
      "train loss:0.02773230682916367\n",
      "train loss:0.01288224949862686\n",
      "train loss:0.10300062681541367\n",
      "train loss:0.013843420000943659\n",
      "train loss:0.049334513309749944\n",
      "train loss:0.027479906717387675\n",
      "train loss:0.05740364534490327\n",
      "train loss:0.09970763682823414\n",
      "train loss:0.01793745616080846\n",
      "train loss:0.01009643937432533\n",
      "train loss:0.05057588719441815\n",
      "train loss:0.006002968978177199\n",
      "train loss:0.11564161661835237\n",
      "train loss:0.0110545660429929\n",
      "train loss:0.14674524096359687\n",
      "train loss:0.06854789963100504\n",
      "train loss:0.028024515690741783\n",
      "train loss:0.046316038939929076\n",
      "train loss:0.09508318617383464\n",
      "train loss:0.036960562790637974\n",
      "train loss:0.026892626970839557\n",
      "train loss:0.0218920899214081\n",
      "train loss:0.04876710937609987\n",
      "train loss:0.018564524539640078\n",
      "train loss:0.06720209133202164\n",
      "train loss:0.029267309658806973\n",
      "train loss:0.012596600540114434\n",
      "train loss:0.03961902433615762\n",
      "train loss:0.03175552571654381\n",
      "train loss:0.050590516088554686\n",
      "train loss:0.03739137354463843\n",
      "train loss:0.08917306345971307\n",
      "train loss:0.0633994840293388\n",
      "train loss:0.10412349201010572\n",
      "train loss:0.04658129254021444\n",
      "train loss:0.05314916195566287\n",
      "train loss:0.1272442700951584\n",
      "train loss:0.04131733388880577\n",
      "train loss:0.02801381898511779\n",
      "train loss:0.08619209509109606\n",
      "train loss:0.032368996561142956\n",
      "train loss:0.01850230570758707\n",
      "train loss:0.023424741898184883\n",
      "train loss:0.04220192790308239\n",
      "train loss:0.038913302605519666\n",
      "train loss:0.06719952091629787\n",
      "train loss:0.048666450276629025\n",
      "train loss:0.016293672538752677\n",
      "train loss:0.045809126419819365\n",
      "train loss:0.025483690609348138\n",
      "train loss:0.04073843925627116\n",
      "train loss:0.02402162635676628\n",
      "train loss:0.08658374602543562\n",
      "train loss:0.06619307562454232\n",
      "train loss:0.03080056283072846\n",
      "train loss:0.020130334225696673\n",
      "train loss:0.022318211881120025\n",
      "train loss:0.03135862431044336\n",
      "train loss:0.09050264929938502\n",
      "train loss:0.08097912613808296\n",
      "train loss:0.028226044365267034\n",
      "train loss:0.01780873228206448\n",
      "train loss:0.07066005174176387\n",
      "train loss:0.06574196728330771\n",
      "train loss:0.049093399247607736\n",
      "train loss:0.02733318341244184\n",
      "train loss:0.016135085992166086\n",
      "train loss:0.02118244464569555\n",
      "train loss:0.04847990134489238\n",
      "train loss:0.03135416736038408\n",
      "train loss:0.019034822260441314\n",
      "train loss:0.010360418588309219\n",
      "train loss:0.022499914998958176\n",
      "train loss:0.00717327542058197\n",
      "train loss:0.029587228173109437\n",
      "train loss:0.12226734473579146\n",
      "train loss:0.11617909494593395\n",
      "train loss:0.02660256427626607\n",
      "train loss:0.015609552785410163\n",
      "train loss:0.0623972912727309\n",
      "train loss:0.0593916439541402\n",
      "=== epoch:4, train acc:0.985, test acc:0.98 ===\n",
      "train loss:0.016865087229635155\n",
      "train loss:0.012088723554308211\n",
      "train loss:0.02480862802371185\n",
      "train loss:0.030793398318302696\n",
      "train loss:0.06902605445699972\n",
      "train loss:0.013189902121109022\n",
      "train loss:0.018812021946281673\n",
      "train loss:0.04758974647724013\n",
      "train loss:0.052778844161128505\n",
      "train loss:0.025217509259245867\n",
      "train loss:0.011201803766707184\n",
      "train loss:0.09414501651406601\n",
      "train loss:0.13196246080254118\n",
      "train loss:0.012404986907634035\n",
      "train loss:0.09023726499247749\n",
      "train loss:0.013457609265265536\n",
      "train loss:0.006403138443921546\n",
      "train loss:0.1304615418095184\n",
      "train loss:0.022022187665611197\n",
      "train loss:0.05564794743698891\n",
      "train loss:0.007659511922407839\n",
      "train loss:0.00846335984402976\n",
      "train loss:0.04458723542774184\n",
      "train loss:0.01617425773793992\n",
      "train loss:0.0229318250419985\n",
      "train loss:0.06136272421594093\n",
      "train loss:0.01402647648176169\n",
      "train loss:0.09281959356041035\n",
      "train loss:0.03124764384163121\n",
      "train loss:0.099767031075925\n",
      "train loss:0.049865046231431315\n",
      "train loss:0.05244345255281693\n",
      "train loss:0.023823735305952828\n",
      "train loss:0.08562661901632568\n",
      "train loss:0.01646623217536654\n",
      "train loss:0.03379087637739121\n",
      "train loss:0.048283630259718276\n",
      "train loss:0.026524743909439947\n",
      "train loss:0.16824181816805364\n",
      "train loss:0.0162342742477851\n",
      "train loss:0.05760022147063471\n",
      "train loss:0.009648827384347396\n",
      "train loss:0.00823920167986883\n",
      "train loss:0.007493746491983805\n",
      "train loss:0.030985265715268096\n",
      "train loss:0.01855951336711688\n",
      "train loss:0.019999995412824757\n",
      "train loss:0.040757784902482115\n",
      "train loss:0.1088085469978743\n",
      "train loss:0.019165471615399596\n",
      "train loss:0.07761923533773994\n",
      "train loss:0.053802376950112946\n",
      "train loss:0.03109864327670782\n",
      "train loss:0.10024738659263038\n",
      "train loss:0.06905631486130985\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.030918882066081007\n",
      "train loss:0.03190454303423036\n",
      "train loss:0.03371099929459438\n",
      "train loss:0.03747216493726874\n",
      "train loss:0.0448758854135286\n",
      "train loss:0.028988132116827613\n",
      "train loss:0.01664579908077961\n",
      "train loss:0.017541717784613883\n",
      "train loss:0.02664585099795377\n",
      "train loss:0.07202880666602393\n",
      "train loss:0.043400026507621876\n",
      "train loss:0.01506667209450083\n",
      "train loss:0.029161762153390856\n",
      "train loss:0.03308614831590652\n",
      "train loss:0.019667212461379265\n",
      "train loss:0.0429642425457887\n",
      "train loss:0.015489054468872639\n",
      "train loss:0.02153639675410768\n",
      "train loss:0.01674373424122902\n",
      "train loss:0.08051172921943138\n",
      "train loss:0.019390080340501003\n",
      "train loss:0.02680471275313459\n",
      "train loss:0.040187469767152845\n",
      "train loss:0.07486855390357769\n",
      "train loss:0.009831396104887726\n",
      "train loss:0.053850617854837315\n",
      "train loss:0.12607934577083366\n",
      "train loss:0.02741760266271817\n",
      "train loss:0.04926810966470319\n",
      "train loss:0.023143790504277346\n",
      "train loss:0.11969695868809022\n",
      "train loss:0.03215277977785108\n",
      "train loss:0.018328001543667014\n",
      "train loss:0.038343273994876845\n",
      "train loss:0.014923425748643231\n",
      "train loss:0.034489864491310376\n",
      "train loss:0.08080679249756104\n",
      "train loss:0.08636727458276777\n",
      "train loss:0.10100594607499631\n",
      "train loss:0.04037292628127628\n",
      "train loss:0.03848536623807325\n",
      "train loss:0.009689748915182823\n",
      "train loss:0.053619205233280814\n",
      "train loss:0.024368050897803542\n",
      "train loss:0.02762626299107776\n",
      "train loss:0.05859319944913913\n",
      "train loss:0.04093236893202791\n",
      "train loss:0.02290850379494827\n",
      "train loss:0.031259046804626024\n",
      "train loss:0.07588787124730584\n",
      "train loss:0.043253418030539524\n",
      "train loss:0.03090194700562633\n",
      "train loss:0.031014120526363168\n",
      "train loss:0.051123975429896475\n",
      "train loss:0.0380159791876394\n",
      "train loss:0.02636620241010713\n",
      "train loss:0.09557926488335175\n",
      "train loss:0.06103155695276466\n",
      "train loss:0.035764697974482916\n",
      "train loss:0.053749105901245695\n",
      "train loss:0.027608359085481537\n",
      "train loss:0.03243574400364438\n",
      "train loss:0.0886352997833386\n",
      "train loss:0.016020630389104666\n",
      "train loss:0.0873085843689745\n",
      "train loss:0.04464442028951704\n",
      "train loss:0.08985150029890329\n",
      "train loss:0.029713161430309533\n",
      "train loss:0.07403893375305232\n",
      "train loss:0.024959345617340395\n",
      "train loss:0.026611120945013608\n",
      "train loss:0.05574363909334445\n",
      "train loss:0.01610977232975123\n",
      "train loss:0.029361916120789856\n",
      "train loss:0.020680202741902264\n",
      "train loss:0.031790298047913716\n",
      "train loss:0.00975149366366495\n",
      "train loss:0.06129554766645488\n",
      "train loss:0.09612390068610989\n",
      "train loss:0.01790487257560674\n",
      "train loss:0.06421812420627819\n",
      "train loss:0.050264888595939625\n",
      "train loss:0.012962302051122873\n",
      "train loss:0.011281738685347757\n",
      "train loss:0.012521722709686638\n",
      "train loss:0.0794654035051792\n",
      "train loss:0.03209616649228552\n",
      "train loss:0.052249445036620816\n",
      "train loss:0.03796260390718163\n",
      "train loss:0.04211954861641436\n",
      "train loss:0.012610207407298948\n",
      "train loss:0.028081952177470913\n",
      "train loss:0.016608450613676894\n",
      "train loss:0.0362137771115508\n",
      "train loss:0.038324647259792094\n",
      "train loss:0.04647915732434615\n",
      "train loss:0.03761028397396717\n",
      "train loss:0.07359990286923418\n",
      "train loss:0.012571846652443971\n",
      "train loss:0.05509266566991983\n",
      "train loss:0.02331275336200728\n",
      "train loss:0.04263663776542539\n",
      "train loss:0.03012102763711594\n",
      "train loss:0.03697033137232194\n",
      "train loss:0.042999371002171084\n",
      "train loss:0.008753683769555326\n",
      "train loss:0.07083971446968111\n",
      "train loss:0.03246602375837393\n",
      "train loss:0.00992130780205775\n",
      "train loss:0.030706113677909475\n",
      "train loss:0.004803329913984729\n",
      "train loss:0.07901420839537475\n",
      "train loss:0.0607969644787151\n",
      "train loss:0.052258242371880446\n",
      "train loss:0.018290983378714563\n",
      "train loss:0.013888241235810521\n",
      "train loss:0.013808747060900598\n",
      "train loss:0.057493195816177345\n",
      "train loss:0.019489543108831803\n",
      "train loss:0.06306756902384343\n",
      "train loss:0.07953087419624837\n",
      "train loss:0.010228552040606414\n",
      "train loss:0.01813202051075065\n",
      "train loss:0.025091357034602062\n",
      "train loss:0.02177164227175858\n",
      "train loss:0.01011756092385481\n",
      "train loss:0.09063730843436714\n",
      "train loss:0.008807983929968555\n",
      "train loss:0.014775646659086204\n",
      "train loss:0.0499390953016974\n",
      "train loss:0.014383466213673772\n",
      "train loss:0.02978442604051608\n",
      "train loss:0.005095964102566383\n",
      "train loss:0.054567537586248986\n",
      "train loss:0.05098991059546441\n",
      "train loss:0.02291798839016284\n",
      "train loss:0.025989856729107724\n",
      "train loss:0.030444350699302066\n",
      "train loss:0.011787769416495423\n",
      "train loss:0.008724461068423743\n",
      "train loss:0.07381986432272031\n",
      "train loss:0.00937125733634772\n",
      "train loss:0.009260646763401915\n",
      "train loss:0.07380696436912441\n",
      "train loss:0.026542579912355743\n",
      "train loss:0.03600275208951167\n",
      "train loss:0.007849416692678414\n",
      "train loss:0.017355593957270824\n",
      "train loss:0.04977280894983606\n",
      "train loss:0.024197483997022963\n",
      "train loss:0.017152696011137804\n",
      "train loss:0.016603429169004726\n",
      "train loss:0.029908422088789667\n",
      "train loss:0.03881836153384628\n",
      "train loss:0.030699643115461427\n",
      "train loss:0.03768478089766217\n",
      "train loss:0.018794305099992557\n",
      "train loss:0.06157202077769302\n",
      "train loss:0.03222655624411588\n",
      "train loss:0.008103701974130293\n",
      "train loss:0.11508035253677149\n",
      "train loss:0.01765115438625514\n",
      "train loss:0.0404350889665671\n",
      "train loss:0.041381943594084\n",
      "train loss:0.013343571395217347\n",
      "train loss:0.014857133449213513\n",
      "train loss:0.031775333752455295\n",
      "train loss:0.02391035743806198\n",
      "train loss:0.028393764869249973\n",
      "train loss:0.019295342308935644\n",
      "train loss:0.039988495682286025\n",
      "train loss:0.025346751921472017\n",
      "train loss:0.014095621506528362\n",
      "train loss:0.018938706384271004\n",
      "train loss:0.016014392274871402\n",
      "train loss:0.03181711380130031\n",
      "train loss:0.013026868089667337\n",
      "train loss:0.022998883384040547\n",
      "train loss:0.023694496143367983\n",
      "train loss:0.018442920121953702\n",
      "train loss:0.06684373784327308\n",
      "train loss:0.018516108042100996\n",
      "train loss:0.022486725149753802\n",
      "train loss:0.0478888571332964\n",
      "train loss:0.053423084685867074\n",
      "train loss:0.04578691099255593\n",
      "train loss:0.06891054219407747\n",
      "train loss:0.04645408025376714\n",
      "train loss:0.04083239402924467\n",
      "train loss:0.01772599498202671\n",
      "train loss:0.02766631324093524\n",
      "train loss:0.09279457279427868\n",
      "train loss:0.1356548448868451\n",
      "train loss:0.04402374580970185\n",
      "train loss:0.07523640868804016\n",
      "train loss:0.06403647750147154\n",
      "train loss:0.05054901196867925\n",
      "train loss:0.019227257380966662\n",
      "train loss:0.04337892422482652\n",
      "train loss:0.012656791730563674\n",
      "train loss:0.09276969035828461\n",
      "train loss:0.020815540237863094\n",
      "train loss:0.032316093137158816\n",
      "train loss:0.021180242287940763\n",
      "train loss:0.015845212957045263\n",
      "train loss:0.004489866232496881\n",
      "train loss:0.03665757159784596\n",
      "train loss:0.03499912765412698\n",
      "train loss:0.01014745298436378\n",
      "train loss:0.02580098701017155\n",
      "train loss:0.02092853029887374\n",
      "train loss:0.02264962031170091\n",
      "train loss:0.017496431864808183\n",
      "train loss:0.00921799279833616\n",
      "train loss:0.021148565104777944\n",
      "train loss:0.02667952783303132\n",
      "train loss:0.013288266332712337\n",
      "train loss:0.010597419874102256\n",
      "train loss:0.015027897863254978\n",
      "train loss:0.01508284370014432\n",
      "train loss:0.009938628644698692\n",
      "train loss:0.015897192639298317\n",
      "train loss:0.03683890612730316\n",
      "train loss:0.0047577924711038775\n",
      "train loss:0.009186858153727216\n",
      "train loss:0.031767503613433244\n",
      "train loss:0.06652956222501612\n",
      "train loss:0.03713524578119749\n",
      "train loss:0.02665446597767844\n",
      "train loss:0.010993516067168163\n",
      "train loss:0.08838915337525416\n",
      "train loss:0.03354392206132329\n",
      "train loss:0.00941574085698806\n",
      "train loss:0.03989624159230031\n",
      "train loss:0.014968652196210505\n",
      "train loss:0.09152784621474616\n",
      "train loss:0.018503275282710212\n",
      "train loss:0.007683188046483238\n",
      "train loss:0.019432882928952372\n",
      "train loss:0.11000953747667225\n",
      "train loss:0.03382996928189795\n",
      "train loss:0.024900792082153962\n",
      "train loss:0.05443537465275274\n",
      "train loss:0.0884541375792436\n",
      "train loss:0.034472806207934886\n",
      "train loss:0.008046462261710482\n",
      "train loss:0.016476712718066316\n",
      "train loss:0.03265070374246644\n",
      "train loss:0.06608053956981251\n",
      "train loss:0.015734551888223983\n",
      "train loss:0.03067675397346058\n",
      "train loss:0.016772264282045746\n",
      "train loss:0.01884691998085254\n",
      "train loss:0.05013451079312259\n",
      "train loss:0.011633154175676001\n",
      "train loss:0.1058284642315634\n",
      "train loss:0.033345795235439374\n",
      "train loss:0.022740136487214856\n",
      "train loss:0.024500897731831547\n",
      "train loss:0.018526956426936095\n",
      "train loss:0.014610221611368455\n",
      "train loss:0.05190472033818287\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.029117062466183806\n",
      "train loss:0.02118090646432345\n",
      "train loss:0.028161349692915755\n",
      "train loss:0.023423137565314625\n",
      "train loss:0.02028706152533414\n",
      "train loss:0.04205752434373387\n",
      "train loss:0.06163665986346363\n",
      "train loss:0.02590197916495747\n",
      "train loss:0.015098187961464013\n",
      "train loss:0.0264912355923773\n",
      "train loss:0.01586069056973227\n",
      "train loss:0.030293933768931032\n",
      "train loss:0.010952514623914658\n",
      "train loss:0.027350883682242682\n",
      "train loss:0.029670899934760898\n",
      "train loss:0.03688044544107951\n",
      "train loss:0.04715860997350741\n",
      "train loss:0.08564572412335453\n",
      "train loss:0.03698521721648934\n",
      "train loss:0.0733668466262178\n",
      "train loss:0.06585898924051022\n",
      "train loss:0.05330162989807881\n",
      "train loss:0.0024547687893589553\n",
      "train loss:0.08410336252619159\n",
      "train loss:0.030695927874927906\n",
      "train loss:0.07345461171337607\n",
      "train loss:0.007034183417476563\n",
      "train loss:0.05906906734301405\n",
      "train loss:0.026509816900157065\n",
      "train loss:0.03477900370914031\n",
      "train loss:0.05109373932037948\n",
      "train loss:0.027631162092340608\n",
      "train loss:0.030368716710042442\n",
      "train loss:0.01298397727673541\n",
      "train loss:0.03265145652081763\n",
      "train loss:0.016702022611045184\n",
      "train loss:0.012593420399494022\n",
      "train loss:0.02461319839312032\n",
      "train loss:0.012905882354248301\n",
      "train loss:0.022447703680575967\n",
      "train loss:0.017187200402597417\n",
      "train loss:0.02335514531796163\n",
      "train loss:0.02039337725679467\n",
      "train loss:0.016465543582685305\n",
      "train loss:0.017585738567191703\n",
      "train loss:0.014112019582143236\n",
      "train loss:0.010816173174785604\n",
      "train loss:0.039543088942833766\n",
      "train loss:0.07007120420925932\n",
      "train loss:0.05260250783346567\n",
      "train loss:0.04853466709767959\n",
      "train loss:0.0343991531348622\n",
      "train loss:0.004464771895842202\n",
      "train loss:0.03751784921012261\n",
      "train loss:0.048708149627811725\n",
      "train loss:0.008313913918866518\n",
      "train loss:0.03345693657292282\n",
      "train loss:0.015551851434688617\n",
      "train loss:0.014587165045285289\n",
      "train loss:0.04053243618467504\n",
      "train loss:0.07130888733675388\n",
      "train loss:0.012388732457115824\n",
      "train loss:0.021774817247412797\n",
      "train loss:0.12517419654755185\n",
      "train loss:0.17544236730677248\n",
      "train loss:0.03350239359416296\n",
      "train loss:0.061086813706465105\n",
      "train loss:0.028043843623028298\n",
      "train loss:0.07431327528145432\n",
      "train loss:0.04386629663470239\n",
      "train loss:0.015596017578062747\n",
      "train loss:0.015103727317303892\n",
      "train loss:0.015657079588405735\n",
      "train loss:0.010357428417165256\n",
      "train loss:0.0056637509572463616\n",
      "train loss:0.008334749630222677\n",
      "train loss:0.02211744524486928\n",
      "train loss:0.011033441875978246\n",
      "train loss:0.018659333473776216\n",
      "train loss:0.06989138135728196\n",
      "train loss:0.014899165916060381\n",
      "train loss:0.009639849783276332\n",
      "train loss:0.05685477868869944\n",
      "train loss:0.06906840364908538\n",
      "train loss:0.03426925485352097\n",
      "train loss:0.0531688501939683\n",
      "train loss:0.009083947016249901\n",
      "train loss:0.015972197206591498\n",
      "train loss:0.043090481777676874\n",
      "train loss:0.02180566033112742\n",
      "train loss:0.014591794938225\n",
      "train loss:0.020219879134151193\n",
      "train loss:0.011583365394152174\n",
      "train loss:0.0397216572983425\n",
      "train loss:0.0434304567306589\n",
      "train loss:0.01197551294703584\n",
      "train loss:0.03206140121952721\n",
      "train loss:0.02192856255201745\n",
      "train loss:0.0643615257853765\n",
      "train loss:0.0071619514944037945\n",
      "train loss:0.0164452216490045\n",
      "train loss:0.03282125867085318\n",
      "train loss:0.0030077074025292205\n",
      "train loss:0.02486980498356231\n",
      "train loss:0.025626256126020996\n",
      "train loss:0.06710593038610929\n",
      "train loss:0.010954641076541245\n",
      "train loss:0.01577958243603522\n",
      "train loss:0.010009482344410545\n",
      "train loss:0.02023483608806155\n",
      "train loss:0.03675051913063988\n",
      "train loss:0.021936549726475914\n",
      "train loss:0.017031913858513867\n",
      "train loss:0.05174656236381565\n",
      "train loss:0.007931894614348916\n",
      "train loss:0.03728362002934201\n",
      "train loss:0.009174345060776036\n",
      "train loss:0.011464432404770122\n",
      "train loss:0.02263270166165607\n",
      "train loss:0.08096971161892062\n",
      "train loss:0.03552586534196198\n",
      "train loss:0.050526739638250676\n",
      "train loss:0.006364776552746468\n",
      "train loss:0.01576355280225286\n",
      "train loss:0.014109251229500125\n",
      "train loss:0.011318715547535314\n",
      "train loss:0.013575870185755134\n",
      "train loss:0.01475697714185632\n",
      "train loss:0.013822372009541298\n",
      "train loss:0.04861230974576967\n",
      "train loss:0.026930174179225063\n",
      "train loss:0.04121265664943276\n",
      "train loss:0.06506695463791734\n",
      "train loss:0.040907318328876806\n",
      "train loss:0.0261270135469819\n",
      "train loss:0.043153793867496425\n",
      "train loss:0.030272456722256216\n",
      "train loss:0.02793923936016931\n",
      "train loss:0.059172122403645326\n",
      "train loss:0.02614058745793846\n",
      "train loss:0.043332624506824305\n",
      "train loss:0.00764206205339302\n",
      "train loss:0.016037619273811587\n",
      "train loss:0.022179178697330194\n",
      "train loss:0.06433732741659041\n",
      "train loss:0.04077961553235352\n",
      "train loss:0.02759183113545328\n",
      "train loss:0.025256901459075113\n",
      "train loss:0.014727155008337996\n",
      "train loss:0.012853398470242654\n",
      "train loss:0.1272772395183751\n",
      "train loss:0.02546613620403697\n",
      "train loss:0.014696824502535072\n",
      "train loss:0.019725870184536237\n",
      "train loss:0.012585490525185516\n",
      "train loss:0.03410081210099134\n",
      "train loss:0.06143827222556262\n",
      "train loss:0.057633396409574045\n",
      "train loss:0.11701637734188558\n",
      "train loss:0.07452733745201813\n",
      "train loss:0.03484793807550239\n",
      "train loss:0.01566973668689992\n",
      "train loss:0.03713575433117423\n",
      "train loss:0.05974300174426827\n",
      "train loss:0.015685240817655408\n",
      "train loss:0.06658942819760404\n",
      "train loss:0.017901577615576057\n",
      "train loss:0.0398515033749092\n",
      "train loss:0.01811746501229573\n",
      "train loss:0.01602427525717095\n",
      "train loss:0.019091142154767256\n",
      "train loss:0.05241311446085972\n",
      "train loss:0.0179953228630365\n",
      "train loss:0.17811085858729248\n",
      "train loss:0.02622132292553661\n",
      "train loss:0.014541039237521512\n",
      "train loss:0.02926685224595184\n",
      "train loss:0.012239514196388237\n",
      "train loss:0.009108102500204161\n",
      "train loss:0.0414469888166432\n",
      "train loss:0.02014052835363039\n",
      "train loss:0.020238740778173347\n",
      "train loss:0.018207684074459968\n",
      "train loss:0.023347787339427085\n",
      "train loss:0.018059117158617286\n",
      "train loss:0.06636032914405304\n",
      "train loss:0.031158755252595753\n",
      "train loss:0.012002949731662257\n",
      "train loss:0.03469215078133586\n",
      "train loss:0.04705928960025121\n",
      "train loss:0.014390218704889168\n",
      "train loss:0.05187618522959454\n",
      "train loss:0.022773004397484208\n",
      "train loss:0.0278716172270394\n",
      "train loss:0.016177270489338622\n",
      "train loss:0.06195916392095539\n",
      "train loss:0.05442200550248881\n",
      "train loss:0.027345778156080844\n",
      "train loss:0.007125390623951254\n",
      "train loss:0.0399036346763506\n",
      "train loss:0.10719362411458881\n",
      "train loss:0.022571432439599106\n",
      "train loss:0.030944949353562796\n",
      "train loss:0.0149988030050788\n",
      "train loss:0.017626418756775578\n",
      "train loss:0.03709483914648735\n",
      "train loss:0.04042137682668487\n",
      "train loss:0.008563312968142939\n",
      "train loss:0.03339454730897996\n",
      "train loss:0.08167567693225022\n",
      "train loss:0.010933498116575282\n",
      "train loss:0.01975877298151706\n",
      "train loss:0.022410657437010095\n",
      "train loss:0.07523686177929109\n",
      "train loss:0.0262375248963724\n",
      "train loss:0.03828032422002533\n",
      "train loss:0.01052034571972147\n",
      "train loss:0.04352658023626624\n",
      "train loss:0.11350702074091008\n",
      "train loss:0.006121093753664388\n",
      "train loss:0.014777101968500345\n",
      "train loss:0.018555856784066994\n",
      "train loss:0.004560884767609466\n",
      "train loss:0.01647249186513017\n",
      "train loss:0.03367271457051322\n",
      "train loss:0.01905697874552923\n",
      "train loss:0.0709133171668494\n",
      "train loss:0.0182293736030647\n",
      "train loss:0.01295335215273723\n",
      "train loss:0.03679785684266526\n",
      "train loss:0.021729835966891518\n",
      "train loss:0.019682847778514048\n",
      "train loss:0.08045964652427917\n",
      "train loss:0.01738838076175577\n",
      "train loss:0.034334550765697275\n",
      "train loss:0.03511656873883206\n",
      "train loss:0.03476458515727397\n",
      "train loss:0.04631552484084632\n",
      "train loss:0.021964416766814997\n",
      "train loss:0.005824313357808274\n",
      "train loss:0.08262669949918829\n",
      "train loss:0.008562079037826591\n",
      "train loss:0.06286324154417905\n",
      "train loss:0.00873253377508451\n",
      "train loss:0.026617249306327032\n",
      "train loss:0.060893673045491335\n",
      "train loss:0.017411283552405968\n",
      "train loss:0.02780635005001915\n",
      "train loss:0.009159399957624641\n",
      "train loss:0.02472081517669459\n",
      "train loss:0.01518042303610112\n",
      "train loss:0.06356823425704998\n",
      "train loss:0.037261418239198874\n",
      "train loss:0.009699200243310504\n",
      "train loss:0.03651741504658497\n",
      "train loss:0.04258842900255309\n",
      "train loss:0.022170747532875828\n",
      "train loss:0.008004927560891207\n",
      "train loss:0.06552438923170772\n",
      "train loss:0.019868152036163197\n",
      "train loss:0.05974216495404016\n",
      "train loss:0.006358532651313964\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.056398460362591434\n",
      "train loss:0.012215936557317317\n",
      "train loss:0.07428285808906938\n",
      "train loss:0.007162111808800158\n",
      "train loss:0.004276478101049141\n",
      "train loss:0.052645766830369006\n",
      "train loss:0.11781278619427299\n",
      "train loss:0.03808483324054083\n",
      "train loss:0.02159725586740283\n",
      "train loss:0.06299873557784273\n",
      "train loss:0.07400181408420581\n",
      "train loss:0.007662249439413262\n",
      "train loss:0.03769032026000617\n",
      "train loss:0.02811359180654489\n",
      "train loss:0.06584275027338055\n",
      "train loss:0.019127082295954435\n",
      "train loss:0.03866181807967008\n",
      "train loss:0.0386836176944098\n",
      "train loss:0.018977638473436306\n",
      "train loss:0.013400215243624017\n",
      "train loss:0.09190638642155272\n",
      "=== epoch:5, train acc:0.987, test acc:0.981 ===\n",
      "train loss:0.005411282995738926\n",
      "train loss:0.034348344048946294\n",
      "train loss:0.038575840526344746\n",
      "train loss:0.02429776023344657\n",
      "train loss:0.020525623492447145\n",
      "train loss:0.027926733694650055\n",
      "train loss:0.015166834301572247\n",
      "train loss:0.030064482591690617\n",
      "train loss:0.09048519592554789\n",
      "train loss:0.009119522984722302\n",
      "train loss:0.015844551345426623\n",
      "train loss:0.014752445074478735\n",
      "train loss:0.042509860176385174\n",
      "train loss:0.03193430174335387\n",
      "train loss:0.028962408410283986\n",
      "train loss:0.06518940086574025\n",
      "train loss:0.010771391487014323\n",
      "train loss:0.03068157603894039\n",
      "train loss:0.014973754472477537\n",
      "train loss:0.03793743311967464\n",
      "train loss:0.024088770282450257\n",
      "train loss:0.04404836486418451\n",
      "train loss:0.009933472971345352\n",
      "train loss:0.03242794630695827\n",
      "train loss:0.015126383799837183\n",
      "train loss:0.03540233224440773\n",
      "train loss:0.030324090638889068\n",
      "train loss:0.006765303435302867\n",
      "train loss:0.014633649151752188\n",
      "train loss:0.01880802743273945\n",
      "train loss:0.032649598443027235\n",
      "train loss:0.010107046707330534\n",
      "train loss:0.02137760245573423\n",
      "train loss:0.024038874857470454\n",
      "train loss:0.032665141735616646\n",
      "train loss:0.005203785930722638\n",
      "train loss:0.02110798676319724\n",
      "train loss:0.017569312911905447\n",
      "train loss:0.04108180678885605\n",
      "train loss:0.035665159773144245\n",
      "train loss:0.00939108877450474\n",
      "train loss:0.02078777662009585\n",
      "train loss:0.13346756344238186\n",
      "train loss:0.06345208045000592\n",
      "train loss:0.0487112826745492\n",
      "train loss:0.00989076985268157\n",
      "train loss:0.06360731752514488\n",
      "train loss:0.010938155744462424\n",
      "train loss:0.05944102087829053\n",
      "train loss:0.02607421099780207\n",
      "train loss:0.017387015035409\n",
      "train loss:0.019603350579555333\n",
      "train loss:0.08921099596267236\n",
      "train loss:0.022179179246314316\n",
      "train loss:0.006712238202751325\n",
      "train loss:0.033511126720519646\n",
      "train loss:0.033829072364848965\n",
      "train loss:0.054729355624849985\n",
      "train loss:0.015174715002197067\n",
      "train loss:0.01975019015409794\n",
      "train loss:0.02496796284454345\n",
      "train loss:0.008842998486153811\n",
      "train loss:0.016409456651994687\n",
      "train loss:0.03279459754692263\n",
      "train loss:0.03682724669122928\n",
      "train loss:0.04612096580157996\n",
      "train loss:0.05985572237290704\n",
      "train loss:0.008041087956809441\n",
      "train loss:0.03387524757926107\n",
      "train loss:0.013571730864352467\n",
      "train loss:0.025078047166219877\n",
      "train loss:0.04043131513522314\n",
      "train loss:0.01319684038957884\n",
      "train loss:0.057465392737830016\n",
      "train loss:0.021214958438251025\n",
      "train loss:0.016927161472085287\n",
      "train loss:0.028885493189049524\n",
      "train loss:0.054822919285361975\n",
      "train loss:0.022542658428967407\n",
      "train loss:0.0747196834092029\n",
      "train loss:0.047336304509218205\n",
      "train loss:0.010601026213134699\n",
      "train loss:0.030681589501238445\n",
      "train loss:0.02416611037977245\n",
      "train loss:0.015739785426497562\n",
      "train loss:0.036523170483245854\n",
      "train loss:0.04294916320097175\n",
      "train loss:0.010389912629035387\n",
      "train loss:0.023475480321754345\n",
      "train loss:0.10005656043351874\n",
      "train loss:0.011780568125003395\n",
      "train loss:0.04087822300269951\n",
      "train loss:0.00434783400277401\n",
      "train loss:0.008868563910761532\n",
      "train loss:0.10142753806509554\n",
      "train loss:0.03858401951050153\n",
      "train loss:0.026837574209111308\n",
      "train loss:0.039380311041307604\n",
      "train loss:0.017242896969409727\n",
      "train loss:0.02395949455246013\n",
      "train loss:0.037233617101100215\n",
      "train loss:0.021609777537602667\n",
      "train loss:0.016813149069482333\n",
      "train loss:0.021607880248844132\n",
      "train loss:0.008401237608270001\n",
      "train loss:0.005396218483430182\n",
      "train loss:0.012014326201760135\n",
      "train loss:0.005565138323833185\n",
      "train loss:0.021041742106475816\n",
      "train loss:0.013366159868284964\n",
      "train loss:0.042664819764150985\n",
      "train loss:0.01834709972727144\n",
      "train loss:0.022424482676602363\n",
      "train loss:0.05812051080398846\n",
      "train loss:0.0023143540709757143\n",
      "train loss:0.030880986530016905\n",
      "train loss:0.008989140784452548\n",
      "train loss:0.0431429546509277\n",
      "train loss:0.019823974370546747\n",
      "train loss:0.019522304262972582\n",
      "train loss:0.02646870265858161\n",
      "train loss:0.08435464927349813\n",
      "train loss:0.0065515065008453725\n",
      "train loss:0.00783622629250376\n",
      "train loss:0.005542633779658262\n",
      "train loss:0.03770683119544623\n",
      "train loss:0.03738625300277238\n",
      "train loss:0.0035711795520397722\n",
      "train loss:0.011243552497459421\n",
      "train loss:0.0573857671108139\n",
      "train loss:0.0897923672642615\n",
      "train loss:0.07095395436221091\n",
      "train loss:0.063620950769382\n",
      "train loss:0.012817556919689483\n",
      "train loss:0.025075247752642967\n",
      "train loss:0.0428495311277429\n",
      "train loss:0.015792104041271123\n",
      "train loss:0.05033827140005491\n",
      "train loss:0.011899403029828386\n",
      "train loss:0.01557758419777141\n",
      "train loss:0.02049031170580032\n",
      "train loss:0.03466119558512787\n",
      "train loss:0.08669727073671611\n",
      "train loss:0.008256789356734276\n",
      "train loss:0.05048952241240827\n",
      "train loss:0.0612376035295403\n",
      "train loss:0.01807164911120951\n",
      "train loss:0.09135836980706422\n",
      "train loss:0.008115113009052502\n",
      "train loss:0.028372467537262226\n",
      "train loss:0.008150865935017619\n",
      "train loss:0.021880746650193662\n",
      "train loss:0.02721051539236309\n",
      "train loss:0.08534533582962289\n",
      "train loss:0.020942714479490154\n",
      "train loss:0.012535554645969083\n",
      "train loss:0.0177569561266322\n",
      "train loss:0.012303539025123982\n",
      "train loss:0.02638976630762575\n",
      "train loss:0.024419818734355343\n",
      "train loss:0.09208192667436499\n",
      "train loss:0.018294570469567964\n",
      "train loss:0.06728986512818545\n",
      "train loss:0.030578969547145576\n",
      "train loss:0.014287340298621101\n",
      "train loss:0.02475345000515305\n",
      "train loss:0.0237987378782856\n",
      "train loss:0.021369956600933313\n",
      "train loss:0.027081493433585787\n",
      "train loss:0.02335972837300857\n",
      "train loss:0.01135640071280586\n",
      "train loss:0.010968706577665709\n",
      "train loss:0.0157751197218003\n",
      "train loss:0.024416071098340906\n",
      "train loss:0.014792278092471065\n",
      "train loss:0.017103265773167495\n",
      "train loss:0.006264564233655784\n",
      "train loss:0.05411122104306476\n",
      "train loss:0.008329667987445933\n",
      "train loss:0.021260087301115123\n",
      "train loss:0.05224070366857994\n",
      "train loss:0.010027002626340537\n",
      "train loss:0.14776236588040084\n",
      "train loss:0.026100694126501067\n",
      "train loss:0.07976775764393278\n",
      "train loss:0.020537117834420127\n",
      "train loss:0.03498624866573925\n",
      "train loss:0.09334864943089106\n",
      "train loss:0.014939541939756393\n",
      "train loss:0.04630276611516708\n",
      "train loss:0.06991905236712183\n",
      "train loss:0.015712654578211277\n",
      "train loss:0.007361584950544065\n",
      "train loss:0.009915753850554362\n",
      "train loss:0.018937693687966536\n",
      "train loss:0.024944866051629554\n",
      "train loss:0.023563568236549492\n",
      "train loss:0.019728243531761062\n",
      "train loss:0.07471940158918079\n",
      "train loss:0.021201838307946138\n",
      "train loss:0.04705545221210773\n",
      "train loss:0.016230787806422908\n",
      "train loss:0.027224149783947667\n",
      "train loss:0.021928293773622123\n",
      "train loss:0.014822862984697498\n",
      "train loss:0.022995848299574354\n",
      "train loss:0.024016007758839674\n",
      "train loss:0.028771936411770237\n",
      "train loss:0.03629602982428925\n",
      "train loss:0.010866283412465216\n",
      "train loss:0.03432685727873627\n",
      "train loss:0.009283952480731416\n",
      "train loss:0.03572948670207658\n",
      "train loss:0.011080339985246051\n",
      "train loss:0.03888570949314288\n",
      "train loss:0.0062967850132577274\n",
      "train loss:0.00788798057058287\n",
      "train loss:0.061641977267333774\n",
      "train loss:0.0366946732431095\n",
      "train loss:0.06632408994775414\n",
      "train loss:0.055972889684883634\n",
      "train loss:0.021691305387788122\n",
      "train loss:0.041643592709117376\n",
      "train loss:0.0056564547424529255\n",
      "train loss:0.023327919501846588\n",
      "train loss:0.03203154730520967\n",
      "train loss:0.017853795243886025\n",
      "train loss:0.02233246742450953\n",
      "train loss:0.1952300247767174\n",
      "train loss:0.015400471826454591\n",
      "train loss:0.050875085788429496\n",
      "train loss:0.006661275375593879\n",
      "train loss:0.05973883294824363\n",
      "train loss:0.03156013800930643\n",
      "train loss:0.008195610482416828\n",
      "train loss:0.01876857116268773\n",
      "train loss:0.02400529493984122\n",
      "train loss:0.010851986685053345\n",
      "train loss:0.03259499012329559\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.03243574193499991\n",
      "train loss:0.04116018568021767\n",
      "train loss:0.007995225337528031\n",
      "train loss:0.05860608402372375\n",
      "train loss:0.0656812544630884\n",
      "train loss:0.0913102380536094\n",
      "train loss:0.08235282637265878\n",
      "train loss:0.0125407787537409\n",
      "train loss:0.0181831396307688\n",
      "train loss:0.013276255247985829\n",
      "train loss:0.021835320919751208\n",
      "train loss:0.01352322793492935\n",
      "train loss:0.03622378405811811\n",
      "train loss:0.016224744406899316\n",
      "train loss:0.05982300403934406\n",
      "train loss:0.014833264751136001\n",
      "train loss:0.06009387741388372\n",
      "train loss:0.017997814066606693\n",
      "train loss:0.018959652069055796\n",
      "train loss:0.022015266003574223\n",
      "train loss:0.016870922709155484\n",
      "train loss:0.014580700091880257\n",
      "train loss:0.06605982794453602\n",
      "train loss:0.0070121290908466884\n",
      "train loss:0.012308401308182502\n",
      "train loss:0.046858002597157285\n",
      "train loss:0.014234814687099293\n",
      "train loss:0.07525095821981717\n",
      "train loss:0.024266469225704194\n",
      "train loss:0.020050292378991853\n",
      "train loss:0.052754590702405284\n",
      "train loss:0.010451055014229972\n",
      "train loss:0.017665267275516025\n",
      "train loss:0.020037342389986685\n",
      "train loss:0.027938958769897757\n",
      "train loss:0.007184796604165189\n",
      "train loss:0.028961891801623972\n",
      "train loss:0.010118653395587865\n",
      "train loss:0.006304904432362199\n",
      "train loss:0.02323816810294623\n",
      "train loss:0.008986550671313856\n",
      "train loss:0.007082968668246821\n",
      "train loss:0.07661873525213946\n",
      "train loss:0.11064842679616901\n",
      "train loss:0.046870504442503236\n",
      "train loss:0.05221218303684149\n",
      "train loss:0.032517742339843704\n",
      "train loss:0.012978182567379324\n",
      "train loss:0.026094190435213806\n",
      "train loss:0.026630264910469624\n",
      "train loss:0.010415522715693595\n",
      "train loss:0.005565797956669739\n",
      "train loss:0.030589225903397146\n",
      "train loss:0.033287796567290605\n",
      "train loss:0.01482220370479424\n",
      "train loss:0.03583520634256722\n",
      "train loss:0.0539166692371115\n",
      "train loss:0.007112027193040489\n",
      "train loss:0.013586972125912611\n",
      "train loss:0.049190723538143064\n",
      "train loss:0.00570674436015708\n",
      "train loss:0.041217448271853856\n",
      "train loss:0.14204347629878078\n",
      "train loss:0.016465094502996942\n",
      "train loss:0.013675098047114628\n",
      "train loss:0.008660110795761587\n",
      "train loss:0.0398266260661265\n",
      "train loss:0.007632792088183401\n",
      "train loss:0.016164901404418047\n",
      "train loss:0.01904706623139077\n",
      "train loss:0.040315868545051786\n",
      "train loss:0.007785808229203159\n",
      "train loss:0.017335507661676484\n",
      "train loss:0.0012882725367688993\n",
      "train loss:0.008588972133729842\n",
      "train loss:0.049224483532603884\n",
      "train loss:0.03379365234708816\n",
      "train loss:0.01530149712597576\n",
      "train loss:0.008779683116926637\n",
      "train loss:0.06213531720324284\n",
      "train loss:0.015787323094370056\n",
      "train loss:0.011594905291603985\n",
      "train loss:0.025860821388348644\n",
      "train loss:0.07613292280348737\n",
      "train loss:0.0878025003088063\n",
      "train loss:0.021624980863824392\n",
      "train loss:0.013423806272366352\n",
      "train loss:0.04733821180958651\n",
      "train loss:0.02774739374745286\n",
      "train loss:0.012710080121139443\n",
      "train loss:0.06641704324870443\n",
      "train loss:0.06671853643733212\n",
      "train loss:0.015490857200277318\n",
      "train loss:0.03117169564888739\n",
      "train loss:0.012414075989566975\n",
      "train loss:0.07126118394522281\n",
      "train loss:0.012016757908780165\n",
      "train loss:0.0872727211720407\n",
      "train loss:0.02772943355197544\n",
      "train loss:0.014158344781567416\n",
      "train loss:0.013146026584375326\n",
      "train loss:0.0374078002906142\n",
      "train loss:0.022770212638277366\n",
      "train loss:0.012499285286962217\n",
      "train loss:0.007596687498635564\n",
      "train loss:0.003998026649922599\n",
      "train loss:0.02502520683465638\n",
      "train loss:0.023226832721337763\n",
      "train loss:0.007386467264037396\n",
      "train loss:0.06384660686937776\n",
      "train loss:0.009765101759417742\n",
      "train loss:0.00682424112172922\n",
      "train loss:0.05878643568218187\n",
      "train loss:0.021822355798463488\n",
      "train loss:0.06012235992667217\n",
      "train loss:0.0045136567924053\n",
      "train loss:0.014110131112002265\n",
      "train loss:0.01861348030575257\n",
      "train loss:0.016322283072798618\n",
      "train loss:0.04684574920340625\n",
      "train loss:0.028205522134725113\n",
      "train loss:0.08276759247644899\n",
      "train loss:0.05173324955420048\n",
      "train loss:0.044990547384208074\n",
      "train loss:0.07983939670345448\n",
      "train loss:0.001918531362588417\n",
      "train loss:0.02699886973167335\n",
      "train loss:0.007257979136240242\n",
      "train loss:0.00558205396345136\n",
      "train loss:0.03416976724371276\n",
      "train loss:0.0180599409662684\n",
      "train loss:0.04393801970338787\n",
      "train loss:0.00957739753593031\n",
      "train loss:0.07503932385176518\n",
      "train loss:0.02763617759649396\n",
      "train loss:0.0325498990124383\n",
      "train loss:0.01584101934368141\n",
      "train loss:0.03959350810950017\n",
      "train loss:0.09455235738166982\n",
      "train loss:0.003746588722639846\n",
      "train loss:0.036629508108222075\n",
      "train loss:0.017863119893616573\n",
      "train loss:0.025253195183278062\n",
      "train loss:0.007712586268755873\n",
      "train loss:0.012096751133915411\n",
      "train loss:0.014956693689147897\n",
      "train loss:0.004616094056248849\n",
      "train loss:0.02400226869955618\n",
      "train loss:0.04161434980288817\n",
      "train loss:0.007534061969634032\n",
      "train loss:0.013398309617901616\n",
      "train loss:0.006022658044121234\n",
      "train loss:0.008411748161071016\n",
      "train loss:0.014146647440486953\n",
      "train loss:0.009485679517517746\n",
      "train loss:0.012235186599244862\n",
      "train loss:0.08089090306817132\n",
      "train loss:0.020888836793062575\n",
      "train loss:0.15395278861502354\n",
      "train loss:0.019952778266920476\n",
      "train loss:0.022596667572793643\n",
      "train loss:0.007994238341891984\n",
      "train loss:0.010875768286789494\n",
      "train loss:0.036570218472413\n",
      "train loss:0.024344650501730816\n",
      "train loss:0.02218281555400554\n",
      "train loss:0.010949109441945753\n",
      "train loss:0.019513891639964295\n",
      "train loss:0.008916565038124208\n",
      "train loss:0.058304141081208016\n",
      "train loss:0.006572647875957397\n",
      "train loss:0.04677699609562805\n",
      "train loss:0.09478793044353281\n",
      "train loss:0.04382297403219297\n",
      "train loss:0.0063705941411844194\n",
      "train loss:0.09821455639121585\n",
      "train loss:0.021387437383597736\n",
      "train loss:0.05793549266874863\n",
      "train loss:0.0068592795315038525\n",
      "train loss:0.010094134032311474\n",
      "train loss:0.02043337014026674\n",
      "train loss:0.0077662194966208855\n",
      "train loss:0.014620558031817221\n",
      "train loss:0.048907160947306634\n",
      "train loss:0.037725869325280416\n",
      "train loss:0.01837965993982033\n",
      "train loss:0.10114720378493464\n",
      "train loss:0.016182307272606403\n",
      "train loss:0.06387019592903388\n",
      "train loss:0.06506687581849176\n",
      "train loss:0.018860555423195365\n",
      "train loss:0.025545721569914387\n",
      "train loss:0.02430271767964504\n",
      "train loss:0.003922251789292372\n",
      "train loss:0.03678548462499906\n",
      "train loss:0.014438791166950238\n",
      "train loss:0.03273743649363332\n",
      "train loss:0.04282565212756202\n",
      "train loss:0.042972800682163956\n",
      "train loss:0.043261803813169394\n",
      "train loss:0.0037198848328120343\n",
      "train loss:0.029735776927724576\n",
      "train loss:0.026276624815368837\n",
      "train loss:0.02960907914654222\n",
      "train loss:0.0092957230844179\n",
      "train loss:0.010423536526186883\n",
      "train loss:0.015571621928502947\n",
      "train loss:0.014500837473999339\n",
      "train loss:0.025572196600073434\n",
      "train loss:0.020071832325198647\n",
      "train loss:0.03707001626649513\n",
      "train loss:0.003455258850492544\n",
      "train loss:0.039127289447922195\n",
      "train loss:0.07213245696890279\n",
      "train loss:0.039848424682139214\n",
      "train loss:0.026266819227699544\n",
      "train loss:0.030057501040530572\n",
      "train loss:0.022110194237440012\n",
      "train loss:0.005160180982396663\n",
      "train loss:0.004769166187507716\n",
      "train loss:0.0077894265209375105\n",
      "train loss:0.027807515973443993\n",
      "train loss:0.017931121463693668\n",
      "train loss:0.03994631106935723\n",
      "train loss:0.010075803418851323\n",
      "train loss:0.026007136427142825\n",
      "train loss:0.04044597793526087\n",
      "train loss:0.01863271251174961\n",
      "train loss:0.016526607715846485\n",
      "train loss:0.02990859532822655\n",
      "train loss:0.011202844193213995\n",
      "train loss:0.06766778199539118\n",
      "train loss:0.017302432902991265\n",
      "train loss:0.031104506011691374\n",
      "train loss:0.031034101174554136\n",
      "train loss:0.011574143438428514\n",
      "train loss:0.007768068251551751\n",
      "train loss:0.027374054120371204\n",
      "train loss:0.018141562328720103\n",
      "train loss:0.036860882299850864\n",
      "train loss:0.06414388035771894\n",
      "train loss:0.018154034692626192\n",
      "train loss:0.006057449331209806\n",
      "train loss:0.005142523835828701\n",
      "train loss:0.030443135223215723\n",
      "train loss:0.09494393797064504\n",
      "train loss:0.027739091444520844\n",
      "train loss:0.0205875911390281\n",
      "train loss:0.02545084752941189\n",
      "train loss:0.04041242389782546\n",
      "train loss:0.023991620157193267\n",
      "train loss:0.014500807849197512\n",
      "train loss:0.035417012233674154\n",
      "train loss:0.05995224487830462\n",
      "train loss:0.029171285420655543\n",
      "train loss:0.015245461722205677\n",
      "train loss:0.006694707503947038\n",
      "train loss:0.009362940894521127\n",
      "train loss:0.020152380930817424\n",
      "train loss:0.04410204680847315\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.0165615161654378\n",
      "train loss:0.019755273614815074\n",
      "train loss:0.023057575688988072\n",
      "train loss:0.01314251818129299\n",
      "train loss:0.016156413364608036\n",
      "train loss:0.02212941799802981\n",
      "train loss:0.00577830243768243\n",
      "train loss:0.06430889495652242\n",
      "train loss:0.006032355457012465\n",
      "train loss:0.020427924959748097\n",
      "train loss:0.023617925350815812\n",
      "train loss:0.04812529809510524\n",
      "train loss:0.01857979323072755\n",
      "train loss:0.025870390325168004\n",
      "train loss:0.01316191225692134\n",
      "train loss:0.034222892064116835\n",
      "train loss:0.013675756001997719\n",
      "train loss:0.009993534722681325\n",
      "train loss:0.0019591577942865003\n",
      "train loss:0.006580772732503477\n",
      "train loss:0.018776337632714284\n",
      "train loss:0.01521177352729473\n",
      "train loss:0.005991720956148532\n",
      "train loss:0.03781201747067917\n",
      "train loss:0.017128186967747597\n",
      "train loss:0.03697988027560082\n",
      "train loss:0.012715554766815742\n",
      "train loss:0.018635478404462183\n",
      "train loss:0.008167106532314668\n",
      "train loss:0.011893828898909924\n",
      "train loss:0.021941430767049325\n",
      "train loss:0.008094328788804103\n",
      "train loss:0.005283946199231032\n",
      "train loss:0.015181682555806817\n",
      "train loss:0.0037872917467458318\n",
      "train loss:0.02418441302594605\n",
      "train loss:0.014754899937491427\n",
      "train loss:0.012488482773732443\n",
      "train loss:0.018520662066459775\n",
      "train loss:0.016021669970623046\n",
      "train loss:0.04746013544038418\n",
      "train loss:0.01894682366606765\n",
      "train loss:0.015551059540393137\n",
      "train loss:0.009745271599690838\n",
      "train loss:0.1592545598903828\n",
      "train loss:0.0120930425170798\n",
      "train loss:0.0034681855824498166\n",
      "train loss:0.05464730010857049\n",
      "train loss:0.01605750350318487\n",
      "train loss:0.028179718868276808\n",
      "train loss:0.06929429041209524\n",
      "train loss:0.01719605261694191\n",
      "train loss:0.022216031046824746\n",
      "train loss:0.007464280760391628\n",
      "train loss:0.015997931227683514\n",
      "train loss:0.02089790334131084\n",
      "train loss:0.021129634907118958\n",
      "train loss:0.004165315145691014\n",
      "train loss:0.03728445428896547\n",
      "train loss:0.012773612101889988\n",
      "train loss:0.014460421987469671\n",
      "train loss:0.02359903807705107\n",
      "train loss:0.009653162556752899\n",
      "train loss:0.011816786824018453\n",
      "train loss:0.04628605129152643\n",
      "train loss:0.006784445400644865\n",
      "train loss:0.020963632597148327\n",
      "train loss:0.028090576785512765\n",
      "train loss:0.07984418343946167\n",
      "train loss:0.030343334700973248\n",
      "train loss:0.007489275155396114\n",
      "train loss:0.023450622422846065\n",
      "train loss:0.035869098072543626\n",
      "train loss:0.010125926993531972\n",
      "train loss:0.017678536696527178\n",
      "train loss:0.030078437050989667\n",
      "train loss:0.027519812686172474\n",
      "train loss:0.013143717966681602\n",
      "train loss:0.011258553683746982\n",
      "train loss:0.03183544754717922\n",
      "train loss:0.042023180300749335\n",
      "train loss:0.019973403949807324\n",
      "train loss:0.016869731588345177\n",
      "train loss:0.028022902325696063\n",
      "train loss:0.024225711428868507\n",
      "train loss:0.0571421049389836\n",
      "train loss:0.015595318584868824\n",
      "train loss:0.008945268096106927\n",
      "train loss:0.009587910219098729\n",
      "train loss:0.04729666849065086\n",
      "train loss:0.026490934897547846\n",
      "train loss:0.03394519928544112\n",
      "train loss:0.04266853136270552\n",
      "train loss:0.05668109007535891\n",
      "train loss:0.022734497993695604\n",
      "train loss:0.012027961498429022\n",
      "train loss:0.04276166094239117\n",
      "train loss:0.05384233863352447\n",
      "train loss:0.002179641336424507\n",
      "train loss:0.012505017256967512\n",
      "train loss:0.005884237391734359\n",
      "=== epoch:6, train acc:0.987, test acc:0.986 ===\n",
      "train loss:0.006926792087817995\n",
      "train loss:0.004377535996851915\n",
      "train loss:0.013066036327819724\n",
      "train loss:0.0350225894205581\n",
      "train loss:0.004501800407425798\n",
      "train loss:0.013607801575095314\n",
      "train loss:0.0569221253876486\n",
      "train loss:0.01786838179096047\n",
      "train loss:0.003783529836343782\n",
      "train loss:0.025933458001238478\n",
      "train loss:0.010040455658716751\n",
      "train loss:0.017073871520712783\n",
      "train loss:0.004153788446276582\n",
      "train loss:0.008455911523789439\n",
      "train loss:0.019134835270276096\n",
      "train loss:0.005639162133379834\n",
      "train loss:0.008017041007540724\n",
      "train loss:0.03334044273503036\n",
      "train loss:0.0394278090546426\n",
      "train loss:0.017468261873132482\n",
      "train loss:0.07836269222671233\n",
      "train loss:0.027318028257757514\n",
      "train loss:0.01816897977298939\n",
      "train loss:0.011184987243656748\n",
      "train loss:0.04428479722303473\n",
      "train loss:0.023529639997357722\n",
      "train loss:0.029673651160202433\n",
      "train loss:0.014109827381454065\n",
      "train loss:0.017546291214348118\n",
      "train loss:0.005012220639563615\n",
      "train loss:0.027298045981009666\n",
      "train loss:0.037728377304248405\n",
      "train loss:0.010327096044405548\n",
      "train loss:0.02476029335972143\n",
      "train loss:0.01125590699278298\n",
      "train loss:0.02475620540328616\n",
      "train loss:0.015870040966524137\n",
      "train loss:0.056863795643458205\n",
      "train loss:0.007266004469810458\n",
      "train loss:0.0364979356394234\n",
      "train loss:0.008126513582161404\n",
      "train loss:0.023817287566926453\n",
      "train loss:0.007258640861549132\n",
      "train loss:0.010846890773784366\n",
      "train loss:0.02728473066590561\n",
      "train loss:0.04370585531093314\n",
      "train loss:0.007071545124915182\n",
      "train loss:0.005149013000844955\n",
      "train loss:0.04627537980692002\n",
      "train loss:0.0051230561856856\n",
      "train loss:0.021537362098922045\n",
      "train loss:0.009141091099082798\n",
      "train loss:0.022936414492694693\n",
      "train loss:0.028076996269059445\n",
      "train loss:0.018392278450122514\n",
      "train loss:0.007348122979406097\n",
      "train loss:0.009557260874808054\n",
      "train loss:0.02431815695985049\n",
      "train loss:0.014724620412709576\n",
      "train loss:0.005398103776586336\n",
      "train loss:0.020662449780104803\n",
      "train loss:0.008361994056689762\n",
      "train loss:0.008081992481661852\n",
      "train loss:0.039820996218423235\n",
      "train loss:0.0188555499657795\n",
      "train loss:0.0064746481537430785\n",
      "train loss:0.007175596434107828\n",
      "train loss:0.010524417771451536\n",
      "train loss:0.008408012615942788\n",
      "train loss:0.008035668907087384\n",
      "train loss:0.05434224585968802\n",
      "train loss:0.01491108673231223\n",
      "train loss:0.0354979542451301\n",
      "train loss:0.01690516954398814\n",
      "train loss:0.03655757163230615\n",
      "train loss:0.013993025978838593\n",
      "train loss:0.00557214975251983\n",
      "train loss:0.16778338812580876\n",
      "train loss:0.04850021783183268\n",
      "train loss:0.011817669219411398\n",
      "train loss:0.003905696915854825\n",
      "train loss:0.025628822268649952\n",
      "train loss:0.01887508528597404\n",
      "train loss:0.010032514285570742\n",
      "train loss:0.02585706664923575\n",
      "train loss:0.017503395118230142\n",
      "train loss:0.0051652279930064285\n",
      "train loss:0.004452729915753294\n",
      "train loss:0.004114313097566572\n",
      "train loss:0.0025268239240210876\n",
      "train loss:0.015316395285983187\n",
      "train loss:0.021680053843310135\n",
      "train loss:0.0377584653851433\n",
      "train loss:0.03816123092996034\n",
      "train loss:0.02102749225161553\n",
      "train loss:0.0070465366391610565\n",
      "train loss:0.06650167614845916\n",
      "train loss:0.014594835453930819\n",
      "train loss:0.0026277714958744115\n",
      "train loss:0.013018977924333904\n",
      "train loss:0.00709944889122338\n",
      "train loss:0.0027926676635905657\n",
      "train loss:0.005318161229237983\n",
      "train loss:0.007415161012193745\n",
      "train loss:0.028309923161508866\n",
      "train loss:0.005806817237513667\n",
      "train loss:0.022916120965385634\n",
      "train loss:0.002885238783163622\n",
      "train loss:0.007398847151953512\n",
      "train loss:0.0035661517569649786\n",
      "train loss:0.040283216863125186\n",
      "train loss:0.024928896114320937\n",
      "train loss:0.017959621129163453\n",
      "train loss:0.04011045909836558\n",
      "train loss:0.023387724870036247\n",
      "train loss:0.01022947843093641\n",
      "train loss:0.02974188291752248\n",
      "train loss:0.008665292529720245\n",
      "train loss:0.014936684551306397\n",
      "train loss:0.04838667909648277\n",
      "train loss:0.039766419016598886\n",
      "train loss:0.015184082149075106\n",
      "train loss:0.0241656365942232\n",
      "train loss:0.014366130511606361\n",
      "train loss:0.010873724379471712\n",
      "train loss:0.0068581127776873585\n",
      "train loss:0.004337131757709461\n",
      "train loss:0.01648302074844279\n",
      "train loss:0.030695718152633167\n",
      "train loss:0.0205783102041724\n",
      "train loss:0.005864630478105956\n",
      "train loss:0.005635644307645479\n",
      "train loss:0.007918326745560976\n",
      "train loss:0.006281176889518852\n",
      "train loss:0.020683892876231152\n",
      "train loss:0.007023830304017141\n",
      "train loss:0.0038272689084616176\n",
      "train loss:0.03774595746711084\n",
      "train loss:0.013862861241126677\n",
      "train loss:0.008680952912864952\n",
      "train loss:0.016352801673745213\n",
      "train loss:0.0020131387239394455\n",
      "train loss:0.06345708221907607\n",
      "train loss:0.01130000192956294\n",
      "train loss:0.012418373996622534\n",
      "train loss:0.011103899522179654\n",
      "train loss:0.015086688720205741\n",
      "train loss:0.012805469359775114\n",
      "train loss:0.020119412923952217\n",
      "train loss:0.0183687516150769\n",
      "train loss:0.06235379601063634\n",
      "train loss:0.16988495681044286\n",
      "train loss:0.01954416357991658\n",
      "train loss:0.016264590862114996\n",
      "train loss:0.019842414113560653\n",
      "train loss:0.02668987626536372\n",
      "train loss:0.013656123955596577\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.0028405288298230407\n",
      "train loss:0.024547738736066235\n",
      "train loss:0.003924758364041593\n",
      "train loss:0.056376919529803365\n",
      "train loss:0.003387385945913553\n",
      "train loss:0.09103946613184657\n",
      "train loss:0.013338691596985081\n",
      "train loss:0.013613588400291657\n",
      "train loss:0.04890462590120582\n",
      "train loss:0.01039485865936615\n",
      "train loss:0.013909374851854579\n",
      "train loss:0.03134891944145097\n",
      "train loss:0.014006225951403432\n",
      "train loss:0.02036350365661922\n",
      "train loss:0.003370769244781514\n",
      "train loss:0.003478990375501097\n",
      "train loss:0.051838589696354714\n",
      "train loss:0.029851973642042746\n",
      "train loss:0.03872023218812563\n",
      "train loss:0.04883150723021235\n",
      "train loss:0.01069360291199347\n",
      "train loss:0.009135142418253011\n",
      "train loss:0.013661144999236161\n",
      "train loss:0.024232180032318223\n",
      "train loss:0.012157013198870841\n",
      "train loss:0.009087496551305502\n",
      "train loss:0.005911559592916331\n",
      "train loss:0.01140805051306915\n",
      "train loss:0.02354387302866101\n",
      "train loss:0.03435754965733363\n",
      "train loss:0.036404704173838204\n",
      "train loss:0.009613356329701846\n",
      "train loss:0.0453476242014861\n",
      "train loss:0.03492113427630883\n",
      "train loss:0.032000248498675755\n",
      "train loss:0.007290811784677404\n",
      "train loss:0.007398949465922077\n",
      "train loss:0.024476516490201643\n",
      "train loss:0.025389954970768944\n",
      "train loss:0.0082988577934738\n",
      "train loss:0.02227361702111511\n",
      "train loss:0.04587510560565964\n",
      "train loss:0.011624623382053237\n",
      "train loss:0.008571511956023474\n",
      "train loss:0.03474499859491296\n",
      "train loss:0.020397358585001784\n",
      "train loss:0.0071956503812436725\n",
      "train loss:0.08298761060804725\n",
      "train loss:0.009049326428170844\n",
      "train loss:0.021445174709885727\n",
      "train loss:0.008156055557935294\n",
      "train loss:0.003648236255395314\n",
      "train loss:0.017080751039363986\n",
      "train loss:0.016777292706128013\n",
      "train loss:0.010616629370367486\n",
      "train loss:0.008704985407251892\n",
      "train loss:0.014364021871748485\n",
      "train loss:0.00622154737824544\n",
      "train loss:0.043118721972861034\n",
      "train loss:0.015545918535552367\n",
      "train loss:0.014092445065048597\n",
      "train loss:0.004005839918327834\n",
      "train loss:0.057377078955840356\n",
      "train loss:0.007234366580950343\n",
      "train loss:0.0032885078988428244\n",
      "train loss:0.018038311876480025\n",
      "train loss:0.028134725221428035\n",
      "train loss:0.05367245010864129\n",
      "train loss:0.00573622064657099\n",
      "train loss:0.012213298993488424\n",
      "train loss:0.012798148309494155\n",
      "train loss:0.03288481767082842\n",
      "train loss:0.010775061387899099\n",
      "train loss:0.0599854670408925\n",
      "train loss:0.02571361254735524\n",
      "train loss:0.023474419611977583\n",
      "train loss:0.014049171296285936\n",
      "train loss:0.023720614803607543\n",
      "train loss:0.0051156901929359\n",
      "train loss:0.003464402366313806\n",
      "train loss:0.005237926925968205\n",
      "train loss:0.0228046479008814\n",
      "train loss:0.014588085663422923\n",
      "train loss:0.048849029615261295\n",
      "train loss:0.020955442757159118\n",
      "train loss:0.009173817804763498\n",
      "train loss:0.018701892403866535\n",
      "train loss:0.0030680066438754983\n",
      "train loss:0.017075694260592\n",
      "train loss:0.010006155883375919\n",
      "train loss:0.004685656199677908\n",
      "train loss:0.013032735590548478\n",
      "train loss:0.01847219202501388\n",
      "train loss:0.02677304184545997\n",
      "train loss:0.01041421010180888\n",
      "train loss:0.014956784992928187\n",
      "train loss:0.0099183427237546\n",
      "train loss:0.013143754857813104\n",
      "train loss:0.0342367227844697\n",
      "train loss:0.03020459250216716\n",
      "train loss:0.012081227545940328\n",
      "train loss:0.01743979797356431\n",
      "train loss:0.021829422853615586\n",
      "train loss:0.01869839378428137\n",
      "train loss:0.0038707152965705744\n",
      "train loss:0.023641257968027015\n",
      "train loss:0.006443713563756893\n",
      "train loss:0.012067369118288547\n",
      "train loss:0.1022539915641723\n",
      "train loss:0.007507373115018579\n",
      "train loss:0.009212844348168022\n",
      "train loss:0.02595687399511405\n",
      "train loss:0.050004493779179204\n",
      "train loss:0.04034406900181857\n",
      "train loss:0.009327904110031728\n",
      "train loss:0.0073410529351013555\n",
      "train loss:0.014750124585884372\n",
      "train loss:0.015058229967158852\n",
      "train loss:0.005534618948079409\n",
      "train loss:0.02042614940751284\n",
      "train loss:0.012821451659441731\n",
      "train loss:0.045564440945794885\n",
      "train loss:0.00879825619055138\n",
      "train loss:0.002837190869853006\n",
      "train loss:0.012210140242159613\n",
      "train loss:0.030984195046296525\n",
      "train loss:0.009292388392732654\n",
      "train loss:0.03384262953064904\n",
      "train loss:0.010012931652684165\n",
      "train loss:0.014080524972263121\n",
      "train loss:0.06070181985616254\n",
      "train loss:0.01606357014884299\n",
      "train loss:0.008953416188174442\n",
      "train loss:0.002446508723229331\n",
      "train loss:0.006569366347985118\n",
      "train loss:0.014611492362184085\n",
      "train loss:0.02247438231082848\n",
      "train loss:0.003139251554346545\n",
      "train loss:0.0055884663961501\n",
      "train loss:0.04327264298369507\n",
      "train loss:0.008315441342777098\n",
      "train loss:0.029885387990287754\n",
      "train loss:0.031712355706727806\n",
      "train loss:0.033651880405369435\n",
      "train loss:0.027006132436324198\n",
      "train loss:0.04336626325967284\n",
      "train loss:0.00694673211106624\n",
      "train loss:0.020104905243824533\n",
      "train loss:0.05245930738623622\n",
      "train loss:0.007476407773673278\n",
      "train loss:0.014979262228980529\n",
      "train loss:0.00225309826005031\n",
      "train loss:0.0157489147319926\n",
      "train loss:0.006826234437201257\n",
      "train loss:0.015837695101590138\n",
      "train loss:0.02094112440314408\n",
      "train loss:0.012026202556731935\n",
      "train loss:0.004623533335705222\n",
      "train loss:0.015023269530246812\n",
      "train loss:0.0034581094604038136\n",
      "train loss:0.003183553563724616\n",
      "train loss:0.043204891163961215\n",
      "train loss:0.006588739581166997\n",
      "train loss:0.017483170846332847\n",
      "train loss:0.024035567526784197\n",
      "train loss:0.0006884583835372842\n",
      "train loss:0.00531857566005905\n",
      "train loss:0.06351938022246563\n",
      "train loss:0.004896303008533607\n",
      "train loss:0.007226349297836863\n",
      "train loss:0.015174379353999554\n",
      "train loss:0.006631144350432832\n",
      "train loss:0.020450558348325307\n",
      "train loss:0.03651587874968994\n",
      "train loss:0.06199956668206077\n",
      "train loss:0.01782979793949316\n",
      "train loss:0.021711073132431508\n",
      "train loss:0.03631175094966623\n",
      "train loss:0.010543934061262854\n",
      "train loss:0.012207397035000503\n",
      "train loss:0.015381397715214455\n",
      "train loss:0.07003606487424388\n",
      "train loss:0.035950575921347754\n",
      "train loss:0.05924992927747498\n",
      "train loss:0.02033490833111104\n",
      "train loss:0.00756653269819077\n",
      "train loss:0.013417565674485998\n",
      "train loss:0.016638991291038196\n",
      "train loss:0.02868830963740433\n",
      "train loss:0.004465872824639646\n",
      "train loss:0.007256782994492196\n",
      "train loss:0.05286101051071729\n",
      "train loss:0.0006661249930367129\n",
      "train loss:0.008884798552870719\n",
      "train loss:0.0015558515075915313\n",
      "train loss:0.008268597978597749\n",
      "train loss:0.02337895939879304\n",
      "train loss:0.006113924117560134\n",
      "train loss:0.02722509955731394\n",
      "train loss:0.034883120396619435\n",
      "train loss:0.04101581424958489\n",
      "train loss:0.03431132706417739\n",
      "train loss:0.037989660822035386\n",
      "train loss:0.02447322167802136\n",
      "train loss:0.07129143710923143\n",
      "train loss:0.008078325199805001\n",
      "train loss:0.008368848204398293\n",
      "train loss:0.005665425794350156\n",
      "train loss:0.006620484158388339\n",
      "train loss:0.019287407764738265\n",
      "train loss:0.009114396852286799\n",
      "train loss:0.006163960471574251\n",
      "train loss:0.04620684833392117\n",
      "train loss:0.003934743647542736\n",
      "train loss:0.052748328774818665\n",
      "train loss:0.01316902622396162\n",
      "train loss:0.0559979654217918\n",
      "train loss:0.010185169081107844\n",
      "train loss:0.009027130430644249\n",
      "train loss:0.013394715623051851\n",
      "train loss:0.0072044164757744675\n",
      "train loss:0.047467871156279394\n",
      "train loss:0.0112258643160614\n",
      "train loss:0.0034949269285457145\n",
      "train loss:0.05465471483680697\n",
      "train loss:0.01166820032793178\n",
      "train loss:0.00630500532258531\n",
      "train loss:0.012509494315947419\n",
      "train loss:0.06416639946424942\n",
      "train loss:0.004299552637879841\n",
      "train loss:0.008384752242661863\n",
      "train loss:0.007870873611765958\n",
      "train loss:0.008358909846348605\n",
      "train loss:0.0998322995266343\n",
      "train loss:0.00950662505551242\n",
      "train loss:0.006768110712576184\n",
      "train loss:0.0027090734135539153\n",
      "train loss:0.011707204932875595\n",
      "train loss:0.0674764458122492\n",
      "train loss:0.008739523952959773\n",
      "train loss:0.005834251646231731\n",
      "train loss:0.0041770020598818\n",
      "train loss:0.004153891252804\n",
      "train loss:0.07141229487021325\n",
      "train loss:0.028928032730275017\n",
      "train loss:0.028594167374654974\n",
      "train loss:0.01468972099335926\n",
      "train loss:0.013504840586442192\n",
      "train loss:0.03483597855045504\n",
      "train loss:0.019086752568114505\n",
      "train loss:0.02481742700321188\n",
      "train loss:0.012009152864063097\n",
      "train loss:0.0054769642366083145\n",
      "train loss:0.008994126651583886\n",
      "train loss:0.013539734139568238\n",
      "train loss:0.016874549436150417\n",
      "train loss:0.02119038338115781\n",
      "train loss:0.0455919778871423\n",
      "train loss:0.01098960674220541\n",
      "train loss:0.02327281215489707\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.026044647551715032\n",
      "train loss:0.026149288196808052\n",
      "train loss:0.02032123461910169\n",
      "train loss:0.009683916407296093\n",
      "train loss:0.011776508421332129\n",
      "train loss:0.019599418457118326\n",
      "train loss:0.008535491132215498\n",
      "train loss:0.006835093409858598\n",
      "train loss:0.007162576124557556\n",
      "train loss:0.05345486543536379\n",
      "train loss:0.02440246114990733\n",
      "train loss:0.011695557343241268\n",
      "train loss:0.011677192235214\n",
      "train loss:0.01749301475344825\n",
      "train loss:0.07637155742943491\n",
      "train loss:0.01753981049171907\n",
      "train loss:0.019915230152182682\n",
      "train loss:0.012121250879938997\n",
      "train loss:0.012505358721583155\n",
      "train loss:0.005243918513710508\n",
      "train loss:0.0059343878514590154\n",
      "train loss:0.0139222695998516\n",
      "train loss:0.0582154400802585\n",
      "train loss:0.032928004239564615\n",
      "train loss:0.007487435439947635\n",
      "train loss:0.007357501334951038\n",
      "train loss:0.0024755621669369783\n",
      "train loss:0.025831602467473257\n",
      "train loss:0.008590803817714572\n",
      "train loss:0.01058371528974611\n",
      "train loss:0.004518638464885327\n",
      "train loss:0.010526733847519766\n",
      "train loss:0.009635041283235488\n",
      "train loss:0.006204673232208083\n",
      "train loss:0.02660040522594046\n",
      "train loss:0.026228051488806216\n",
      "train loss:0.007749119296584562\n",
      "train loss:0.014015184546409806\n",
      "train loss:0.005765840180100038\n",
      "train loss:0.07258816326312156\n",
      "train loss:0.02500443989925483\n",
      "train loss:0.015429618413428542\n",
      "train loss:0.06067026170731639\n",
      "train loss:0.0390887498800211\n",
      "train loss:0.008402131171050806\n",
      "train loss:0.06602284350940861\n",
      "train loss:0.006047716459632796\n",
      "train loss:0.010816498185333203\n",
      "train loss:0.004474133036309682\n",
      "train loss:0.05165420330827644\n",
      "train loss:0.02391981629494239\n",
      "train loss:0.02653077453801849\n",
      "train loss:0.013776707906061392\n",
      "train loss:0.011824082345730964\n",
      "train loss:0.01905341689071854\n",
      "train loss:0.014466323501574542\n",
      "train loss:0.01351602972138221\n",
      "train loss:0.040354381480466044\n",
      "train loss:0.00624158581171534\n",
      "train loss:0.029478867609674032\n",
      "train loss:0.019418700380118906\n",
      "train loss:0.007895500841775333\n",
      "train loss:0.00971719936230065\n",
      "train loss:0.017544055787835574\n",
      "train loss:0.01836683441636915\n",
      "train loss:0.008798115817414773\n",
      "train loss:0.04215020285047239\n",
      "train loss:0.007003864343462085\n",
      "train loss:0.03175289371468318\n",
      "train loss:0.006291455578262446\n",
      "train loss:0.03323036348579936\n",
      "train loss:0.032843764897988285\n",
      "train loss:0.041370998339653686\n",
      "train loss:0.016814044971966858\n",
      "train loss:0.022753705766361088\n",
      "train loss:0.008055717993844743\n",
      "train loss:0.02498103708909457\n",
      "train loss:0.01461550762786674\n",
      "train loss:0.00897788952062614\n",
      "train loss:0.0058860063780670525\n",
      "train loss:0.019134370790339167\n",
      "train loss:0.04775237336100782\n",
      "train loss:0.003273094256229297\n",
      "train loss:0.0015799727070619817\n",
      "train loss:0.021065701528538244\n",
      "train loss:0.003042399502324376\n",
      "train loss:0.004603215467206936\n",
      "train loss:0.026641136333104828\n",
      "train loss:0.04383355407213688\n",
      "train loss:0.009115946741953356\n",
      "train loss:0.042090150362107275\n",
      "train loss:0.027097253056986917\n",
      "train loss:0.0076802459172718674\n",
      "train loss:0.0036575125637973356\n",
      "train loss:0.01752852704508645\n",
      "train loss:0.020452221988035514\n",
      "train loss:0.014647868242974434\n",
      "train loss:0.0397280084046154\n",
      "train loss:0.057869838816165364\n",
      "train loss:0.04186045703416301\n",
      "train loss:0.011062357114655676\n",
      "train loss:0.018458445305321425\n",
      "train loss:0.012934795384452023\n",
      "train loss:0.049571567828558614\n",
      "train loss:0.00401012916577593\n",
      "train loss:0.05518528651333245\n",
      "train loss:0.0053029324919852\n",
      "train loss:0.008578927906072169\n",
      "train loss:0.015230055653784309\n",
      "train loss:0.03431500580422018\n",
      "train loss:0.0032108420566798273\n",
      "train loss:0.001374643268988531\n",
      "train loss:0.005065743566695775\n",
      "train loss:0.05396141166536839\n",
      "train loss:0.034742517562295266\n",
      "train loss:0.019332095530523265\n",
      "train loss:0.007301379275997052\n",
      "train loss:0.053818079726579045\n",
      "train loss:0.013540467350846297\n",
      "train loss:0.009219237209932351\n",
      "train loss:0.029326644531755566\n",
      "train loss:0.007251132818780147\n",
      "train loss:0.007338705499130902\n",
      "train loss:0.014736881953507633\n",
      "train loss:0.0028438974345883455\n",
      "train loss:0.010825533282518326\n",
      "train loss:0.03189349569304088\n",
      "train loss:0.02449983739860979\n",
      "train loss:0.01628560015730116\n",
      "train loss:0.012668659673423809\n",
      "train loss:0.007375200172366072\n",
      "train loss:0.05133120313079832\n",
      "train loss:0.05090099521300735\n",
      "train loss:0.023885679457924337\n",
      "train loss:0.029663834834390657\n",
      "train loss:0.004808067123802354\n",
      "train loss:0.023486217919323718\n",
      "train loss:0.00762806763974161\n",
      "train loss:0.0029031569548858987\n",
      "train loss:0.0746442549763709\n",
      "train loss:0.009972163582415886\n",
      "train loss:0.022709760868201676\n",
      "train loss:0.013005119540978995\n",
      "train loss:0.003990799822002827\n",
      "train loss:0.01251706323767608\n",
      "train loss:0.01420240508207742\n",
      "train loss:0.009459698708176366\n",
      "train loss:0.009295507577045576\n",
      "train loss:0.00724574614422589\n",
      "train loss:0.0383611530880679\n",
      "train loss:0.0067131744805257855\n",
      "train loss:0.0019005356917799149\n",
      "train loss:0.06365404235261153\n",
      "train loss:0.012329009719266915\n",
      "train loss:0.002281639167672967\n",
      "train loss:0.02960586528063269\n",
      "train loss:0.010414424029270609\n",
      "train loss:0.008785003285985426\n",
      "train loss:0.01050043528343407\n",
      "train loss:0.006717976455764547\n",
      "train loss:0.015737197817294175\n",
      "train loss:0.00651176318630332\n",
      "train loss:0.019731231788197003\n",
      "train loss:0.03255457614933752\n",
      "train loss:0.012134952166945118\n",
      "train loss:0.006729020004922287\n",
      "train loss:0.05007856359113252\n",
      "train loss:0.01218894589942498\n",
      "train loss:0.003739428655537806\n",
      "train loss:0.06675198028083092\n",
      "train loss:0.011170424119098793\n",
      "train loss:0.014100148755302952\n",
      "train loss:0.02279185976366717\n",
      "train loss:0.003806406669185668\n",
      "train loss:0.012338881542239555\n",
      "train loss:0.012753915794996986\n",
      "train loss:0.019106698524240528\n",
      "train loss:0.011637919822016214\n",
      "train loss:0.014892219053198284\n",
      "train loss:0.009970626948927934\n",
      "train loss:0.06672216799341879\n",
      "train loss:0.03431587034739156\n",
      "train loss:0.024389097116915472\n",
      "=== epoch:7, train acc:0.992, test acc:0.987 ===\n",
      "train loss:0.0014381184317580084\n",
      "train loss:0.045982303519918596\n",
      "train loss:0.02802827028076682\n",
      "train loss:0.008113128208978115\n",
      "train loss:0.00971087288143958\n",
      "train loss:0.007112540230768811\n",
      "train loss:0.016286068947171297\n",
      "train loss:0.015193451573895653\n",
      "train loss:0.012564441256944366\n",
      "train loss:0.009015661852469882\n",
      "train loss:0.004687591016783098\n",
      "train loss:0.03571544287702222\n",
      "train loss:0.009596085416353668\n",
      "train loss:0.014065486200920288\n",
      "train loss:0.027829111456171413\n",
      "train loss:0.01598225441021969\n",
      "train loss:0.015547774945485671\n",
      "train loss:0.0104101945446811\n",
      "train loss:0.008558241939547554\n",
      "train loss:0.004202823673185404\n",
      "train loss:0.010079888295760488\n",
      "train loss:0.010922226375192112\n",
      "train loss:0.016655619974317363\n",
      "train loss:0.01668926935305305\n",
      "train loss:0.032469435666100915\n",
      "train loss:0.025224704098702536\n",
      "train loss:0.03131251959882023\n",
      "train loss:0.025789465714627095\n",
      "train loss:0.005249742691957934\n",
      "train loss:0.03736022596992379\n",
      "train loss:0.013162716362637722\n",
      "train loss:0.018157448938529337\n",
      "train loss:0.026756359853547882\n",
      "train loss:0.022847228380575815\n",
      "train loss:0.01601156880984084\n",
      "train loss:0.005321980141554366\n",
      "train loss:0.007247429123854225\n",
      "train loss:0.0023793965343056655\n",
      "train loss:0.011833428534204746\n",
      "train loss:0.018057639696922607\n",
      "train loss:0.007842875098885758\n",
      "train loss:0.02106615699021622\n",
      "train loss:0.013685216058432028\n",
      "train loss:0.011607649452780804\n",
      "train loss:0.0055648744717614815\n",
      "train loss:0.017174099487563738\n",
      "train loss:0.022376652820546798\n",
      "train loss:0.011322180718843153\n",
      "train loss:0.019979858732126817\n",
      "train loss:0.015182239958706618\n",
      "train loss:0.015327471549840582\n",
      "train loss:0.009248215591625635\n",
      "train loss:0.016474358447744593\n",
      "train loss:0.02378024558448855\n",
      "train loss:0.023743771410097855\n",
      "train loss:0.014670195277507231\n",
      "train loss:0.007414261164686007\n",
      "train loss:0.012266690340792197\n",
      "train loss:0.01012172819181182\n",
      "train loss:0.008985960401867516\n",
      "train loss:0.005722320005765851\n",
      "train loss:0.021607586889310824\n",
      "train loss:0.005280838987668553\n",
      "train loss:0.02331002690000338\n",
      "train loss:0.04326622603674563\n",
      "train loss:0.009359806161362968\n",
      "train loss:0.004562489033251463\n",
      "train loss:0.03409908856511486\n",
      "train loss:0.04067617767674985\n",
      "train loss:0.006821942910825278\n",
      "train loss:0.02628255798670708\n",
      "train loss:0.00835881132582836\n",
      "train loss:0.00699093108306162\n",
      "train loss:0.012897153505045587\n",
      "train loss:0.02901114312547167\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.006009531388473158\n",
      "train loss:0.009664691590047651\n",
      "train loss:0.005048415741815745\n",
      "train loss:0.0067780174180418\n",
      "train loss:0.019277632430281605\n",
      "train loss:0.006390930114633736\n",
      "train loss:0.014822413158743917\n",
      "train loss:0.044692637917482625\n",
      "train loss:0.008381889165868055\n",
      "train loss:0.003832358689364631\n",
      "train loss:0.0020363115649220144\n",
      "train loss:0.01370098803641792\n",
      "train loss:0.0023749679360897005\n",
      "train loss:0.009452642140129341\n",
      "train loss:0.011314750475368552\n",
      "train loss:0.0123627316787948\n",
      "train loss:0.016430820680923493\n",
      "train loss:0.0032994186058655315\n",
      "train loss:0.0034876460959052946\n",
      "train loss:0.002809966656956136\n",
      "train loss:0.008105859813624341\n",
      "train loss:0.0025827614549052908\n",
      "train loss:0.046213999244363604\n",
      "train loss:0.06791797563337704\n",
      "train loss:0.015853538499820827\n",
      "train loss:0.021414382144685117\n",
      "train loss:0.013635140181782423\n",
      "train loss:0.007948790596058351\n",
      "train loss:0.09655886603094072\n",
      "train loss:0.014690507382462055\n",
      "train loss:0.007867869709120495\n",
      "train loss:0.007806672599648565\n",
      "train loss:0.048437752368460145\n",
      "train loss:0.004397240895418071\n",
      "train loss:0.006814499621760649\n",
      "train loss:0.05038936421894451\n",
      "train loss:0.02039949915453774\n",
      "train loss:0.024888105703856255\n",
      "train loss:0.005044320047323009\n",
      "train loss:0.007833756280658745\n",
      "train loss:0.0046703094035254935\n",
      "train loss:0.026711672324445917\n",
      "train loss:0.008199970231501\n",
      "train loss:0.0060506752652072\n",
      "train loss:0.005652156904649423\n",
      "train loss:0.0052293411047177\n",
      "train loss:0.005821422677064587\n",
      "train loss:0.009803662540590855\n",
      "train loss:0.006660220193239767\n",
      "train loss:0.0204999215406375\n",
      "train loss:0.07238860458689333\n",
      "train loss:0.008524622381593804\n",
      "train loss:0.030529089141810416\n",
      "train loss:0.010214237741058521\n",
      "train loss:0.008613509027745221\n",
      "train loss:0.0851949938193112\n",
      "train loss:0.001414636702606712\n",
      "train loss:0.014219463952453855\n",
      "train loss:0.003455505303125958\n",
      "train loss:0.005046799191783014\n",
      "train loss:0.006190740181441159\n",
      "train loss:0.010661373838777239\n",
      "train loss:0.013163641115615079\n",
      "train loss:0.0029300569476202964\n",
      "train loss:0.014656461571972099\n",
      "train loss:0.007894118362096893\n",
      "train loss:0.003909790033515822\n",
      "train loss:0.00685554079019354\n",
      "train loss:0.004975189008027731\n",
      "train loss:0.02197580128676881\n",
      "train loss:0.01894434182635289\n",
      "train loss:0.022432894777117237\n",
      "train loss:0.0072467884050866505\n",
      "train loss:0.05871846728475484\n",
      "train loss:0.010512707813777923\n",
      "train loss:0.0036292394850106595\n",
      "train loss:0.0061149290839486534\n",
      "train loss:0.034619487854543024\n",
      "train loss:0.009342228944574479\n",
      "train loss:0.016246659622932827\n",
      "train loss:0.013685260493281564\n",
      "train loss:0.00977758159914504\n",
      "train loss:0.045511549423719794\n",
      "train loss:0.002905813034520396\n",
      "train loss:0.008265880268269006\n",
      "train loss:0.009869521876777615\n",
      "train loss:0.0068980086426488575\n",
      "train loss:0.01757079497978975\n",
      "train loss:0.0020901718724861042\n",
      "train loss:0.006651889954455652\n",
      "train loss:0.0007445636959158461\n",
      "train loss:0.023150472809160445\n",
      "train loss:0.01918343138411826\n",
      "train loss:0.07378143966215356\n",
      "train loss:0.0024594214494223937\n",
      "train loss:0.004993914794366826\n",
      "train loss:0.006277515810168108\n",
      "train loss:0.00764877880431233\n",
      "train loss:0.06911520506864303\n",
      "train loss:0.004478943495817276\n",
      "train loss:0.03021774221204811\n",
      "train loss:0.006941124842264212\n",
      "train loss:0.007122817551591483\n",
      "train loss:0.00766637212647753\n",
      "train loss:0.01780540614251714\n",
      "train loss:0.008304365827184716\n",
      "train loss:0.008269881804472617\n",
      "train loss:0.003364271205617615\n",
      "train loss:0.010937708978456924\n",
      "train loss:0.006696224669339275\n",
      "train loss:0.014679439935989233\n",
      "train loss:0.009766651386707135\n",
      "train loss:0.006081921647690884\n",
      "train loss:0.08204250244678656\n",
      "train loss:0.030850712017803553\n",
      "train loss:0.004149784222809188\n",
      "train loss:0.005465657998016182\n",
      "train loss:0.007496685733331188\n",
      "train loss:0.00960687489761013\n",
      "train loss:0.0067158232086404175\n",
      "train loss:0.010177002143290243\n",
      "train loss:0.01161683879313829\n",
      "train loss:0.031611999422190375\n",
      "train loss:0.017346394468497603\n",
      "train loss:0.0009444166443289236\n",
      "train loss:0.0021413028929571885\n",
      "train loss:0.18476500859786948\n",
      "train loss:0.0017806787545444017\n",
      "train loss:0.05132594691367705\n",
      "train loss:0.02545617761336213\n",
      "train loss:0.0042594489718299645\n",
      "train loss:0.02105521955281561\n",
      "train loss:0.008913952006977633\n",
      "train loss:0.015268768669704174\n",
      "train loss:0.02933947781051631\n",
      "train loss:0.0056614457046336155\n",
      "train loss:0.004638011235321569\n",
      "train loss:0.01617858530871553\n",
      "train loss:0.029578314089737896\n",
      "train loss:0.0046296683048381165\n",
      "train loss:0.003915773727934365\n",
      "train loss:0.019158277407480884\n",
      "train loss:0.005881240942102978\n",
      "train loss:0.0051425609019763695\n",
      "train loss:0.00455366242170121\n",
      "train loss:0.03218930707071305\n",
      "train loss:0.014405061363280236\n",
      "train loss:0.005983599235882261\n",
      "train loss:0.02674859102153011\n",
      "train loss:0.015815156494555675\n",
      "train loss:0.030014106680781628\n",
      "train loss:0.009615473144627193\n",
      "train loss:0.011779337270660195\n",
      "train loss:0.004238471628185736\n",
      "train loss:0.0780145056736098\n",
      "train loss:0.01119393637034258\n",
      "train loss:0.006486464108716221\n",
      "train loss:0.0032163651913395637\n",
      "train loss:0.00396514930742607\n",
      "train loss:0.00939713492122952\n",
      "train loss:0.015611714944258953\n",
      "train loss:0.004144496244082001\n",
      "train loss:0.001631003579607139\n",
      "train loss:0.006666794343371894\n",
      "train loss:0.016778229851019663\n",
      "train loss:0.014152117024096014\n",
      "train loss:0.004843903669064949\n",
      "train loss:0.01076598338712362\n",
      "train loss:0.02776904068037391\n",
      "train loss:0.005678800813215065\n",
      "train loss:0.004823211274980363\n",
      "train loss:0.019972917039644315\n",
      "train loss:0.005473848969267409\n",
      "train loss:0.006533572528128329\n",
      "train loss:0.012987567900532272\n",
      "train loss:0.005791042506699751\n",
      "train loss:0.010465674581129005\n",
      "train loss:0.03154647340591879\n",
      "train loss:0.03599034289905585\n",
      "train loss:0.01297984767507827\n",
      "train loss:0.05905818350686079\n",
      "train loss:0.010772037356762769\n",
      "train loss:0.012271634884278976\n",
      "train loss:0.0372218038945571\n",
      "train loss:0.00678182349250265\n",
      "train loss:0.002627713118021206\n",
      "train loss:0.01144454718853358\n",
      "train loss:0.011998544042700654\n",
      "train loss:0.041746629418461884\n",
      "train loss:0.0428183057414012\n",
      "train loss:0.011861098004956026\n",
      "train loss:0.006590968743693954\n",
      "train loss:0.006065848312316102\n",
      "train loss:0.0261570678038529\n",
      "train loss:0.051812224795394365\n",
      "train loss:0.014804385544039747\n",
      "train loss:0.006333561058694509\n",
      "train loss:0.01239071300700342\n",
      "train loss:0.00668111596717895\n",
      "train loss:0.009156110392468607\n",
      "train loss:0.023050109853553796\n",
      "train loss:0.020252919531802055\n",
      "train loss:0.0028344321293038623\n",
      "train loss:0.010614439354733876\n",
      "train loss:0.019353167299138142\n",
      "train loss:0.04395574499962881\n",
      "train loss:0.04699617124064996\n",
      "train loss:0.00497217131146704\n",
      "train loss:0.02101099288220717\n",
      "train loss:0.007966908616427432\n",
      "train loss:0.02359542507350046\n",
      "train loss:0.018327778903407893\n",
      "train loss:0.004244773654311461\n",
      "train loss:0.026691818824769266\n",
      "train loss:0.014819012805558219\n",
      "train loss:0.036359494707123935\n",
      "train loss:0.0328768746831388\n",
      "train loss:0.01545393464372119\n",
      "train loss:0.003825943351084909\n",
      "train loss:0.0193447921680855\n",
      "train loss:0.010562738370741261\n",
      "train loss:0.0030244251593950517\n",
      "train loss:0.002837753443869721\n",
      "train loss:0.0027238731525906458\n",
      "train loss:0.10061608282859794\n",
      "train loss:0.01046648417717563\n",
      "train loss:0.0031699751299304095\n",
      "train loss:0.013657079656599928\n",
      "train loss:0.03237639672586256\n",
      "train loss:0.006408356569842458\n",
      "train loss:0.005453938136809927\n",
      "train loss:0.009973206218448294\n",
      "train loss:0.00268156039862012\n",
      "train loss:0.0045143267066520025\n",
      "train loss:0.004444273917946219\n",
      "train loss:0.0026477514422403687\n",
      "train loss:0.004384640205511547\n",
      "train loss:0.010345210791783785\n",
      "train loss:0.0025764441407348025\n",
      "train loss:0.019194756216393362\n",
      "train loss:0.017344532362592716\n",
      "train loss:0.013057231651910708\n",
      "train loss:0.007736719792144631\n",
      "train loss:0.01340136941370359\n",
      "train loss:0.005573895698471551\n",
      "train loss:0.004429044071285173\n",
      "train loss:0.0036287073738996227\n",
      "train loss:0.004699997660748897\n",
      "train loss:0.004963914461563706\n",
      "train loss:0.00424925259132214\n",
      "train loss:0.005287251870880497\n",
      "train loss:0.011599046401519915\n",
      "train loss:0.008964172413153592\n",
      "train loss:0.020933980518411655\n",
      "train loss:0.012104358775832462\n",
      "train loss:0.010502930305929142\n",
      "train loss:0.004409804871932132\n",
      "train loss:0.017827898303976176\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.003949580273180943\n",
      "train loss:0.004944025319641698\n",
      "train loss:0.01219476280537529\n",
      "train loss:0.003422915993727605\n",
      "train loss:0.0012309346831391628\n",
      "train loss:0.01452196482281564\n",
      "train loss:0.003082614033064626\n",
      "train loss:0.005266290624489312\n",
      "train loss:0.004045265284418027\n",
      "train loss:0.01020701448194997\n",
      "train loss:0.041775921560267576\n",
      "train loss:0.006224880229626032\n",
      "train loss:0.07384702445361536\n",
      "train loss:0.022570489231727144\n",
      "train loss:0.028233638958069802\n",
      "train loss:0.004767052879068566\n",
      "train loss:0.0027802778977635877\n",
      "train loss:0.008476954079778116\n",
      "train loss:0.004832161337075284\n",
      "train loss:0.17015372763481043\n",
      "train loss:0.014139812068786374\n",
      "train loss:0.00517154221571672\n",
      "train loss:0.005928969348592839\n",
      "train loss:0.016764598896008273\n",
      "train loss:0.001197707008388456\n",
      "train loss:0.02172494156913276\n",
      "train loss:0.02744639279360169\n",
      "train loss:0.006636276043886808\n",
      "train loss:0.0051511129051531246\n",
      "train loss:0.00971543501878282\n",
      "train loss:0.015436869718919593\n",
      "train loss:0.0035715903920829468\n",
      "train loss:0.014939653353404107\n",
      "train loss:0.004849165483192934\n",
      "train loss:0.005401222089677307\n",
      "train loss:0.011828714602379449\n",
      "train loss:0.04603398739874517\n",
      "train loss:0.0031249939704723604\n",
      "train loss:0.016914364898449753\n",
      "train loss:0.003502648374787553\n",
      "train loss:0.003398772247216928\n",
      "train loss:0.014349376506082513\n",
      "train loss:0.007355188801154313\n",
      "train loss:0.022293916235002972\n",
      "train loss:0.01220551125426891\n",
      "train loss:0.0066417437500696\n",
      "train loss:0.012181478194471207\n",
      "train loss:0.007237264566776669\n",
      "train loss:0.00354478010593156\n",
      "train loss:0.012833091506852762\n",
      "train loss:0.005614743258302702\n",
      "train loss:0.0024439053194695525\n",
      "train loss:0.020803441408218472\n",
      "train loss:0.0012206767016008833\n",
      "train loss:0.009624113194906416\n",
      "train loss:0.005548264072180373\n",
      "train loss:0.08052327212438731\n",
      "train loss:0.010052135909158055\n",
      "train loss:0.022776761755829253\n",
      "train loss:0.022161248271850623\n",
      "train loss:0.0035637368514886652\n",
      "train loss:0.007607378543447183\n",
      "train loss:0.006458351606594197\n",
      "train loss:0.01761970197550976\n",
      "train loss:0.011012892250388914\n",
      "train loss:0.0351289419262173\n",
      "train loss:0.015886565202875732\n",
      "train loss:0.004775084468355214\n",
      "train loss:0.005393302906742698\n",
      "train loss:0.005073165649776518\n",
      "train loss:0.06171582003311557\n",
      "train loss:0.0045825415137958295\n",
      "train loss:0.001506389483436838\n",
      "train loss:0.008363836117776495\n",
      "train loss:0.012960477988814003\n",
      "train loss:0.007735737052577392\n",
      "train loss:0.005893216065677189\n",
      "train loss:0.014667728984346436\n",
      "train loss:0.017188357389851947\n",
      "train loss:0.0013397504870044858\n",
      "train loss:0.0038181824748995253\n",
      "train loss:0.012069224046175154\n",
      "train loss:0.004621221349026241\n",
      "train loss:0.014354516240026947\n",
      "train loss:0.013515556301499098\n",
      "train loss:0.006937395023221405\n",
      "train loss:0.03227050360659977\n",
      "train loss:0.021328731703049223\n",
      "train loss:0.0026372597536497523\n",
      "train loss:0.014668552968315091\n",
      "train loss:0.014621774905918284\n",
      "train loss:0.018375474320050086\n",
      "train loss:0.006219788329244917\n",
      "train loss:0.007120406139139296\n",
      "train loss:0.005983306332791991\n",
      "train loss:0.0037948545212006845\n",
      "train loss:0.02754655668198613\n",
      "train loss:0.018239360114057235\n",
      "train loss:0.011909827712831863\n",
      "train loss:0.05327963229560472\n",
      "train loss:0.017958748140750887\n",
      "train loss:0.0038640212544769474\n",
      "train loss:0.0029257734069328034\n",
      "train loss:0.025285347192428177\n",
      "train loss:0.011898325778909003\n",
      "train loss:0.028040099040757736\n",
      "train loss:0.004719526037841576\n",
      "train loss:0.023435391061642517\n",
      "train loss:0.007027700173639463\n",
      "train loss:0.06698114246397883\n",
      "train loss:0.027506623084148165\n",
      "train loss:0.004260442345499141\n",
      "train loss:0.007262948682397455\n",
      "train loss:0.008780782699040882\n",
      "train loss:0.007858364744100278\n",
      "train loss:0.0052736651424856685\n",
      "train loss:0.013630196455328336\n",
      "train loss:0.04990774950320644\n",
      "train loss:0.010274771781961244\n",
      "train loss:0.009629561676285387\n",
      "train loss:0.015832108496086718\n",
      "train loss:0.0050868310554118045\n",
      "train loss:0.002727231795687526\n",
      "train loss:0.0062157780105929015\n",
      "train loss:0.01029046867800081\n",
      "train loss:0.07072755607191658\n",
      "train loss:0.013431173636937252\n",
      "train loss:0.008767384689934347\n",
      "train loss:0.02317215746516821\n",
      "train loss:0.01244232575852207\n",
      "train loss:0.00442327200867173\n",
      "train loss:0.020149008911576383\n",
      "train loss:0.0020880992397159866\n",
      "train loss:0.041762081200524354\n",
      "train loss:0.019386758801796574\n",
      "train loss:0.001193154041995826\n",
      "train loss:0.03592645654811719\n",
      "train loss:0.004039331330387364\n",
      "train loss:0.058046997370927805\n",
      "train loss:0.0014246208264946053\n",
      "train loss:0.0130124160231975\n",
      "train loss:0.010068293071310687\n",
      "train loss:0.013171509816847466\n",
      "train loss:0.008378178094799701\n",
      "train loss:0.06176271168316963\n",
      "train loss:0.018732826352760943\n",
      "train loss:0.04513170600137723\n",
      "train loss:0.011612861001522066\n",
      "train loss:0.009677069789116364\n",
      "train loss:0.023716168374481365\n",
      "train loss:0.022505561396996138\n",
      "train loss:0.012141624225806565\n",
      "train loss:0.023238376320746754\n",
      "train loss:0.008458944688840352\n",
      "train loss:0.01966899130871747\n",
      "train loss:0.009640588616289197\n",
      "train loss:0.005027170661564292\n",
      "train loss:0.005466493023065758\n",
      "train loss:0.02391858474851008\n",
      "train loss:0.0038372878686327105\n",
      "train loss:0.00480003308668511\n",
      "train loss:0.007320470077577816\n",
      "train loss:0.002810926459486583\n",
      "train loss:0.011296238017119596\n",
      "train loss:0.012612413574329543\n",
      "train loss:0.013694757174188889\n",
      "train loss:0.014634446483996604\n",
      "train loss:0.006188475856042055\n",
      "train loss:0.009929559934283159\n",
      "train loss:0.003169639993922652\n",
      "train loss:0.00733254978930082\n",
      "train loss:0.005297868115991144\n",
      "train loss:0.01363789112769563\n",
      "train loss:0.005583891074322535\n",
      "train loss:0.05043343896638822\n",
      "train loss:0.027453654300618666\n",
      "train loss:0.08525090374014094\n",
      "train loss:0.008925739944490467\n",
      "train loss:0.01173111334420062\n",
      "train loss:0.024331682587408986\n",
      "train loss:0.006564102015848866\n",
      "train loss:0.010020525340289282\n",
      "train loss:0.05377413325440943\n",
      "train loss:0.009159123483888955\n",
      "train loss:0.00948210708590316\n",
      "train loss:0.01866527337362361\n",
      "train loss:0.013643024023882488\n",
      "train loss:0.010845854905808763\n",
      "train loss:0.05524192221789306\n",
      "train loss:0.011401372736527159\n",
      "train loss:0.013692264416019317\n",
      "train loss:0.009940219633847834\n",
      "train loss:0.026759607942162953\n",
      "train loss:0.06445993446582314\n",
      "train loss:0.007092590413586951\n",
      "train loss:0.004907375843116302\n",
      "train loss:0.008034714817583692\n",
      "train loss:0.032548705410402085\n",
      "train loss:0.00851895966663123\n",
      "train loss:0.006673444689412267\n",
      "train loss:0.006696396229876594\n",
      "train loss:0.00878823694648571\n",
      "train loss:0.0028546000028679625\n",
      "train loss:0.007162795576824988\n",
      "train loss:0.012743966835847127\n",
      "train loss:0.055332545126855856\n",
      "train loss:0.009344714267716207\n",
      "train loss:0.006526006813029128\n",
      "train loss:0.010360568757089999\n",
      "train loss:0.011018513806507526\n",
      "train loss:0.008546689853960532\n",
      "train loss:0.012182012581808954\n",
      "train loss:0.012766964229973808\n",
      "train loss:0.02392608778005654\n",
      "train loss:0.002633846332589148\n",
      "train loss:0.05878284695580813\n",
      "train loss:0.00930772449520229\n",
      "train loss:0.0013001742728156324\n",
      "train loss:0.010393328437505985\n",
      "train loss:0.00966508150309793\n",
      "train loss:0.001986058149275735\n",
      "train loss:0.014190796365799466\n",
      "train loss:0.007276913979500342\n",
      "train loss:0.020292256390498836\n",
      "train loss:0.00735990066548653\n",
      "train loss:0.02125816978305926\n",
      "train loss:0.01071931720935556\n",
      "train loss:0.0451973760117229\n",
      "train loss:0.005177326422374057\n",
      "train loss:0.004530379509445405\n",
      "train loss:0.002568197442045397\n",
      "train loss:0.002794137486608722\n",
      "train loss:0.009101097539714198\n",
      "train loss:0.017239207164149017\n",
      "train loss:0.017920260464155024\n",
      "train loss:0.0317947171354994\n",
      "train loss:0.004756760698056432\n",
      "train loss:0.0011959189203986887\n",
      "train loss:0.01436779052021735\n",
      "train loss:0.0019803386060790102\n",
      "train loss:0.00394377043449764\n",
      "train loss:0.006160768213087863\n",
      "train loss:0.03452855071688838\n",
      "train loss:0.005730214777658678\n",
      "train loss:0.015435925988172894\n",
      "train loss:0.01617865657250062\n",
      "train loss:0.015316820161371252\n",
      "train loss:0.006335647866269557\n",
      "train loss:0.004076835001777667\n",
      "train loss:0.04482270597668711\n",
      "train loss:0.007969731823024876\n",
      "train loss:0.003994797661303095\n",
      "train loss:0.002622602785623415\n",
      "train loss:0.005193937615210321\n",
      "train loss:0.01576375662887828\n",
      "train loss:0.006051662506654245\n",
      "train loss:0.0014872097106030163\n",
      "train loss:0.011654185076808859\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.012312423547333888\n",
      "train loss:0.0018039800434920116\n",
      "train loss:0.005882921333672374\n",
      "train loss:0.004231263217520952\n",
      "train loss:0.0030404312479010032\n",
      "train loss:0.0045605253886168914\n",
      "train loss:0.006762373821644516\n",
      "train loss:0.017984125143004244\n",
      "train loss:0.0016500988065330186\n",
      "=== epoch:8, train acc:0.987, test acc:0.98 ===\n",
      "train loss:0.04204537579793613\n",
      "train loss:0.01692108939616748\n",
      "train loss:0.013430452598682302\n",
      "train loss:0.004584506417981347\n",
      "train loss:0.005853608139531988\n",
      "train loss:0.006535591900286816\n",
      "train loss:0.014327558732002497\n",
      "train loss:0.033347484831859814\n",
      "train loss:0.02469011622532495\n",
      "train loss:0.009182985492388933\n",
      "train loss:0.010269125942597834\n",
      "train loss:0.021048806666877286\n",
      "train loss:0.009544812734280542\n",
      "train loss:0.000740505152760951\n",
      "train loss:0.01970931960518856\n",
      "train loss:0.01593410775422509\n",
      "train loss:0.002389985042259871\n",
      "train loss:0.008966229413833064\n",
      "train loss:0.01282565249564073\n",
      "train loss:0.0016938453659788733\n",
      "train loss:0.006584413330151009\n",
      "train loss:0.02135798115592427\n",
      "train loss:0.017868008786299377\n",
      "train loss:0.024207759651741427\n",
      "train loss:0.0007418055286052144\n",
      "train loss:0.007089529998042171\n",
      "train loss:0.0016096983519175326\n",
      "train loss:0.006852901228504526\n",
      "train loss:0.028870380375413684\n",
      "train loss:0.032535079916219234\n",
      "train loss:0.01244663118864885\n",
      "train loss:0.011612109866921355\n",
      "train loss:0.0060670803804572316\n",
      "train loss:0.012993233550620549\n",
      "train loss:0.01816785948929031\n",
      "train loss:0.031067954331102356\n",
      "train loss:0.045624941245994526\n",
      "train loss:0.016896296332516558\n",
      "train loss:0.004656790766343303\n",
      "train loss:0.01823617181377142\n",
      "train loss:0.005525148338742268\n",
      "train loss:0.027625757662165778\n",
      "train loss:0.025483414697792816\n",
      "train loss:0.005168497175231335\n",
      "train loss:0.018748015959140676\n",
      "train loss:0.005410244304815823\n",
      "train loss:0.00523801280145117\n",
      "train loss:0.012902100044299886\n",
      "train loss:0.0038985829178947527\n",
      "train loss:0.002947164460593567\n",
      "train loss:0.02060440461668588\n",
      "train loss:0.14767579207455878\n",
      "train loss:0.005184818253366309\n",
      "train loss:0.004538321705386207\n",
      "train loss:0.00669487174857582\n",
      "train loss:0.008079890914737065\n",
      "train loss:0.008052988485750047\n",
      "train loss:0.004147563349288964\n",
      "train loss:0.012400983863384228\n",
      "train loss:0.006291407555447638\n",
      "train loss:0.007220226195970376\n",
      "train loss:0.002177702158445266\n",
      "train loss:0.06481790861769028\n",
      "train loss:0.007258971263692695\n",
      "train loss:0.002992730745237695\n",
      "train loss:0.01748885586821233\n",
      "train loss:0.004422449596727281\n",
      "train loss:0.023200642162923328\n",
      "train loss:0.004110251032091\n",
      "train loss:0.0037890985757522864\n",
      "train loss:0.005550585856426222\n",
      "train loss:0.0022569818898979972\n",
      "train loss:0.0047375157995750835\n",
      "train loss:0.03429069927086374\n",
      "train loss:0.00826733402218713\n",
      "train loss:0.016483337993747904\n",
      "train loss:0.015061284139243552\n",
      "train loss:0.020923265509597083\n",
      "train loss:0.0030382882543683177\n",
      "train loss:0.0073314711930231235\n",
      "train loss:0.006193765461458783\n",
      "train loss:0.015530507880914821\n",
      "train loss:0.01614562752802487\n",
      "train loss:0.003830438022628868\n",
      "train loss:0.0018215284013384878\n",
      "train loss:0.0088810259417545\n",
      "train loss:0.008424742862850191\n",
      "train loss:0.014250877202325651\n",
      "train loss:0.003843662309560496\n",
      "train loss:0.00731780196198693\n",
      "train loss:0.00893014317304334\n",
      "train loss:0.008333331971317\n",
      "train loss:0.01683931878982618\n",
      "train loss:0.00808802351399158\n",
      "train loss:0.00726251032019481\n",
      "train loss:0.012505418256519185\n",
      "train loss:0.0042959526456831125\n",
      "train loss:0.01662665519153171\n",
      "train loss:0.0163215759246984\n",
      "train loss:0.004893279708621664\n",
      "train loss:0.013618130141785282\n",
      "train loss:0.0018175172948771206\n",
      "train loss:0.0019202373421482069\n",
      "train loss:0.015312362652955953\n",
      "train loss:0.003193172029006503\n",
      "train loss:0.005379587439014329\n",
      "train loss:0.006408976183169308\n",
      "train loss:0.018607059879342875\n",
      "train loss:0.0032471458407972\n",
      "train loss:0.01726132296103884\n",
      "train loss:0.00715923743675056\n",
      "train loss:0.01494978286423158\n",
      "train loss:0.00945425603115207\n",
      "train loss:0.0008108218921342731\n",
      "train loss:0.018926117883912272\n",
      "train loss:0.0025589756481897196\n",
      "train loss:0.0011839481014334866\n",
      "train loss:0.09680756460339955\n",
      "train loss:0.014244611243132825\n",
      "train loss:0.006515600213574132\n",
      "train loss:0.004627576966981476\n",
      "train loss:0.023075083616446068\n",
      "train loss:0.01174751024596927\n",
      "train loss:0.004036096884161722\n",
      "train loss:0.05562986731382363\n",
      "train loss:0.014732149540763365\n",
      "train loss:0.00986758968735502\n",
      "train loss:0.006281743062896888\n",
      "train loss:0.007643835922071979\n",
      "train loss:0.009236223324582318\n",
      "train loss:0.014684083453751488\n",
      "train loss:0.014765666210271873\n",
      "train loss:0.01493684416611373\n",
      "train loss:0.007078659200394418\n",
      "train loss:0.010589350590848123\n",
      "train loss:0.0023642126118377472\n",
      "train loss:0.005847414877732718\n",
      "train loss:0.013000808313451734\n",
      "train loss:0.0022975166683391456\n",
      "train loss:0.06901550074602367\n",
      "train loss:0.03382771107043041\n",
      "train loss:0.0055822557324031056\n",
      "train loss:0.027976075783993658\n",
      "train loss:0.010041552873557956\n",
      "train loss:0.019882721582899502\n",
      "train loss:0.005794896568790014\n",
      "train loss:0.007320024624007836\n",
      "train loss:0.007292298453336259\n",
      "train loss:0.03675868972253369\n",
      "train loss:0.0011087284704115535\n",
      "train loss:0.010153454092677235\n",
      "train loss:0.01975426443509746\n",
      "train loss:0.024417381351447956\n",
      "train loss:0.017923344445235165\n",
      "train loss:0.024243743718378313\n",
      "train loss:0.027527986841898732\n",
      "train loss:0.0035958956632526906\n",
      "train loss:0.016749238956340645\n",
      "train loss:0.01008897055567942\n",
      "train loss:0.006676192606385163\n",
      "train loss:0.004732590152575259\n",
      "train loss:0.011757218599864321\n",
      "train loss:0.0027390196175830933\n",
      "train loss:0.007451271794022455\n",
      "train loss:0.04991746924094762\n",
      "train loss:0.007569623714317748\n",
      "train loss:0.013534298847296938\n",
      "train loss:0.01892719150538972\n",
      "train loss:0.014671227850736601\n",
      "train loss:0.002046254601662246\n",
      "train loss:0.055509766357909\n",
      "train loss:0.00688109549962018\n",
      "train loss:0.022526882232032946\n",
      "train loss:0.009804893900166183\n",
      "train loss:0.005818164960618852\n",
      "train loss:0.007704984360510783\n",
      "train loss:0.007990017481481171\n",
      "train loss:0.0062861281784572275\n",
      "train loss:0.0030355910151663294\n",
      "train loss:0.005838102062123384\n",
      "train loss:0.0030278005377957014\n",
      "train loss:0.013570315149493285\n",
      "train loss:0.008752028642853507\n",
      "train loss:0.013214679303109373\n",
      "train loss:0.01129757147317773\n",
      "train loss:0.014260366574930072\n",
      "train loss:0.0038785555285017308\n",
      "train loss:0.0034015133200944636\n",
      "train loss:0.004525007083643697\n",
      "train loss:0.019221862636759842\n",
      "train loss:0.0030190121068202646\n",
      "train loss:0.005844275844118504\n",
      "train loss:0.008498843956737325\n",
      "train loss:0.005043139880392364\n",
      "train loss:0.004066388171797496\n",
      "train loss:0.01376041385679111\n",
      "train loss:0.007878109288962385\n",
      "train loss:0.006179684212807556\n",
      "train loss:0.014205652967122373\n",
      "train loss:0.01311223390808623\n",
      "train loss:0.007965436079814063\n",
      "train loss:0.02090552034147032\n",
      "train loss:0.005107680153047023\n",
      "train loss:0.04589347832188607\n",
      "train loss:0.004957249776613561\n",
      "train loss:0.0016716718699307533\n",
      "train loss:0.009966718705072753\n",
      "train loss:0.0475979147492678\n",
      "train loss:0.004248152718134012\n",
      "train loss:0.0013810415547277491\n",
      "train loss:0.04901242177209448\n",
      "train loss:0.002312933835659595\n",
      "train loss:0.015622807164961934\n",
      "train loss:0.0040176462160306315\n",
      "train loss:0.009879522074927444\n",
      "train loss:0.012825662998734355\n",
      "train loss:0.006001202435251738\n",
      "train loss:0.0022710056859339004\n",
      "train loss:0.014489700666867878\n",
      "train loss:0.008012287412308937\n",
      "train loss:0.00453933438140025\n",
      "train loss:0.01140922496688648\n",
      "train loss:0.006589284440595929\n",
      "train loss:0.017312817506044735\n",
      "train loss:0.004795264677653253\n",
      "train loss:0.003144539425159027\n",
      "train loss:0.008977877784692\n",
      "train loss:0.004261774892502207\n",
      "train loss:0.009501035028497173\n",
      "train loss:0.053392915878426185\n",
      "train loss:0.006696841314721792\n",
      "train loss:0.021795773314234546\n",
      "train loss:0.012652184105964987\n",
      "train loss:0.0287589057313521\n",
      "train loss:0.019097322803427547\n",
      "train loss:0.003210568356730698\n",
      "train loss:0.007924396439647414\n",
      "train loss:0.005163009132221011\n",
      "train loss:0.006015816646577751\n",
      "train loss:0.01786765092377353\n",
      "train loss:0.005239126195274255\n",
      "train loss:0.033126820972240616\n",
      "train loss:0.07827383046633768\n",
      "train loss:0.013351804670730083\n",
      "train loss:0.03023114919448086\n",
      "train loss:0.01692513640863855\n",
      "train loss:0.009094822991185674\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.011922561575148406\n",
      "train loss:0.008326653497146081\n",
      "train loss:0.003304519510130727\n",
      "train loss:0.0009853418345784168\n",
      "train loss:0.019811271214996862\n",
      "train loss:0.007470029770471558\n",
      "train loss:0.0036635682468563265\n",
      "train loss:0.0038993549645046288\n",
      "train loss:0.0023672511316596774\n",
      "train loss:0.005818638435802739\n",
      "train loss:0.04574477751345942\n",
      "train loss:0.004196524657952825\n",
      "train loss:0.007606648033974623\n",
      "train loss:0.09491266802862972\n",
      "train loss:0.026405044245459232\n",
      "train loss:0.01678517902170219\n",
      "train loss:0.016859354634734747\n",
      "train loss:0.00495554857320071\n",
      "train loss:0.004227390558873079\n",
      "train loss:0.03867601975866563\n",
      "train loss:0.054884356064776416\n",
      "train loss:0.011047482284539072\n",
      "train loss:0.02358116766773569\n",
      "train loss:0.0017934100442338816\n",
      "train loss:0.034648455189675846\n",
      "train loss:0.0047242132964123\n",
      "train loss:0.009631438860753539\n",
      "train loss:0.004204428297129179\n",
      "train loss:0.002684509975214257\n",
      "train loss:0.012500123714752414\n",
      "train loss:0.010833925259742581\n",
      "train loss:0.006670133366120229\n",
      "train loss:0.0745398103848391\n",
      "train loss:0.012440081036459369\n",
      "train loss:0.020908032916989207\n",
      "train loss:0.11265127650765887\n",
      "train loss:0.021123175517582155\n",
      "train loss:0.01984728487840594\n",
      "train loss:0.008119101281679482\n",
      "train loss:0.007376220553426968\n",
      "train loss:0.009024214278725073\n",
      "train loss:0.007657812256868169\n",
      "train loss:0.007324769743507581\n",
      "train loss:0.013520683079322077\n",
      "train loss:0.008040894932808471\n",
      "train loss:0.00824702143621248\n",
      "train loss:0.01270032254533735\n",
      "train loss:0.002751799045902418\n",
      "train loss:0.009781910899076344\n",
      "train loss:0.0018784823249574003\n",
      "train loss:0.024106339200712007\n",
      "train loss:0.048123912088757895\n",
      "train loss:0.0077843773715172175\n",
      "train loss:0.0027551344048894273\n",
      "train loss:0.010583923517670301\n",
      "train loss:0.021220595472640307\n",
      "train loss:0.002158355500785263\n",
      "train loss:0.00572306031120799\n",
      "train loss:0.004904661497165521\n",
      "train loss:0.021342893588430903\n",
      "train loss:0.006511531917434588\n",
      "train loss:0.007388094555103058\n",
      "train loss:0.019805667833448625\n",
      "train loss:0.004649277617359852\n",
      "train loss:0.003698436977244549\n",
      "train loss:0.017156317118717603\n",
      "train loss:0.04730037379172164\n",
      "train loss:0.021746666746068975\n",
      "train loss:0.002430741646635138\n",
      "train loss:0.0452997789089567\n",
      "train loss:0.003638029423360648\n",
      "train loss:0.03354170429812106\n",
      "train loss:0.003024176941813718\n",
      "train loss:0.006150173951174973\n",
      "train loss:0.004040272851568436\n",
      "train loss:0.0072261301942749745\n",
      "train loss:0.006315586737539388\n",
      "train loss:0.021461715230592354\n",
      "train loss:0.00789482820110546\n",
      "train loss:0.0033847411507587593\n",
      "train loss:0.005009679364489233\n",
      "train loss:0.04273752202151432\n",
      "train loss:0.003322044966221407\n",
      "train loss:0.05757494849965089\n",
      "train loss:0.007112592743273558\n",
      "train loss:0.010537117423695204\n",
      "train loss:0.00857145305618018\n",
      "train loss:0.005110148770393479\n",
      "train loss:0.012532151797090227\n",
      "train loss:0.006965593145420676\n",
      "train loss:0.003423298422405999\n",
      "train loss:0.0653610432057549\n",
      "train loss:0.015179894316791431\n",
      "train loss:0.029687553030394897\n",
      "train loss:0.0016524034326634623\n",
      "train loss:0.003897054094424963\n",
      "train loss:0.015319973044011854\n",
      "train loss:0.004788006450668524\n",
      "train loss:0.003976035825691011\n",
      "train loss:0.01587415347077992\n",
      "train loss:0.03328574719521979\n",
      "train loss:0.0024616042190429514\n",
      "train loss:0.013750017282727203\n",
      "train loss:0.0008363610767873336\n",
      "train loss:0.007982711827553217\n",
      "train loss:0.017425153256769656\n",
      "train loss:0.007156819314066687\n",
      "train loss:0.01068474038465792\n",
      "train loss:0.009569505329526263\n",
      "train loss:0.0009035806119080969\n",
      "train loss:0.026038881873864102\n",
      "train loss:0.0010816447165763027\n",
      "train loss:0.006332876726674158\n",
      "train loss:0.0024480852518187473\n",
      "train loss:0.003369003150150032\n",
      "train loss:0.008072763467025927\n",
      "train loss:0.0060675392239180805\n",
      "train loss:0.016612532908549214\n",
      "train loss:0.00141371058478323\n",
      "train loss:0.006024331062765752\n",
      "train loss:0.0052367420974602785\n",
      "train loss:0.0065737650652999725\n",
      "train loss:0.022554019915978274\n",
      "train loss:0.012645966932324426\n",
      "train loss:0.013686720545057181\n",
      "train loss:0.0012361574757236906\n",
      "train loss:0.011228539306373447\n",
      "train loss:0.008248740667729858\n",
      "train loss:0.00936889231176367\n",
      "train loss:0.006185322635615157\n",
      "train loss:0.027650872564962833\n",
      "train loss:0.00101282021352371\n",
      "train loss:0.016336415700499974\n",
      "train loss:0.017723678962324692\n",
      "train loss:0.004905530747627071\n",
      "train loss:0.003944832872576248\n",
      "train loss:0.0062012073474372155\n",
      "train loss:0.0049567669109009446\n",
      "train loss:0.003255459223142064\n",
      "train loss:0.0017580703443430725\n",
      "train loss:0.011007786163251519\n",
      "train loss:0.00772818963110447\n",
      "train loss:0.007946285959057872\n",
      "train loss:0.004693935886890009\n",
      "train loss:0.009693315369671414\n",
      "train loss:0.0065437837088222215\n",
      "train loss:0.004547535720702739\n",
      "train loss:0.0035343772623511426\n",
      "train loss:0.00887552388299462\n",
      "train loss:0.012243797411055714\n",
      "train loss:0.0075684843503205715\n",
      "train loss:0.0077025174770574585\n",
      "train loss:0.003986304550778829\n",
      "train loss:0.014180491124621672\n",
      "train loss:0.004303543532085018\n",
      "train loss:0.0053424857580900735\n",
      "train loss:0.009285833226284842\n",
      "train loss:0.008565032579868768\n",
      "train loss:0.0063900882803455674\n",
      "train loss:0.01002410945413717\n",
      "train loss:0.002987116895292125\n",
      "train loss:0.008272393080164406\n",
      "train loss:0.0020580192108628588\n",
      "train loss:0.007040664155162888\n",
      "train loss:0.01647687062613916\n",
      "train loss:0.006642664979603063\n",
      "train loss:0.0026219596978939875\n",
      "train loss:0.0013908176233073338\n",
      "train loss:0.01073346784417949\n",
      "train loss:0.003750469489872245\n",
      "train loss:0.003488422623441006\n",
      "train loss:0.04881433746273799\n",
      "train loss:0.01970219166670016\n",
      "train loss:0.0020047149257023983\n",
      "train loss:0.012413348867267082\n",
      "train loss:0.0073893173372793115\n",
      "train loss:0.0009643886232152335\n",
      "train loss:0.005385597519222243\n",
      "train loss:0.0018306148807973174\n",
      "train loss:0.011873062727213677\n",
      "train loss:0.005724912090698249\n",
      "train loss:0.0016164069891844428\n",
      "train loss:0.0022587276117302106\n",
      "train loss:0.008293955725809987\n",
      "train loss:0.004964952166431762\n",
      "train loss:0.017601506868582507\n",
      "train loss:0.001952396728866599\n",
      "train loss:0.014044688382782953\n",
      "train loss:0.0019630991986815506\n",
      "train loss:0.004306309777210757\n",
      "train loss:0.013980760236580948\n",
      "train loss:0.016584899764799276\n",
      "train loss:0.016574124080573193\n",
      "train loss:0.005613898457041315\n",
      "train loss:0.00429067309731254\n",
      "train loss:0.016307323022383576\n",
      "train loss:0.0013196562914494505\n",
      "train loss:0.0032695798363096516\n",
      "train loss:0.009228024718484181\n",
      "train loss:0.014360636386185186\n",
      "train loss:0.014182117795425815\n",
      "train loss:0.030514629210257927\n",
      "train loss:0.01300762676810939\n",
      "train loss:0.009521735215694443\n",
      "train loss:0.031068336196271997\n",
      "train loss:0.08283168397673446\n",
      "train loss:0.033054938025696104\n",
      "train loss:0.039922316155765324\n",
      "train loss:0.0011345887954349323\n",
      "train loss:0.008605820320338683\n",
      "train loss:0.010188760972829584\n",
      "train loss:0.014669731736099147\n",
      "train loss:0.010949430454583091\n",
      "train loss:0.0013897639331590867\n",
      "train loss:0.01154115156788791\n",
      "train loss:0.036560676530419854\n",
      "train loss:0.001901412355255597\n",
      "train loss:0.0063373019097735395\n",
      "train loss:0.003675503302960445\n",
      "train loss:0.02178429200836012\n",
      "train loss:0.022917751206293403\n",
      "train loss:0.06021235873388544\n",
      "train loss:0.0038310116046151193\n",
      "train loss:0.0053212884982143495\n",
      "train loss:0.007553280607155908\n",
      "train loss:0.007556406082210872\n",
      "train loss:0.02766798527361565\n",
      "train loss:0.0060439728832913445\n",
      "train loss:0.005111506763596072\n",
      "train loss:0.022201993586088365\n",
      "train loss:0.014018536594622629\n",
      "train loss:0.08294664758331084\n",
      "train loss:0.004589982066050724\n",
      "train loss:0.002568046520851285\n",
      "train loss:0.018096522115448776\n",
      "train loss:0.022457869401042087\n",
      "train loss:0.01057486980009752\n",
      "train loss:0.004377668225251372\n",
      "train loss:0.03652066632969999\n",
      "train loss:0.011515121647671307\n",
      "train loss:0.007350404760170565\n",
      "train loss:0.005108527900899011\n",
      "train loss:0.026733871771144647\n",
      "train loss:0.006116780213514891\n",
      "train loss:0.015205280022030811\n",
      "train loss:0.029006015330218828\n",
      "train loss:0.0025467937092008798\n",
      "train loss:0.005651568414177015\n",
      "train loss:0.00256160286912873\n",
      "train loss:0.011145332297654043\n",
      "train loss:0.005281551370506285\n",
      "train loss:0.04100966505801917\n",
      "train loss:0.011453571765466606\n",
      "train loss:0.0242790520016324\n",
      "train loss:0.021539731231036738\n",
      "train loss:0.0006646820637358322\n",
      "train loss:0.010159118975745849\n",
      "train loss:0.010123203765877366\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.0022719748150377772\n",
      "train loss:0.014214021646125816\n",
      "train loss:0.04365636799170849\n",
      "train loss:0.0034558001329208134\n",
      "train loss:0.0015770106146438603\n",
      "train loss:0.0033501794076155485\n",
      "train loss:0.004176133558803694\n",
      "train loss:0.010143393965222108\n",
      "train loss:0.01499114576513448\n",
      "train loss:0.07226030962262316\n",
      "train loss:0.007473534719949847\n",
      "train loss:0.005841993409140619\n",
      "train loss:0.020875127488895914\n",
      "train loss:0.021771387685091636\n",
      "train loss:0.03991958764177972\n",
      "train loss:0.010840156786575952\n",
      "train loss:0.0034277643153108983\n",
      "train loss:0.010145604514405621\n",
      "train loss:0.007416452114293052\n",
      "train loss:0.005590132917946653\n",
      "train loss:0.03006936324823576\n",
      "train loss:0.000776080034887443\n",
      "train loss:0.008061066994926223\n",
      "train loss:0.01303903410621694\n",
      "train loss:0.011948365608358292\n",
      "train loss:0.00677665340288504\n",
      "train loss:0.003227998968081062\n",
      "train loss:0.001955270750997697\n",
      "train loss:0.004021828741460269\n",
      "train loss:0.034126544003742154\n",
      "train loss:0.006294011032700792\n",
      "train loss:0.0007572354474353948\n",
      "train loss:0.055622257267609554\n",
      "train loss:0.004252200959645021\n",
      "train loss:0.09306390104348486\n",
      "train loss:0.001396735918553877\n",
      "train loss:0.01941337194675172\n",
      "train loss:0.010822140999745721\n",
      "train loss:0.053727801039103414\n",
      "train loss:0.015650751977954055\n",
      "train loss:0.04341156454852293\n",
      "train loss:0.05452607140875717\n",
      "train loss:0.0036950695375366858\n",
      "train loss:0.00555663122797443\n",
      "train loss:0.0071006424632727785\n",
      "train loss:0.030281978715844232\n",
      "train loss:0.01896238266375353\n",
      "train loss:0.012063697520163029\n",
      "train loss:0.012990931173315352\n",
      "train loss:0.012182524229235523\n",
      "train loss:0.030562189588764218\n",
      "train loss:0.012300039195714733\n",
      "train loss:0.004937368957858758\n",
      "train loss:0.0025153105308018424\n",
      "train loss:0.008916637931279357\n",
      "train loss:0.006878917896258243\n",
      "train loss:0.013956685939171994\n",
      "train loss:0.002261934493635865\n",
      "train loss:0.0034144780911303284\n",
      "train loss:0.002386092281563118\n",
      "train loss:0.017228988108168454\n",
      "train loss:0.0005141225859058318\n",
      "train loss:0.005050288426296431\n",
      "train loss:0.0023867639309253733\n",
      "train loss:0.01612196943320797\n",
      "train loss:0.042414648541045076\n",
      "train loss:0.0010319151114021614\n",
      "train loss:0.014822943932081946\n",
      "train loss:0.009849399761350984\n",
      "train loss:0.04109536027287494\n",
      "train loss:0.012509652044991158\n",
      "train loss:0.009503408077073984\n",
      "train loss:0.009880990473399376\n",
      "train loss:0.00303767517032477\n",
      "train loss:0.009383363164806412\n",
      "train loss:0.005147718367202615\n",
      "train loss:0.004924566587623269\n",
      "train loss:0.004599320885754618\n",
      "train loss:0.022705956309393236\n",
      "train loss:0.014342996888356637\n",
      "train loss:0.006403601733109456\n",
      "train loss:0.03823012721955609\n",
      "train loss:0.0038656448916532847\n",
      "train loss:0.002437323046659669\n",
      "train loss:0.003119260826605554\n",
      "train loss:0.0076519175004960225\n",
      "train loss:0.034835994876747246\n",
      "train loss:0.0006862518807784017\n",
      "train loss:0.012088223060384878\n",
      "train loss:0.01387560721503537\n",
      "train loss:0.003608409723913127\n",
      "train loss:0.0036162003297088964\n",
      "train loss:0.09495667354002046\n",
      "train loss:0.015571928171295536\n",
      "train loss:0.011926484765746908\n",
      "=== epoch:9, train acc:0.992, test acc:0.979 ===\n",
      "train loss:0.003468911853467847\n",
      "train loss:0.012680152401985953\n",
      "train loss:0.013732698518812534\n",
      "train loss:0.0016378674744448713\n",
      "train loss:0.11353421882337385\n",
      "train loss:0.0032747125564172174\n",
      "train loss:0.00602019942992466\n",
      "train loss:0.007367309354928654\n",
      "train loss:0.022359179868890897\n",
      "train loss:0.0033836001111500614\n",
      "train loss:0.0020469068574469748\n",
      "train loss:0.004107682593295758\n",
      "train loss:0.01014230762572084\n",
      "train loss:0.03533084981450301\n",
      "train loss:0.002798006281011049\n",
      "train loss:0.0024043760444109005\n",
      "train loss:0.004059965351479591\n",
      "train loss:0.0024149188516179552\n",
      "train loss:0.002821259848051748\n",
      "train loss:0.011131241150433258\n",
      "train loss:0.00798104833418026\n",
      "train loss:0.03541993461604869\n",
      "train loss:0.007694337299223557\n",
      "train loss:0.007685251399149875\n",
      "train loss:0.0014061552105389852\n",
      "train loss:0.0009164085354124232\n",
      "train loss:0.0025878539280017473\n",
      "train loss:0.004040468072487017\n",
      "train loss:0.03788392152378408\n",
      "train loss:0.0037835387377226763\n",
      "train loss:0.011108051869025928\n",
      "train loss:0.009411346861388819\n",
      "train loss:0.004254533349435175\n",
      "train loss:0.02642008652299927\n",
      "train loss:0.004386969000748083\n",
      "train loss:0.007825118617591243\n",
      "train loss:0.009463866602583549\n",
      "train loss:0.007031531511858099\n",
      "train loss:0.010912358501523434\n",
      "train loss:0.014339110478529513\n",
      "train loss:0.006686352366865121\n",
      "train loss:0.0010299932423779826\n",
      "train loss:0.001377219789335315\n",
      "train loss:0.007514120062978138\n",
      "train loss:0.019803640882477533\n",
      "train loss:0.003213358722996573\n",
      "train loss:0.0020069921552761595\n",
      "train loss:0.006934439725779442\n",
      "train loss:0.005835790542574398\n",
      "train loss:0.007789560471588106\n",
      "train loss:0.017491318402643428\n",
      "train loss:0.003208119550676288\n",
      "train loss:0.010557312732252489\n",
      "train loss:0.013365937113766277\n",
      "train loss:0.00937019636946112\n",
      "train loss:0.012733059190096811\n",
      "train loss:0.023946890205074366\n",
      "train loss:0.005583360393073316\n",
      "train loss:0.009449674689762756\n",
      "train loss:0.01774278298139676\n",
      "train loss:0.006758650331800332\n",
      "train loss:0.017462404532666297\n",
      "train loss:0.03711636432646145\n",
      "train loss:0.013301400438122842\n",
      "train loss:0.013059016638170684\n",
      "train loss:0.011871047273767199\n",
      "train loss:0.025661102401923732\n",
      "train loss:0.0150549655206031\n",
      "train loss:0.01589143750882953\n",
      "train loss:0.03223474926148453\n",
      "train loss:0.005342572727344664\n",
      "train loss:0.002282740876148513\n",
      "train loss:0.006451941243433511\n",
      "train loss:0.027646824796393136\n",
      "train loss:0.015938739660232838\n",
      "train loss:0.009725943866000812\n",
      "train loss:0.07759055144556934\n",
      "train loss:0.006698967571428393\n",
      "train loss:0.014059693974185971\n",
      "train loss:0.01656842266429403\n",
      "train loss:0.0406218178828377\n",
      "train loss:0.0099888286231243\n",
      "train loss:0.014686159079579897\n",
      "train loss:0.020974454697009398\n",
      "train loss:0.0015865747091863833\n",
      "train loss:0.005839897836092313\n",
      "train loss:0.008695111979639888\n",
      "train loss:0.02436374126369262\n",
      "train loss:0.01006671418055292\n",
      "train loss:0.008904674041631764\n",
      "train loss:0.05356152410881287\n",
      "train loss:0.007414054191870185\n",
      "train loss:0.006842915238627821\n",
      "train loss:0.0074999453732754314\n",
      "train loss:0.0034594449127546166\n",
      "train loss:0.0059325365503681326\n",
      "train loss:0.01750937829538065\n",
      "train loss:0.0021361104055982725\n",
      "train loss:0.003360738076606401\n",
      "train loss:0.010327404043746425\n",
      "train loss:0.006650418564712973\n",
      "train loss:0.04086715131629291\n",
      "train loss:0.028555356449197787\n",
      "train loss:0.001697029022912533\n",
      "train loss:0.028950573807112964\n",
      "train loss:0.017417219446422886\n",
      "train loss:0.04628995069884612\n",
      "train loss:0.0025593949422356376\n",
      "train loss:0.003824094975185435\n",
      "train loss:0.005053749041195096\n",
      "train loss:0.012752029385914264\n",
      "train loss:0.0012040613015918695\n",
      "train loss:0.0025203005269908486\n",
      "train loss:0.0005653220848614157\n",
      "train loss:0.009341053136893594\n",
      "train loss:0.004829037187646759\n",
      "train loss:0.045861382655326945\n",
      "train loss:0.033223208998769314\n",
      "train loss:0.0020418673179046897\n",
      "train loss:0.0035751442644000255\n",
      "train loss:0.008506827179317158\n",
      "train loss:0.004258824182183623\n",
      "train loss:0.011170624446599397\n",
      "train loss:0.007040210682165638\n",
      "train loss:0.014525041830030117\n",
      "train loss:0.02197440312571509\n",
      "train loss:0.03930819656388517\n",
      "train loss:0.012313013206019081\n",
      "train loss:0.0041466571328984065\n",
      "train loss:0.013906338999935368\n",
      "train loss:0.024504442662418694\n",
      "train loss:0.0031847726367830037\n",
      "train loss:0.010839526182432007\n",
      "train loss:0.010218827259739487\n",
      "train loss:0.0020695667987940237\n",
      "train loss:0.009081911774732247\n",
      "train loss:0.022288392953197553\n",
      "train loss:0.007699207655093432\n",
      "train loss:0.002994909850491575\n",
      "train loss:0.0031675114377855986\n",
      "train loss:0.023190456240515075\n",
      "train loss:0.031670742708299685\n",
      "train loss:0.0028823213768666566\n",
      "train loss:0.004961069393474546\n",
      "train loss:0.005818183350383458\n",
      "train loss:0.026194138578362964\n",
      "train loss:0.0052739831027893815\n",
      "train loss:0.013382403919666871\n",
      "train loss:0.00906844332802096\n",
      "train loss:0.009847542412334242\n",
      "train loss:0.004234314500846618\n",
      "train loss:0.006883714788809542\n",
      "train loss:0.030576773830650113\n",
      "train loss:0.0008369649326345568\n",
      "train loss:0.011448495478558331\n",
      "train loss:0.009233692825583631\n",
      "train loss:0.0016236670155411143\n",
      "train loss:0.010505927252910448\n",
      "train loss:0.00458336394435181\n",
      "train loss:0.005910586983915656\n",
      "train loss:0.006529805838457404\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.0024823924385081963\n",
      "train loss:0.015455951699790407\n",
      "train loss:0.005202622421218349\n",
      "train loss:0.004890773800293996\n",
      "train loss:0.003472044923539212\n",
      "train loss:0.014992926002151572\n",
      "train loss:0.0012505553287472013\n",
      "train loss:0.0016533182033190953\n",
      "train loss:0.005450014018615762\n",
      "train loss:0.009602753053350734\n",
      "train loss:0.014384459742224874\n",
      "train loss:0.006720973463367944\n",
      "train loss:0.012546939568359288\n",
      "train loss:0.0009560052838739851\n",
      "train loss:0.008029788872445045\n",
      "train loss:0.0018137935729736659\n",
      "train loss:0.010083910650015182\n",
      "train loss:0.010879002347382922\n",
      "train loss:0.00831685457410094\n",
      "train loss:0.0016889077035150786\n",
      "train loss:0.08495494595666836\n",
      "train loss:0.012361130279921728\n",
      "train loss:0.00408904498304352\n",
      "train loss:0.023246496574229218\n",
      "train loss:0.0035964533918871745\n",
      "train loss:0.007402553157234712\n",
      "train loss:0.003882373508163308\n",
      "train loss:0.007343898853259755\n",
      "train loss:0.0020817724173338927\n",
      "train loss:0.002378569881492506\n",
      "train loss:0.011771250292068458\n",
      "train loss:0.014079017162893202\n",
      "train loss:0.0030916716340434625\n",
      "train loss:0.002317864670541892\n",
      "train loss:0.012780594601153092\n",
      "train loss:0.00613731012228799\n",
      "train loss:0.004054106944817114\n",
      "train loss:0.010416067994008014\n",
      "train loss:0.00647805027400895\n",
      "train loss:0.007438451046026624\n",
      "train loss:0.001495748800917066\n",
      "train loss:0.0018035522881097298\n",
      "train loss:0.0022979221271499832\n",
      "train loss:0.013714153542043153\n",
      "train loss:0.08435068738488588\n",
      "train loss:0.00908261650820122\n",
      "train loss:0.004533409302722555\n",
      "train loss:0.0015101063284161961\n",
      "train loss:0.015907858937920884\n",
      "train loss:0.005132312876040861\n",
      "train loss:0.005172468377616923\n",
      "train loss:0.0012498126556420958\n",
      "train loss:0.003226515577219508\n",
      "train loss:0.014616074399732554\n",
      "train loss:0.009060237404120845\n",
      "train loss:0.0018615902925284609\n",
      "train loss:0.004722960113827443\n",
      "train loss:0.014015186487686168\n",
      "train loss:0.01591627658183377\n",
      "train loss:0.007717902533136561\n",
      "train loss:0.004758604069320249\n",
      "train loss:0.007497660389615468\n",
      "train loss:0.018422337594707777\n",
      "train loss:0.007887055794020421\n",
      "train loss:0.018275432754133642\n",
      "train loss:0.03174149917829995\n",
      "train loss:0.01633993656437171\n",
      "train loss:0.0646778438621701\n",
      "train loss:0.003952338357277249\n",
      "train loss:0.00986002211953972\n",
      "train loss:0.002474761772258727\n",
      "train loss:0.007737387458771608\n",
      "train loss:0.01140331482194321\n",
      "train loss:0.0016522799909953459\n",
      "train loss:0.03804965575774573\n",
      "train loss:0.002389515823342872\n",
      "train loss:0.010675577958114336\n",
      "train loss:0.0008393366863035098\n",
      "train loss:0.005592897724969874\n",
      "train loss:0.032636237460546426\n",
      "train loss:0.008915120497966285\n",
      "train loss:0.010113655867333314\n",
      "train loss:0.0032058299531496355\n",
      "train loss:0.008644120553790982\n",
      "train loss:0.0045492031401530774\n",
      "train loss:0.013967570602130261\n",
      "train loss:0.049647470262632484\n",
      "train loss:0.01011513871553249\n",
      "train loss:0.003549423836257189\n",
      "train loss:0.00421062399167747\n",
      "train loss:0.010392404933177148\n",
      "train loss:0.013470120853185632\n",
      "train loss:0.0014574236987965048\n",
      "train loss:0.006166172223837072\n",
      "train loss:0.001602629624906366\n",
      "train loss:0.00800366933336927\n",
      "train loss:0.007540899032976734\n",
      "train loss:0.009217531354649972\n",
      "train loss:0.0030816003114062175\n",
      "train loss:0.0033554926573603184\n",
      "train loss:0.005657329477392285\n",
      "train loss:0.019565033194723747\n",
      "train loss:0.012059772117133548\n",
      "train loss:0.0027678590450387376\n",
      "train loss:0.00515203019075753\n",
      "train loss:0.00292841449019997\n",
      "train loss:0.00221933998739073\n",
      "train loss:0.0038292387582727094\n",
      "train loss:0.002524177686816364\n",
      "train loss:0.0036392079031781306\n",
      "train loss:0.0014291624487049145\n",
      "train loss:0.009922074133938282\n",
      "train loss:0.01654081454463693\n",
      "train loss:0.0027258188062491695\n",
      "train loss:0.013434672828116336\n",
      "train loss:0.0029706889263213278\n",
      "train loss:0.0063840495373062855\n",
      "train loss:0.006804139912161432\n",
      "train loss:0.005903213796351746\n",
      "train loss:0.014501601199545158\n",
      "train loss:0.009039969223988805\n",
      "train loss:0.0023813376043548174\n",
      "train loss:0.00486261938403653\n",
      "train loss:0.004345551918596883\n",
      "train loss:0.012326846979851348\n",
      "train loss:0.017175932525387416\n",
      "train loss:0.006446445468193961\n",
      "train loss:0.03996602973876534\n",
      "train loss:0.002218104749547649\n",
      "train loss:0.0006690014717395179\n",
      "train loss:0.0020429939344498217\n",
      "train loss:0.006039640213808642\n",
      "train loss:0.007166658061134976\n",
      "train loss:0.014487734825510436\n",
      "train loss:0.0018933710178453934\n",
      "train loss:0.011551029066177568\n",
      "train loss:0.003511755596148876\n",
      "train loss:0.00883873979334238\n",
      "train loss:0.000664527322184949\n",
      "train loss:0.004149470518472679\n",
      "train loss:0.013184882868712569\n",
      "train loss:0.004269826619935038\n",
      "train loss:0.0018348076277007789\n",
      "train loss:0.001266769143784867\n",
      "train loss:0.004394379318550553\n",
      "train loss:0.005410645924898521\n",
      "train loss:0.007790740572955207\n",
      "train loss:0.00315487664625457\n",
      "train loss:0.01538125521060838\n",
      "train loss:0.008428174030616513\n",
      "train loss:0.004200127283904111\n",
      "train loss:0.0039254834318825345\n",
      "train loss:0.002953680789501801\n",
      "train loss:0.004711067167900454\n",
      "train loss:0.008520004651576738\n",
      "train loss:0.001155575203053623\n",
      "train loss:0.007906275868298014\n",
      "train loss:0.007365931478270393\n",
      "train loss:0.0012045473666136243\n",
      "train loss:0.0015343876377128364\n",
      "train loss:0.007847555065230872\n",
      "train loss:0.00412683694085371\n",
      "train loss:0.0037374776965837663\n",
      "train loss:0.005452525696122729\n",
      "train loss:0.02195045414126793\n",
      "train loss:0.0018770446297995535\n",
      "train loss:0.005491100797356583\n",
      "train loss:0.0063302238373294005\n",
      "train loss:0.0043043838004357985\n",
      "train loss:0.052743250028694906\n",
      "train loss:0.004436281677119853\n",
      "train loss:0.005531936611526661\n",
      "train loss:0.009357088348163817\n",
      "train loss:0.004439393350390527\n",
      "train loss:0.010840764166396762\n",
      "train loss:0.045490373862088346\n",
      "train loss:0.0313074301737793\n",
      "train loss:0.0030686335515224734\n",
      "train loss:0.009137375016000596\n",
      "train loss:0.0038578274353372843\n",
      "train loss:0.0012463087619997149\n",
      "train loss:0.0033353187530906995\n",
      "train loss:0.0011925779887272242\n",
      "train loss:0.019249160035164782\n",
      "train loss:0.010883097845910385\n",
      "train loss:0.017098304795041784\n",
      "train loss:0.01563922596701307\n",
      "train loss:0.0017776215275005823\n",
      "train loss:0.0018596005898638274\n",
      "train loss:0.013003237594181967\n",
      "train loss:0.011159796056933043\n",
      "train loss:0.008859670114058476\n",
      "train loss:0.0064721802404203365\n",
      "train loss:0.01170207250589615\n",
      "train loss:0.004328813408599047\n",
      "train loss:0.005906397026545743\n",
      "train loss:0.0007821728052562292\n",
      "train loss:0.03054065448723499\n",
      "train loss:0.0038116614368180813\n",
      "train loss:0.05726066924015919\n",
      "train loss:0.005487224154014552\n",
      "train loss:0.0017461353569764053\n",
      "train loss:0.004155341996917718\n",
      "train loss:0.0029968920536817545\n",
      "train loss:0.0015045773489036087\n",
      "train loss:0.010767707090434226\n",
      "train loss:0.010377288427380962\n",
      "train loss:0.002610165566206554\n",
      "train loss:0.004878846071387643\n",
      "train loss:0.0014615502586920377\n",
      "train loss:0.0589259791144206\n",
      "train loss:0.005163957951946347\n",
      "train loss:0.007015476593017277\n",
      "train loss:0.009833546094234901\n",
      "train loss:0.005074859569908012\n",
      "train loss:0.003581892037432804\n",
      "train loss:0.012672499203974954\n",
      "train loss:0.01511804058849324\n",
      "train loss:0.0015537785726597044\n",
      "train loss:0.02823361131407292\n",
      "train loss:0.00950446519782163\n",
      "train loss:0.004890741626754144\n",
      "train loss:0.024020061627403444\n",
      "train loss:0.0028775520916806403\n",
      "train loss:0.004627602787810615\n",
      "train loss:0.10145621820804791\n",
      "train loss:0.014883764557510006\n",
      "train loss:0.0042091930490281175\n",
      "train loss:0.0035011909189806324\n",
      "train loss:0.0027821060231330817\n",
      "train loss:0.0034337476048902304\n",
      "train loss:0.0019314292798872953\n",
      "train loss:0.022973993253250474\n",
      "train loss:0.01162837269555995\n",
      "train loss:0.007148156851851075\n",
      "train loss:0.0051118432283158355\n",
      "train loss:0.005385739750014337\n",
      "train loss:0.0030084228179442585\n",
      "train loss:0.0031927559224103237\n",
      "train loss:0.0036382740707229023\n",
      "train loss:0.029407181312407226\n",
      "train loss:0.016771939789764097\n",
      "train loss:0.016009398991476288\n",
      "train loss:0.006617583768816096\n",
      "train loss:0.006332044391914074\n",
      "train loss:0.001747085536600444\n",
      "train loss:0.04003124784617956\n",
      "train loss:0.010877134896255795\n",
      "train loss:0.016849560354090277\n",
      "train loss:0.004678110890192935\n",
      "train loss:0.004449570075860188\n",
      "train loss:0.002765417426604792\n",
      "train loss:0.007086061617301825\n",
      "train loss:0.01041942391534192\n",
      "train loss:0.009177770386635682\n",
      "train loss:0.0016325110321604183\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.002935962153776706\n",
      "train loss:0.004492867071958214\n",
      "train loss:0.0022247773161689684\n",
      "train loss:0.009945788897927434\n",
      "train loss:0.004007082023373288\n",
      "train loss:0.002827553515341528\n",
      "train loss:0.024174631738411775\n",
      "train loss:0.0024725997257819014\n",
      "train loss:0.0024440031809402287\n",
      "train loss:0.0055200938188380766\n",
      "train loss:0.0044126868293215705\n",
      "train loss:0.00885593057570638\n",
      "train loss:0.002342411109751538\n",
      "train loss:0.0051421411095581284\n",
      "train loss:0.002470757955063646\n",
      "train loss:0.01748385399482943\n",
      "train loss:0.022405263233811847\n",
      "train loss:0.011602962857929165\n",
      "train loss:0.01560577457809086\n",
      "train loss:0.0015657676812452562\n",
      "train loss:0.0005081903351065162\n",
      "train loss:0.0145047953332528\n",
      "train loss:0.0029415859301194992\n",
      "train loss:0.011915622289443777\n",
      "train loss:0.007936596844812524\n",
      "train loss:0.012956453008093928\n",
      "train loss:0.004556873508212595\n",
      "train loss:0.0034478254331316827\n",
      "train loss:0.003397926427675176\n",
      "train loss:0.013025972662598053\n",
      "train loss:0.01374729126589522\n",
      "train loss:0.004757404951580277\n",
      "train loss:0.03209683221908402\n",
      "train loss:0.0011532644141976683\n",
      "train loss:0.0096951615477464\n",
      "train loss:0.01165921433316891\n",
      "train loss:0.002795732152031518\n",
      "train loss:0.001523025752296275\n",
      "train loss:0.005273166086328433\n",
      "train loss:0.008904192819950791\n",
      "train loss:0.005856254836320431\n",
      "train loss:0.008017584779912044\n",
      "train loss:0.025627679488962846\n",
      "train loss:0.0188152518143724\n",
      "train loss:0.0026366573661915317\n",
      "train loss:0.021605307634458688\n",
      "train loss:0.006649575338482815\n",
      "train loss:0.0015324255017143736\n",
      "train loss:0.011521691445340172\n",
      "train loss:0.010441295137318228\n",
      "train loss:0.0040090651972226965\n",
      "train loss:0.010516958012450868\n",
      "train loss:0.006043118017636795\n",
      "train loss:0.010745149740850642\n",
      "train loss:0.014445720143838105\n",
      "train loss:0.0036930384355616896\n",
      "train loss:0.003977370798560026\n",
      "train loss:0.008744573965410892\n",
      "train loss:0.003976012643151879\n",
      "train loss:0.00671769804322936\n",
      "train loss:0.004815544608655375\n",
      "train loss:0.0021416216550529414\n",
      "train loss:0.00966082436112388\n",
      "train loss:0.004551187017395743\n",
      "train loss:0.011201803771636187\n",
      "train loss:0.003926923755364965\n",
      "train loss:0.004422433492053615\n",
      "train loss:0.0009757133236524268\n",
      "train loss:0.0026731749565516096\n",
      "train loss:0.005137852797207096\n",
      "train loss:0.003143243502338353\n",
      "train loss:0.001959851803971685\n",
      "train loss:0.06741484330754086\n",
      "train loss:0.07852012514769804\n",
      "train loss:0.004745348154173504\n",
      "train loss:0.0027741138560908583\n",
      "train loss:0.010356132803979621\n",
      "train loss:0.052869452354729646\n",
      "train loss:0.01793043400007592\n",
      "train loss:0.0051187938361699215\n",
      "train loss:0.0012078099861664014\n",
      "train loss:0.010099595435379511\n",
      "train loss:0.004031129756794971\n",
      "train loss:0.008876165625646065\n",
      "train loss:0.008874292575623341\n",
      "train loss:0.007162828556878815\n",
      "train loss:0.0122124198110098\n",
      "train loss:0.011061241910222099\n",
      "train loss:0.004293072356817258\n",
      "train loss:0.001912539307180978\n",
      "train loss:0.0025767500813365807\n",
      "train loss:0.00043190815422995986\n",
      "train loss:0.008039798989405269\n",
      "train loss:0.0023015905541648733\n",
      "train loss:0.004661739726775844\n",
      "train loss:0.010565323942363102\n",
      "train loss:0.007213733028420816\n",
      "train loss:0.003847154378977278\n",
      "train loss:0.012101767463923148\n",
      "train loss:0.0031640819584522624\n",
      "train loss:0.005717445854731823\n",
      "train loss:0.0037765275087929717\n",
      "train loss:0.012848659652657184\n",
      "train loss:0.005245749339616564\n",
      "train loss:0.11665983633327504\n",
      "train loss:0.012724263320335787\n",
      "train loss:0.0036126730541861133\n",
      "train loss:0.0040081730452408044\n",
      "train loss:0.008147941049969605\n",
      "train loss:0.011771782451131562\n",
      "train loss:0.0021599750993705415\n",
      "train loss:0.0017387530070458574\n",
      "train loss:0.00344646367338063\n",
      "train loss:0.0012171930771463666\n",
      "train loss:0.0031218888304187908\n",
      "train loss:0.010194615831763322\n",
      "train loss:0.01880648520218674\n",
      "train loss:0.0006360148734613624\n",
      "train loss:0.04045381293396203\n",
      "train loss:0.009192862354206546\n",
      "train loss:0.006464431226835451\n",
      "train loss:0.0010450856544609608\n",
      "train loss:0.009014181240463852\n",
      "train loss:0.14633199545133158\n",
      "train loss:0.010744101059551417\n",
      "train loss:0.0024475358380564756\n",
      "train loss:0.0009487747351544632\n",
      "train loss:0.001846411061438259\n",
      "train loss:0.06104875741224419\n",
      "train loss:0.004640616629921402\n",
      "train loss:0.017428124163277915\n",
      "train loss:0.0068645941794166585\n",
      "train loss:0.023435939512127496\n",
      "train loss:0.0033155224404658092\n",
      "train loss:0.00171765237762631\n",
      "train loss:0.008658424381528439\n",
      "train loss:0.009836000707444517\n",
      "train loss:0.030673814067526804\n",
      "train loss:0.005178703614586411\n",
      "train loss:0.006347370398372456\n",
      "train loss:0.005254601910192736\n",
      "train loss:0.001003986522787744\n",
      "train loss:0.002819297978073874\n",
      "train loss:0.0014753891410510432\n",
      "train loss:0.007791927284704931\n",
      "train loss:0.005477132366212034\n",
      "train loss:0.026497351424725014\n",
      "train loss:0.003815182575421687\n",
      "train loss:0.010595834048450454\n",
      "train loss:0.005411400048215776\n",
      "train loss:0.0016645177385020483\n",
      "train loss:0.011380760026402516\n",
      "train loss:0.010568533333291339\n",
      "train loss:0.004091925976810202\n",
      "train loss:0.011688575389239245\n",
      "train loss:0.005637136864026747\n",
      "train loss:0.01829895642255751\n",
      "train loss:0.0007260039352572196\n",
      "train loss:0.01023032246144767\n",
      "train loss:0.002593790171233007\n",
      "train loss:0.06297047183194752\n",
      "train loss:0.020961717452795597\n",
      "train loss:0.002778144948484595\n",
      "train loss:0.018384171827017633\n",
      "train loss:0.0022990293438762783\n",
      "train loss:0.024243715083169602\n",
      "train loss:0.008725979857908489\n",
      "train loss:0.008880723804354243\n",
      "train loss:0.0014428358507602482\n",
      "train loss:0.0007307674068931151\n",
      "train loss:0.0064157917952545815\n",
      "train loss:0.0008091405408552543\n",
      "train loss:0.007005705437020089\n",
      "train loss:0.0028678709094578066\n",
      "train loss:0.04149414057333203\n",
      "train loss:0.017377748682725257\n",
      "train loss:0.012069880289409307\n",
      "train loss:0.0033790435401415304\n",
      "train loss:0.009897666745889997\n",
      "train loss:0.005407311303020262\n",
      "train loss:0.03563994505167192\n",
      "train loss:0.003174572999776483\n",
      "train loss:0.008256353638796517\n",
      "=== epoch:10, train acc:0.992, test acc:0.986 ===\n",
      "train loss:0.033412362226847195\n",
      "train loss:0.02364902909465082\n",
      "train loss:0.006785653070533675\n",
      "train loss:0.0025228815667421812\n",
      "train loss:0.0026413726686654922\n",
      "train loss:0.018298934983290816\n",
      "train loss:0.004845508996348816\n",
      "train loss:0.009832778620181287\n",
      "train loss:0.009063970486672927\n",
      "train loss:0.004403622268899547\n",
      "train loss:0.00900528179218836\n",
      "train loss:0.008509404788780608\n",
      "train loss:0.0125581575280697\n",
      "train loss:0.014080234036703707\n",
      "train loss:0.0020747890916720194\n",
      "train loss:0.005566629138830043\n",
      "train loss:0.004777253107381193\n",
      "train loss:0.003547745945196882\n",
      "train loss:0.0032366256563329627\n",
      "train loss:0.0032847938655507806\n",
      "train loss:0.0038087253454927154\n",
      "train loss:0.010340854499534648\n",
      "train loss:0.012688084817790834\n",
      "train loss:0.009275411096558557\n",
      "train loss:0.003968193715275231\n",
      "train loss:0.0010299272520326737\n",
      "train loss:0.0023356481576012915\n",
      "train loss:0.026795996336729796\n",
      "train loss:0.0010502319574659442\n",
      "train loss:0.012071545099000826\n",
      "train loss:0.0029153845626359214\n",
      "train loss:0.00469318236986955\n",
      "train loss:0.011279610128605032\n",
      "train loss:0.004354935068774919\n",
      "train loss:0.00880910251326204\n",
      "train loss:0.0025253939101858285\n",
      "train loss:0.016120946976667896\n",
      "train loss:0.002290830336295199\n",
      "train loss:0.01776758326287729\n",
      "train loss:0.002901275374684417\n",
      "train loss:0.007984653113753367\n",
      "train loss:0.012734045179414129\n",
      "train loss:0.0033706564071442945\n",
      "train loss:0.021725538565027014\n",
      "train loss:0.10446086464848242\n",
      "train loss:0.000764269026458144\n",
      "train loss:0.0014547426189906218\n",
      "train loss:0.0012476131388995514\n",
      "train loss:0.002314240404191101\n",
      "train loss:0.0022322851446518518\n",
      "train loss:0.0019461737181251423\n",
      "train loss:0.0018995625810463114\n",
      "train loss:0.0021839982289931707\n",
      "train loss:0.0045742669140414974\n",
      "train loss:0.002763362471269917\n",
      "train loss:0.04366769024941971\n",
      "train loss:0.002316752303079228\n",
      "train loss:0.0032335440644604176\n",
      "train loss:0.010066510396312985\n",
      "train loss:0.004928612720927672\n",
      "train loss:0.005729357757499142\n",
      "train loss:0.0011194910783557921\n",
      "train loss:0.008040392442355987\n",
      "train loss:0.012898230417353454\n",
      "train loss:0.004210033552146695\n",
      "train loss:0.0021335397984505885\n",
      "train loss:0.0025613941707147525\n",
      "train loss:0.028498987723401977\n",
      "train loss:0.00455351396617244\n",
      "train loss:0.07816727687329507\n",
      "train loss:0.0004934835183202196\n",
      "train loss:0.0006441458409045104\n",
      "train loss:0.008732064105589216\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.02371863386330246\n",
      "train loss:0.0018942481422526412\n",
      "train loss:0.0024223626242833316\n",
      "train loss:0.0017534715734080887\n",
      "train loss:0.004861730864149583\n",
      "train loss:0.021627607356888706\n",
      "train loss:0.008168545741979066\n",
      "train loss:0.003580741791330087\n",
      "train loss:0.028441690151348252\n",
      "train loss:0.0052956000821610385\n",
      "train loss:0.004583196894664586\n",
      "train loss:0.00505000392395567\n",
      "train loss:0.019150685621771774\n",
      "train loss:0.007522627283847225\n",
      "train loss:0.0019844507052517958\n",
      "train loss:0.004687547597794651\n",
      "train loss:0.02028128707119831\n",
      "train loss:0.0027142195814609626\n",
      "train loss:0.0036449911877746368\n",
      "train loss:0.009289471183973093\n",
      "train loss:0.007243012653807402\n",
      "train loss:0.006288149203167811\n",
      "train loss:0.0050769387620196674\n",
      "train loss:0.000829352999100422\n",
      "train loss:0.005115576277834577\n",
      "train loss:0.00790224098614369\n",
      "train loss:0.0008301045775961735\n",
      "train loss:0.001678455866281658\n",
      "train loss:0.00795603622890942\n",
      "train loss:0.007709251489376955\n",
      "train loss:0.0011023565506284715\n",
      "train loss:0.003907250993890557\n",
      "train loss:0.022800656192307582\n",
      "train loss:0.02165383392143285\n",
      "train loss:0.0060402212868115\n",
      "train loss:0.017886004703624482\n",
      "train loss:0.004772342580142001\n",
      "train loss:0.02238545538149674\n",
      "train loss:0.0006684048724050118\n",
      "train loss:0.02495568380912501\n",
      "train loss:0.005332582725812337\n",
      "train loss:0.002762006055146331\n",
      "train loss:0.0016211122787585925\n",
      "train loss:0.0057041247454306465\n",
      "train loss:0.008780174961323868\n",
      "train loss:0.014158642968711395\n",
      "train loss:0.01700993818684299\n",
      "train loss:0.05387952811391597\n",
      "train loss:0.0037431594553485542\n",
      "train loss:0.0021126506209133023\n",
      "train loss:0.009339595706700872\n",
      "train loss:0.0005772730095507791\n",
      "train loss:0.01674676677297678\n",
      "train loss:0.008627107783367075\n",
      "train loss:0.005777936221763112\n",
      "train loss:0.004315579503349542\n",
      "train loss:0.003731293534981267\n",
      "train loss:0.014564566264329806\n",
      "train loss:0.004065359939224927\n",
      "train loss:0.006301786762269858\n",
      "train loss:0.009733004402006971\n",
      "train loss:0.011219649333798775\n",
      "train loss:0.005174924922141572\n",
      "train loss:0.007401707111629439\n",
      "train loss:0.03213397106433267\n",
      "train loss:0.0009861087016055205\n",
      "train loss:0.009644863875007266\n",
      "train loss:0.0027676265572893592\n",
      "train loss:0.006444311259173999\n",
      "train loss:0.0057005276077603815\n",
      "train loss:0.015240788421396699\n",
      "train loss:0.01951421006985818\n",
      "train loss:0.0021372382355639417\n",
      "train loss:0.034541806121365946\n",
      "train loss:0.004713046080960348\n",
      "train loss:0.012569369782718704\n",
      "train loss:0.0020007429154515113\n",
      "train loss:0.007431150061672402\n",
      "train loss:0.003339405364120701\n",
      "train loss:0.004186979880775277\n",
      "train loss:0.007951716481992442\n",
      "train loss:0.0016879443081964723\n",
      "train loss:0.0008846716867923317\n",
      "train loss:0.005966564944731597\n",
      "train loss:0.0025162199471216624\n",
      "train loss:0.0023150630511433318\n",
      "train loss:0.042959220564538506\n",
      "train loss:0.005308562281862229\n",
      "train loss:0.006821106783272295\n",
      "train loss:0.009930012217413433\n",
      "train loss:0.004330575554346707\n",
      "train loss:0.03090639992173154\n",
      "train loss:0.002838040613495618\n",
      "train loss:0.00271692570766486\n",
      "train loss:0.008639905210166141\n",
      "train loss:0.007429539308288325\n",
      "train loss:0.004850991819661614\n",
      "train loss:0.012965282072248318\n",
      "train loss:0.009349848615505214\n",
      "train loss:0.0046599748644975784\n",
      "train loss:0.0087534747762735\n",
      "train loss:0.0038708540455978393\n",
      "train loss:0.0024770212408138028\n",
      "train loss:0.0034850737617959254\n",
      "train loss:0.004526270229747848\n",
      "train loss:0.004601469252594234\n",
      "train loss:0.0008506837505556938\n",
      "train loss:0.0035749775701403013\n",
      "train loss:0.0035224736205598465\n",
      "train loss:0.02714588943263453\n",
      "train loss:0.003540528217261657\n",
      "train loss:0.005242217008627026\n",
      "train loss:0.002486746644202748\n",
      "train loss:0.0067417725699641705\n",
      "train loss:0.0034043433483039037\n",
      "train loss:0.01083011064184937\n",
      "train loss:0.001278634050290804\n",
      "train loss:0.07839301272120423\n",
      "train loss:0.007022666461507921\n",
      "train loss:0.0252799753962919\n",
      "train loss:0.0009959156265995418\n",
      "train loss:0.009826632480450207\n",
      "train loss:0.0013676598827624348\n",
      "train loss:0.0013737745394039812\n",
      "train loss:0.003160561108512896\n",
      "train loss:0.00484967324447652\n",
      "train loss:0.00916015767424757\n",
      "train loss:0.007281642449621223\n",
      "train loss:0.002464696174547404\n",
      "train loss:0.006815808861580985\n",
      "train loss:0.00555888382142177\n",
      "train loss:0.005248503520078707\n",
      "train loss:0.007447226162657051\n",
      "train loss:0.002567803749076271\n",
      "train loss:0.0019350651001333013\n",
      "train loss:0.0010149208646465936\n",
      "train loss:0.0033321569446482457\n",
      "train loss:0.003142050979499368\n",
      "train loss:0.007458430445265998\n",
      "train loss:0.0032526088291727363\n",
      "train loss:0.00778773995400694\n",
      "train loss:0.004102706015636495\n",
      "train loss:0.005318740114452714\n",
      "train loss:0.010320482260490885\n",
      "train loss:0.002175379597015822\n",
      "train loss:0.009678264580605644\n",
      "train loss:0.0074679529956138855\n",
      "train loss:0.0033849079919321258\n",
      "train loss:0.0036223306516154448\n",
      "train loss:0.009511277842919916\n",
      "train loss:0.007567079942989924\n",
      "train loss:0.03539119345847506\n",
      "train loss:0.004343209086561268\n",
      "train loss:0.005071479193195435\n",
      "train loss:0.0005352828872615132\n",
      "train loss:0.005100842080003793\n",
      "train loss:0.004266058991791864\n",
      "train loss:0.0064973758673096986\n",
      "train loss:0.004482093511624081\n",
      "train loss:0.0028190743091895654\n",
      "train loss:0.0038665084928949855\n",
      "train loss:0.007540279736607255\n",
      "train loss:0.018496687309236353\n",
      "train loss:0.004213194900523664\n",
      "train loss:0.006781541960589159\n",
      "train loss:0.004674194785981085\n",
      "train loss:0.005734872515480689\n",
      "train loss:0.01024920052398268\n",
      "train loss:0.007155145408996068\n",
      "train loss:0.0006182200272173517\n",
      "train loss:0.003506849110589692\n",
      "train loss:0.0029325021868674616\n",
      "train loss:0.0173921511376965\n",
      "train loss:0.00456029604310096\n",
      "train loss:0.01162026364617499\n",
      "train loss:0.00801833252413315\n",
      "train loss:0.017720276477265637\n",
      "train loss:0.0006409951594981414\n",
      "train loss:0.013577665787314699\n",
      "train loss:0.010857299298824284\n",
      "train loss:0.013486773908212808\n",
      "train loss:0.005893270633848621\n",
      "train loss:0.006649146042240201\n",
      "train loss:0.08059299835287238\n",
      "train loss:0.0016196207360630152\n",
      "train loss:0.006727461690289763\n",
      "train loss:0.0056135719135412656\n",
      "train loss:0.01731913348322458\n",
      "train loss:0.0034874186372770327\n",
      "train loss:0.01890774383075592\n",
      "train loss:0.01391537812009745\n",
      "train loss:0.0032085749471140092\n",
      "train loss:0.009992323417006366\n",
      "train loss:0.006870662384028027\n",
      "train loss:0.0032264378687579176\n",
      "train loss:0.0014973307121918442\n",
      "train loss:0.008147697531335304\n",
      "train loss:0.010330408012134352\n",
      "train loss:0.004701429890801615\n",
      "train loss:0.0003756912291984186\n",
      "train loss:0.0007858712133401402\n",
      "train loss:0.0016990775517939552\n",
      "train loss:0.0030408239953770137\n",
      "train loss:0.002057500342456059\n",
      "train loss:0.0008922322214722475\n",
      "train loss:0.0015143333477165189\n",
      "train loss:0.003102360647136954\n",
      "train loss:0.005858258646490273\n",
      "train loss:0.005132751191375045\n",
      "train loss:0.003386158180807835\n",
      "train loss:0.0038605270719277076\n",
      "train loss:0.009344213775878213\n",
      "train loss:0.0015926150366125736\n",
      "train loss:0.004209632059736481\n",
      "train loss:0.0013715516605928189\n",
      "train loss:0.009764547374689559\n",
      "train loss:0.001939152486541145\n",
      "train loss:0.0035544312001361583\n",
      "train loss:0.005267326913658857\n",
      "train loss:0.0017226541083660857\n",
      "train loss:0.006029691789771196\n",
      "train loss:0.0012608785989236596\n",
      "train loss:0.0022737407949704933\n",
      "train loss:0.08145417920463217\n",
      "train loss:0.002250317621730952\n",
      "train loss:0.0070250530634305775\n",
      "train loss:0.018465763691224876\n",
      "train loss:0.0018229480896920528\n",
      "train loss:0.007762653089379444\n",
      "train loss:0.018876901286195534\n",
      "train loss:0.008604470564010175\n",
      "train loss:0.008744868722888733\n",
      "train loss:0.0041883706051717325\n",
      "train loss:0.013421318369530895\n",
      "train loss:0.005460964428371489\n",
      "train loss:0.0005965688679809622\n",
      "train loss:0.001770141641538557\n",
      "train loss:0.05399833391800122\n",
      "train loss:0.000622880662088926\n",
      "train loss:0.0030844750604710836\n",
      "train loss:0.03217750897297189\n",
      "train loss:0.006448618233493025\n",
      "train loss:0.0029657518140676986\n",
      "train loss:0.0022847926900429892\n",
      "train loss:0.006120333600093231\n",
      "train loss:0.02268523637755916\n",
      "train loss:0.005148899494226113\n",
      "train loss:0.003899606595918971\n",
      "train loss:0.0006146337163382986\n",
      "train loss:0.02023463836194779\n",
      "train loss:0.004490531012780094\n",
      "train loss:0.009232187643954151\n",
      "train loss:0.0048142727036631075\n",
      "train loss:0.0011438088348678568\n",
      "train loss:0.007339988191987877\n",
      "train loss:0.03766956083678466\n",
      "train loss:0.004327001263940094\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.008401677786273352\n",
      "train loss:0.004427063384854154\n",
      "train loss:0.006861677683444753\n",
      "train loss:0.006077105122047792\n",
      "train loss:0.008285993882710938\n",
      "train loss:0.011454584993464018\n",
      "train loss:0.007731658756789752\n",
      "train loss:0.03839087030817381\n",
      "train loss:0.0043666669621649215\n",
      "train loss:0.0029191235248875835\n",
      "train loss:0.0029444039617332273\n",
      "train loss:0.00511330914167443\n",
      "train loss:0.00656599026416953\n",
      "train loss:0.019447976268285188\n",
      "train loss:0.0029754311192850946\n",
      "train loss:0.004678433844883555\n",
      "train loss:0.012878449140140547\n",
      "train loss:0.010052852197800994\n",
      "train loss:0.00659879728192901\n",
      "train loss:0.03690653829114174\n",
      "train loss:0.0022431084268586094\n",
      "train loss:0.06961182324742173\n",
      "train loss:0.009771297576520052\n",
      "train loss:0.0019446548686328077\n",
      "train loss:0.010938357155240956\n",
      "train loss:0.013997170030309047\n",
      "train loss:0.0670724101015427\n",
      "train loss:0.006506520808029917\n",
      "train loss:0.001344137503300786\n",
      "train loss:0.004610217071235886\n",
      "train loss:0.004356268616072576\n",
      "train loss:0.016020649354841435\n",
      "train loss:0.0022614644281548817\n",
      "train loss:0.0804730943705308\n",
      "train loss:0.008028909229226437\n",
      "train loss:0.0008726034823596031\n",
      "train loss:0.008402971842316875\n",
      "train loss:0.016812290080046335\n",
      "train loss:0.005752709291304271\n",
      "train loss:0.001600598064196542\n",
      "train loss:0.004848712575480461\n",
      "train loss:0.004797143447522692\n",
      "train loss:0.004556509492485782\n",
      "train loss:0.0035957672635224002\n",
      "train loss:0.0070504812439412465\n",
      "train loss:0.003069105631265059\n",
      "train loss:0.011010667009244125\n",
      "train loss:0.001073119439452738\n",
      "train loss:0.00817013499512443\n",
      "train loss:0.004045386597061049\n",
      "train loss:0.037051823110756346\n",
      "train loss:0.0035299668749345404\n",
      "train loss:0.0028930770550379126\n",
      "train loss:0.004251724898224227\n",
      "train loss:0.0004304324120012448\n",
      "train loss:0.012925129332629497\n",
      "train loss:0.01377724623320692\n",
      "train loss:0.01346265665484074\n",
      "train loss:0.001619765009222221\n",
      "train loss:0.006064201549490119\n",
      "train loss:0.003239493139996599\n",
      "train loss:0.01035587946667678\n",
      "train loss:0.007163091787801522\n",
      "train loss:0.0007881215656814192\n",
      "train loss:0.002260480057224309\n",
      "train loss:0.0053646814630625254\n",
      "train loss:0.005732850335720789\n",
      "train loss:0.004556342616393496\n",
      "train loss:0.007526601578372792\n",
      "train loss:0.0037863048587262428\n",
      "train loss:0.005498774522761313\n",
      "train loss:0.00405512652803339\n",
      "train loss:0.014277754544545752\n",
      "train loss:0.020929721012033286\n",
      "train loss:0.019526943777498654\n",
      "train loss:0.0038193965679404517\n",
      "train loss:0.002778794073217717\n",
      "train loss:0.013739125589956875\n",
      "train loss:0.008035967378346576\n",
      "train loss:0.006315801781071245\n",
      "train loss:0.0010509907948444126\n",
      "train loss:0.003953961664555667\n",
      "train loss:0.009779582179876097\n",
      "train loss:0.006858462062506523\n",
      "train loss:0.0009875626203781386\n",
      "train loss:0.0023889090663069944\n",
      "train loss:0.005699538849116543\n",
      "train loss:0.0030447787253446296\n",
      "train loss:0.009127417843297457\n",
      "train loss:0.009032500870132099\n",
      "train loss:0.01018628685078896\n",
      "train loss:0.0023749647422186314\n",
      "train loss:0.0021051868096335115\n",
      "train loss:0.0047458268528986205\n",
      "train loss:0.0007693815179438986\n",
      "train loss:0.015500307558027868\n",
      "train loss:0.006957029052849806\n",
      "train loss:0.004887410246126936\n",
      "train loss:0.003923554902266094\n",
      "train loss:0.004373235736153707\n",
      "train loss:0.002211674276555552\n",
      "train loss:0.0038581667239837025\n",
      "train loss:0.005355214194218927\n",
      "train loss:0.005595139587570492\n",
      "train loss:0.0022689609548338387\n",
      "train loss:0.0014397023453237342\n",
      "train loss:0.005025126055910049\n",
      "train loss:0.034932315988606015\n",
      "train loss:0.0006770046748117663\n",
      "train loss:0.02749065807655489\n",
      "train loss:0.0035031186306062416\n",
      "train loss:0.0014646191588013565\n",
      "train loss:0.0012832899956998938\n",
      "train loss:0.008268834038272537\n",
      "train loss:0.002878647309764172\n",
      "train loss:0.002241922831428203\n",
      "train loss:0.002736997370612653\n",
      "train loss:0.002265180372803086\n",
      "train loss:0.00843954285719618\n",
      "train loss:0.0054041232422887085\n",
      "train loss:0.004626296539744806\n",
      "train loss:0.004409740810815949\n",
      "train loss:0.0015773722700471683\n",
      "train loss:0.003480481510830753\n",
      "train loss:0.009060322516211335\n",
      "train loss:0.0015201684155379718\n",
      "train loss:0.004614923469150294\n",
      "train loss:0.0024751821075905027\n",
      "train loss:0.005504899410777228\n",
      "train loss:0.0029086390903515866\n",
      "train loss:0.0053629391244241365\n",
      "train loss:0.009371338985607616\n",
      "train loss:0.01034368880563008\n",
      "train loss:0.006564778169280493\n",
      "train loss:0.005302369895600534\n",
      "train loss:0.008016252973223859\n",
      "train loss:0.001599490027633261\n",
      "train loss:0.004189275305463075\n",
      "train loss:0.017344829005275928\n",
      "train loss:0.006179359809380742\n",
      "train loss:0.014918843854879174\n",
      "train loss:0.008443008058581267\n",
      "train loss:0.010801365790507849\n",
      "train loss:0.002912314618699961\n",
      "train loss:0.0012697443407087472\n",
      "train loss:0.005328055878172691\n",
      "train loss:0.006142346165366185\n",
      "train loss:0.007022472668695304\n",
      "train loss:0.0049530159646631634\n",
      "train loss:0.00648384619347922\n",
      "train loss:0.013642424964680287\n",
      "train loss:0.004055000563468773\n",
      "train loss:0.005709122595539316\n",
      "train loss:0.0024495795977930563\n",
      "train loss:0.0010060757865006146\n",
      "train loss:0.0004646622261420169\n",
      "train loss:0.011576789592898767\n",
      "train loss:0.0035207912735884025\n",
      "train loss:0.007576097725885051\n",
      "train loss:0.0030945164540573827\n",
      "train loss:0.0031025195108505205\n",
      "train loss:0.011613385138604073\n",
      "train loss:0.005594364504088607\n",
      "train loss:0.0022756312782594838\n",
      "train loss:0.009307251160728064\n",
      "train loss:0.001610140627241963\n",
      "train loss:0.0008598426406577178\n",
      "train loss:0.001048651951259044\n",
      "train loss:0.0049174042507396315\n",
      "train loss:0.001481462174629567\n",
      "train loss:0.0016093265832984377\n",
      "train loss:0.008294269796327266\n",
      "train loss:0.009700307971606264\n",
      "train loss:0.002143793262710178\n",
      "train loss:0.0021961548190422226\n",
      "train loss:0.0012845172296012427\n",
      "train loss:0.00965514481506558\n",
      "train loss:0.008482751851374197\n",
      "train loss:0.004320751127034961\n",
      "train loss:0.003314050198906424\n",
      "train loss:0.002207761961853475\n",
      "train loss:0.0016023077714756612\n",
      "train loss:0.00418542158177317\n",
      "train loss:0.0007386166875665488\n",
      "train loss:0.005434401874838797\n",
      "train loss:0.003438391284128569\n",
      "train loss:0.011741004953355876\n",
      "train loss:0.1096020103744571\n",
      "train loss:0.025822061847466875\n",
      "train loss:0.01333175447331633\n",
      "train loss:0.004115959707878752\n",
      "train loss:0.0008553699571922294\n",
      "train loss:0.004554812529662932\n",
      "train loss:0.008195843299043163\n",
      "train loss:0.0022136476950242335\n",
      "train loss:0.0021597101513121026\n",
      "train loss:0.004308798262590709\n",
      "train loss:0.009876587091033116\n",
      "train loss:0.0023546095118696054\n",
      "train loss:0.005105604669960759\n",
      "train loss:0.13005469559987376\n",
      "train loss:0.0019761742211500642\n",
      "train loss:0.00047680432392878267\n",
      "train loss:0.0006027036462301797\n",
      "train loss:0.0187056010021859\n",
      "train loss:0.0020973804258005765\n",
      "train loss:0.006901806529423857\n",
      "train loss:0.010478180293587023\n",
      "train loss:0.0340964408149348\n",
      "train loss:0.021203275376400273\n",
      "train loss:0.02184921118780804\n",
      "train loss:0.01946932556330139\n",
      "train loss:0.00293554375851834\n",
      "train loss:0.004874849810993619\n",
      "train loss:0.007302519124910112\n",
      "train loss:0.001536832361441336\n",
      "train loss:0.0010066355107456134\n",
      "train loss:0.0024367945142245943\n",
      "train loss:0.0038134935976635977\n",
      "train loss:0.001506293477208146\n",
      "train loss:0.003945091953117684\n",
      "train loss:0.0024115721154507226\n",
      "train loss:0.006277133797288814\n",
      "train loss:0.006888402350304173\n",
      "train loss:0.0011700608949356082\n",
      "train loss:0.021167102062455076\n",
      "train loss:0.044721898339032486\n",
      "train loss:0.0022034586164750946\n",
      "train loss:0.0023635940068407906\n",
      "train loss:0.011648484188655446\n",
      "train loss:0.0010826230024799204\n",
      "train loss:0.004425535651284008\n",
      "train loss:0.010347853623386909\n",
      "train loss:0.0065108007397431476\n",
      "train loss:0.0014259063117126414\n",
      "train loss:0.02907164904329768\n",
      "train loss:0.007165026432278752\n",
      "train loss:0.004963433061660746\n",
      "train loss:0.0041331014218414066\n",
      "train loss:0.009408138827885219\n",
      "train loss:0.008654006873950858\n",
      "train loss:0.010838425318966522\n",
      "train loss:0.009309670088736358\n",
      "train loss:0.0035371375498898343\n",
      "train loss:0.0054315587603586575\n",
      "train loss:0.00783567787268207\n",
      "train loss:0.001920540872685031\n",
      "train loss:0.003786839632963126\n",
      "train loss:0.011692987682551925\n",
      "train loss:0.0023365835968496263\n",
      "train loss:0.005774416235518427\n",
      "train loss:0.0010240085625615129\n",
      "train loss:0.0038000128408417254\n",
      "train loss:0.007323383722624353\n",
      "train loss:0.0070529327506123705\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.002248370687210934\n",
      "train loss:0.0010358133353011438\n",
      "train loss:0.0013997292871412515\n",
      "train loss:0.004090072560902038\n",
      "train loss:0.00153945105394912\n",
      "train loss:0.0213726178594869\n",
      "train loss:0.005140711337713959\n",
      "train loss:0.0018009492937368437\n",
      "train loss:0.006243333697363168\n",
      "train loss:0.01400322585107369\n",
      "train loss:0.001260257833945281\n",
      "train loss:0.000649609589946009\n",
      "train loss:0.010002458205162094\n",
      "train loss:0.006237214570005193\n",
      "train loss:0.002638607371795966\n",
      "=== epoch:11, train acc:0.997, test acc:0.982 ===\n",
      "train loss:0.0014724312379223773\n",
      "train loss:0.00833618340968177\n",
      "train loss:0.014591085066956857\n",
      "train loss:0.0028443068897571907\n",
      "train loss:0.000846558919825169\n",
      "train loss:0.0018558338110820248\n",
      "train loss:0.0005761316073222829\n",
      "train loss:0.004668284439070139\n",
      "train loss:0.002519358648523593\n",
      "train loss:0.003990767083204942\n",
      "train loss:0.004152712641813411\n",
      "train loss:0.008968408782985006\n",
      "train loss:0.0031823472198088455\n",
      "train loss:0.011485418389419322\n",
      "train loss:0.006997782199255869\n",
      "train loss:0.0009960721101432378\n",
      "train loss:0.008594809469135047\n",
      "train loss:0.0013485151969923944\n",
      "train loss:0.020919328506647687\n",
      "train loss:0.0042245331553441194\n",
      "train loss:0.0006200148882863963\n",
      "train loss:0.014531994517806608\n",
      "train loss:0.0057267459128948674\n",
      "train loss:0.012762230275874795\n",
      "train loss:0.05890875929935955\n",
      "train loss:0.07580308873636434\n",
      "train loss:0.02597544121316785\n",
      "train loss:0.004453335466220748\n",
      "train loss:0.011372221563706144\n",
      "train loss:0.0036575294990411145\n",
      "train loss:0.0021388015035742067\n",
      "train loss:0.0005621976539002655\n",
      "train loss:0.004387525658874023\n",
      "train loss:0.007121271387298261\n",
      "train loss:0.004940666025703467\n",
      "train loss:0.01361106723720495\n",
      "train loss:0.005528616546405577\n",
      "train loss:0.0012840528896785708\n",
      "train loss:0.010182485965362833\n",
      "train loss:0.003983017382662959\n",
      "train loss:0.019068059643430512\n",
      "train loss:0.0023127632508978158\n",
      "train loss:0.008514958656771899\n",
      "train loss:0.012766675856187125\n",
      "train loss:0.005240971812410844\n",
      "train loss:0.004543703757469394\n",
      "train loss:0.0027273078129679516\n",
      "train loss:0.015462409008366098\n",
      "train loss:0.0014721534792295197\n",
      "train loss:0.010614409024365891\n",
      "train loss:0.0034861820009005336\n",
      "train loss:0.0012991989269307688\n",
      "train loss:0.004271425410234318\n",
      "train loss:0.01037874141692733\n",
      "train loss:0.008338950633719039\n",
      "train loss:0.007124506013028384\n",
      "train loss:0.004368680810192403\n",
      "train loss:0.003387515292039605\n",
      "train loss:0.026999806739451033\n",
      "train loss:0.0017109464876604416\n",
      "train loss:0.008678121717347054\n",
      "train loss:0.016345046703350016\n",
      "train loss:0.0019899749877095915\n",
      "train loss:0.0015495019798693152\n",
      "train loss:0.008772360899527374\n",
      "train loss:0.0012072880436017537\n",
      "train loss:0.009734405427763888\n",
      "train loss:0.022980962551330298\n",
      "train loss:0.006181643540627275\n",
      "train loss:0.01679074246361984\n",
      "train loss:0.018283921243579995\n",
      "train loss:0.0031673435228551307\n",
      "train loss:0.0027007095512700387\n",
      "train loss:0.002160544252997891\n",
      "train loss:0.004451430065143822\n",
      "train loss:0.002512058660962257\n",
      "train loss:0.0031225665110487634\n",
      "train loss:0.0064094390060310735\n",
      "train loss:0.009629593013610943\n",
      "train loss:0.019097703973728664\n",
      "train loss:0.0038032493764449237\n",
      "train loss:0.0047066412784574725\n",
      "train loss:0.004953575281719026\n",
      "train loss:0.0069894799542256246\n",
      "train loss:0.0012630066101300208\n",
      "train loss:0.009808119500111881\n",
      "train loss:0.002704501700035864\n",
      "train loss:0.00208715192822714\n",
      "train loss:0.009883210610782987\n",
      "train loss:0.006532626120580206\n",
      "train loss:0.004983399122728092\n",
      "train loss:0.014317577450242208\n",
      "train loss:0.005953491017009878\n",
      "train loss:0.07973722864572856\n",
      "train loss:0.010252942871747257\n",
      "train loss:0.0011638836365836468\n",
      "train loss:0.008956546936952726\n",
      "train loss:0.00300813152181833\n",
      "train loss:0.006061375198978623\n",
      "train loss:0.0006137658990598863\n",
      "train loss:0.0035870054731837442\n",
      "train loss:0.0022293773241287397\n",
      "train loss:0.003087989095190444\n",
      "train loss:0.005180091593321949\n",
      "train loss:0.0027653267122680876\n",
      "train loss:0.007585270293245963\n",
      "train loss:0.008849100158112503\n",
      "train loss:0.0014153489118218497\n",
      "train loss:0.0017826550555673482\n",
      "train loss:0.0030575967627843666\n",
      "train loss:0.0014348200536407631\n",
      "train loss:0.03287786766756119\n",
      "train loss:0.006560857657478163\n",
      "train loss:0.001602213565770706\n",
      "train loss:0.005179599940788151\n",
      "train loss:0.0025790596475173634\n",
      "train loss:0.007169199620237018\n",
      "train loss:0.0067702724077580686\n",
      "train loss:0.00868645439070074\n",
      "train loss:0.0014985642874101102\n",
      "train loss:0.0005955174807145723\n",
      "train loss:0.002816217946728875\n",
      "train loss:0.014889667398319286\n",
      "train loss:0.04771899672023063\n",
      "train loss:0.003487523216030321\n",
      "train loss:0.009902011268584521\n",
      "train loss:0.00612095185162536\n",
      "train loss:0.002047647461432815\n",
      "train loss:0.006329459374812112\n",
      "train loss:0.029683409578436484\n",
      "train loss:0.0038544343187104434\n",
      "train loss:0.0076384314106566755\n",
      "train loss:0.00675024768287255\n",
      "train loss:0.015166116137297781\n",
      "train loss:0.007852989054667563\n",
      "train loss:0.001312842844245001\n",
      "train loss:0.022812038100404233\n",
      "train loss:0.0018010203733668908\n",
      "train loss:0.0036312280229233453\n",
      "train loss:0.005791671947775692\n",
      "train loss:0.0014341470882762697\n",
      "train loss:0.0006718671209761443\n",
      "train loss:0.016081997017571438\n",
      "train loss:0.0157383501884156\n",
      "train loss:0.0006775159651608528\n",
      "train loss:0.0062782361435065335\n",
      "train loss:0.0066848904888753\n",
      "train loss:0.00178206774914103\n",
      "train loss:0.0052808009957956556\n",
      "train loss:0.008686834666105009\n",
      "train loss:0.05545858353616105\n",
      "train loss:0.020876232321651155\n",
      "train loss:0.004676540893923917\n",
      "train loss:0.04588689535288307\n",
      "train loss:0.006197728600452793\n",
      "train loss:0.0062063947933472755\n",
      "train loss:0.006998272046698085\n",
      "train loss:0.0007966206406756184\n",
      "train loss:0.022165939164909672\n",
      "train loss:0.0171750346692454\n",
      "train loss:0.009817454883893795\n",
      "train loss:0.0011733093827883876\n",
      "train loss:0.005429826824127865\n",
      "train loss:0.002307302325824538\n",
      "train loss:0.004244753989804215\n",
      "train loss:0.0029270736911652852\n",
      "train loss:0.02218320892417834\n",
      "train loss:0.0044790360436570585\n",
      "train loss:0.001868122421509814\n",
      "train loss:0.004623698426172375\n",
      "train loss:0.0028912309360937887\n",
      "train loss:0.0012827938781405774\n",
      "train loss:0.0088715517125316\n",
      "train loss:0.005937906152309248\n",
      "train loss:0.0013879784609626392\n",
      "train loss:0.05693481423467521\n",
      "train loss:0.0024637462965518913\n",
      "train loss:0.007074187953357527\n",
      "train loss:0.005928343679925838\n",
      "train loss:0.0019971159447102825\n",
      "train loss:0.001441744766375476\n",
      "train loss:0.0029884330278849886\n",
      "train loss:0.007707954961317019\n",
      "train loss:0.003909101950803229\n",
      "train loss:0.004519470550563617\n",
      "train loss:0.00037147713675554113\n",
      "train loss:0.005610009182026251\n",
      "train loss:0.0009164210417637547\n",
      "train loss:0.01307122935066251\n",
      "train loss:0.004283774960843789\n",
      "train loss:0.0022756472049763\n",
      "train loss:0.002460021804408089\n",
      "train loss:0.007387156387845548\n",
      "train loss:0.0009535932941563988\n",
      "train loss:0.003932055280305593\n",
      "train loss:0.002734090893041106\n",
      "train loss:0.0047756346313022465\n",
      "train loss:0.0020821997903115864\n",
      "train loss:0.0019403791360038116\n",
      "train loss:0.011482455070537806\n",
      "train loss:0.002554224275321303\n",
      "train loss:0.003602954589441103\n",
      "train loss:0.0006309670948087483\n",
      "train loss:0.02600095937705163\n",
      "train loss:0.020062463368889522\n",
      "train loss:0.0022602903196931984\n",
      "train loss:0.004345536151122893\n",
      "train loss:0.0018602546926528656\n",
      "train loss:0.0021471126393760327\n",
      "train loss:0.005651748155395835\n",
      "train loss:0.00022095460155629603\n",
      "train loss:0.005195214571915118\n",
      "train loss:0.0023795747516729923\n",
      "train loss:0.010070584549963249\n",
      "train loss:0.004621962802383034\n",
      "train loss:0.005574986817529262\n",
      "train loss:0.0009168870056087903\n",
      "train loss:0.008971921316891987\n",
      "train loss:0.001203772215934138\n",
      "train loss:0.0030669255460488228\n",
      "train loss:0.012079528995830549\n",
      "train loss:0.012348920486129962\n",
      "train loss:0.048577217430159865\n",
      "train loss:0.013640189721634544\n",
      "train loss:0.0006057393636048024\n",
      "train loss:0.008081437584671157\n",
      "train loss:0.0017503252227952268\n",
      "train loss:0.0013949537215277418\n",
      "train loss:0.004112833731288175\n",
      "train loss:0.00033758245129490575\n",
      "train loss:0.0014418853165515109\n",
      "train loss:0.0037934315162638428\n",
      "train loss:0.005332117347349921\n",
      "train loss:0.0025099240594309946\n",
      "train loss:0.0037540350437767355\n",
      "train loss:0.0034693792819725654\n",
      "train loss:0.0028252450833800196\n",
      "train loss:0.0023080898340206964\n",
      "train loss:0.002252227823657459\n",
      "train loss:0.004984392611215624\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.000625885286760247\n",
      "train loss:0.00310528412962837\n",
      "train loss:0.00411467152134792\n",
      "train loss:0.0021940946349140295\n",
      "train loss:0.007561578736238305\n",
      "train loss:0.002714334005759673\n",
      "train loss:0.006021120135584085\n",
      "train loss:0.0003797790467254385\n",
      "train loss:0.006844456744031118\n",
      "train loss:0.0047258280844304345\n",
      "train loss:0.00017647159985499327\n",
      "train loss:0.000873846573056965\n",
      "train loss:0.007631102875810523\n",
      "train loss:0.0012936969507342875\n",
      "train loss:0.00559083727551666\n",
      "train loss:0.0016852386129217287\n",
      "train loss:0.008026672372592396\n",
      "train loss:0.003816934382664016\n",
      "train loss:0.007394937311778708\n",
      "train loss:0.00048073389047328366\n",
      "train loss:0.003131654370335435\n",
      "train loss:0.0005472141861457866\n",
      "train loss:0.003913793605148378\n",
      "train loss:0.007492240886208052\n",
      "train loss:0.0018974235159235622\n",
      "train loss:0.016319681771864693\n",
      "train loss:0.004573591753144258\n",
      "train loss:0.001871482969742616\n",
      "train loss:0.0008817511414601429\n",
      "train loss:0.004825071552691463\n",
      "train loss:0.0016556857120843343\n",
      "train loss:0.0005853468382975652\n",
      "train loss:0.0027752955751239694\n",
      "train loss:0.0030724410875184634\n",
      "train loss:0.006928158912211474\n",
      "train loss:0.0019578940231498154\n",
      "train loss:0.001691901191668395\n",
      "train loss:0.00444502389757179\n",
      "train loss:0.0005334932855735488\n",
      "train loss:0.004872099558138638\n",
      "train loss:0.0004454459418883874\n",
      "train loss:0.0006539470950012562\n",
      "train loss:0.002134610769915512\n",
      "train loss:0.033042727151056925\n",
      "train loss:0.007526767434679299\n",
      "train loss:0.002643312980174451\n",
      "train loss:0.002632903531136781\n",
      "train loss:0.000707312396733264\n",
      "train loss:0.004422962927418042\n",
      "train loss:0.005227122080470869\n",
      "train loss:0.0016687301992992522\n",
      "train loss:0.0021113441874791457\n",
      "train loss:0.0009769276830715414\n",
      "train loss:0.001302378862451605\n",
      "train loss:0.000279461750550216\n",
      "train loss:0.007242062983590564\n",
      "train loss:0.0008558543170254888\n",
      "train loss:0.0002571398809329676\n",
      "train loss:0.00426531496435066\n",
      "train loss:0.000903578518275854\n",
      "train loss:0.0019325923135925852\n",
      "train loss:0.002332112603567002\n",
      "train loss:0.006067350406309536\n",
      "train loss:0.00017902739838139943\n",
      "train loss:0.0007002228674072784\n",
      "train loss:0.0018433777379243867\n",
      "train loss:0.01373232313796142\n",
      "train loss:0.001163390414349738\n",
      "train loss:0.00248285092922679\n",
      "train loss:0.0037519116266475456\n",
      "train loss:0.0059182755123918015\n",
      "train loss:0.012120693886100981\n",
      "train loss:0.0018381205463541992\n",
      "train loss:0.0001782511740774564\n",
      "train loss:0.0011763640178346386\n",
      "train loss:0.007045259037192452\n",
      "train loss:0.002228525544783617\n",
      "train loss:0.002961015385821791\n",
      "train loss:0.004511121702455307\n",
      "train loss:0.00043052035690153035\n",
      "train loss:0.0011215268045351359\n",
      "train loss:0.0046845619358001035\n",
      "train loss:0.001360490316316764\n",
      "train loss:0.005436107592845776\n",
      "train loss:0.009333534524056043\n",
      "train loss:0.0025944244236985126\n",
      "train loss:0.0020411181078977144\n",
      "train loss:0.0014549640486125686\n",
      "train loss:0.0344100689665105\n",
      "train loss:0.004021767492749125\n",
      "train loss:0.05610460501360714\n",
      "train loss:0.0025751980182588336\n",
      "train loss:0.01637824265749343\n",
      "train loss:0.005509733752233776\n",
      "train loss:0.002786539635364531\n",
      "train loss:0.00866554951691013\n",
      "train loss:0.0020241394970210583\n",
      "train loss:0.042552230742845074\n",
      "train loss:0.00036968112841390593\n",
      "train loss:0.00022921710695720184\n",
      "train loss:0.0017818289770170092\n",
      "train loss:0.001482926695662175\n",
      "train loss:0.018134766898819318\n",
      "train loss:0.003254947604320037\n",
      "train loss:0.010322892182411917\n",
      "train loss:0.00410030130017649\n",
      "train loss:0.0019710793518125293\n",
      "train loss:0.0012686534490231208\n",
      "train loss:0.0008161598283507545\n",
      "train loss:0.007385941801653253\n",
      "train loss:0.011430487827734743\n",
      "train loss:0.0028194812179918164\n",
      "train loss:0.027035829495992723\n",
      "train loss:0.0017824191948819866\n",
      "train loss:0.0018434456256670151\n",
      "train loss:0.0052715203417744725\n",
      "train loss:0.0012825921324729423\n",
      "train loss:0.0035700854616879762\n",
      "train loss:0.0011541155869213972\n",
      "train loss:0.0018849981017551233\n",
      "train loss:0.0039276957610630174\n",
      "train loss:0.0014385707522668889\n",
      "train loss:0.006188817316496714\n",
      "train loss:0.0045043618483304095\n",
      "train loss:0.003452610188771453\n",
      "train loss:0.0016726347376595826\n",
      "train loss:0.003289366647770049\n",
      "train loss:0.004472230595084635\n",
      "train loss:0.006468523398827994\n",
      "train loss:0.00895318122981018\n",
      "train loss:0.0012198032168447106\n",
      "train loss:0.006027047172379546\n",
      "train loss:0.007393234593719084\n",
      "train loss:0.000180805269347737\n",
      "train loss:0.0012120143577332508\n",
      "train loss:0.0025971265835683325\n",
      "train loss:0.005351549295802893\n",
      "train loss:0.0076545983749806736\n",
      "train loss:0.00043536601285252587\n",
      "train loss:0.006479060471891993\n",
      "train loss:0.005125508564104779\n",
      "train loss:0.0017376150758181387\n",
      "train loss:0.011073908164744713\n",
      "train loss:0.0010475199474091956\n",
      "train loss:0.0005296302038237979\n",
      "train loss:0.008766898241024052\n",
      "train loss:0.003652716261784261\n",
      "train loss:0.0004427708644164961\n",
      "train loss:0.0011158025819824552\n",
      "train loss:0.0021284831775955308\n",
      "train loss:0.0023485433056904042\n",
      "train loss:0.002765637297248695\n",
      "train loss:0.000370339606474063\n",
      "train loss:0.015046202073025958\n",
      "train loss:0.002143615964743296\n",
      "train loss:0.0015318858057158033\n",
      "train loss:0.0012588488028931419\n",
      "train loss:0.0059693097182901165\n",
      "train loss:0.006991875759457026\n",
      "train loss:0.007446037630415756\n",
      "train loss:0.020743264058100435\n",
      "train loss:0.002541823795824706\n",
      "train loss:0.0015460888076192264\n",
      "train loss:0.0023360435117382194\n",
      "train loss:0.0031821639229363085\n",
      "train loss:0.003571330029176686\n",
      "train loss:0.010133221275570729\n",
      "train loss:0.006292260916442946\n",
      "train loss:0.03698221365036224\n",
      "train loss:0.03238941624690066\n",
      "train loss:0.0016731016116396788\n",
      "train loss:0.011485947202881642\n",
      "train loss:0.00066329524412044\n",
      "train loss:0.0026582575540180383\n",
      "train loss:0.004108250077569919\n",
      "train loss:0.0015376231173209914\n",
      "train loss:0.0015036970460722567\n",
      "train loss:0.017577671148653124\n",
      "train loss:0.008040942834855642\n",
      "train loss:0.010160994462103763\n",
      "train loss:0.0023128716932282163\n",
      "train loss:0.013975313536230478\n",
      "train loss:0.00533539558318596\n",
      "train loss:0.012640444401462505\n",
      "train loss:0.004026376122747677\n",
      "train loss:0.011678403023735668\n",
      "train loss:0.0033387103651529777\n",
      "train loss:0.001899317129016\n",
      "train loss:0.0007370032579315477\n",
      "train loss:0.002000027041188602\n",
      "train loss:0.005460876087818425\n",
      "train loss:0.0040348657376939635\n",
      "train loss:0.0033967396898811823\n",
      "train loss:0.004633561308304879\n",
      "train loss:0.038551216783606714\n",
      "train loss:0.013196090078363542\n",
      "train loss:0.001348471748356334\n",
      "train loss:0.005839700509844674\n",
      "train loss:0.006609590202439\n",
      "train loss:0.0036201178488976483\n",
      "train loss:0.0064040983159492585\n",
      "train loss:0.014128888745090391\n",
      "train loss:0.032683062666078955\n",
      "train loss:0.0052880677245617565\n",
      "train loss:0.006568385455511602\n",
      "train loss:0.000986789549552818\n",
      "train loss:0.004557674908078873\n",
      "train loss:0.010337098208341302\n",
      "train loss:0.017762533752473927\n",
      "train loss:0.0026266779182371027\n",
      "train loss:0.0006829116286691925\n",
      "train loss:0.003090493003836027\n",
      "train loss:0.005343881991225042\n",
      "train loss:0.00536458813456544\n",
      "train loss:0.0032021106159212803\n",
      "train loss:0.009794478402730794\n",
      "train loss:0.0019196994328688803\n",
      "train loss:0.0005008241444588618\n",
      "train loss:0.0011199729891812444\n",
      "train loss:0.003582134438341321\n",
      "train loss:0.008160599957916266\n",
      "train loss:0.005655416111572039\n",
      "train loss:0.02378451864067102\n",
      "train loss:0.0014682899020877203\n",
      "train loss:0.014599080169939627\n",
      "train loss:0.0015303880522351942\n",
      "train loss:0.0037375592108955568\n",
      "train loss:0.001095074099336711\n",
      "train loss:0.0026018486198386365\n",
      "train loss:0.006345077642672455\n",
      "train loss:0.007866775405758421\n",
      "train loss:0.0011049987822079092\n",
      "train loss:0.006033860923274547\n",
      "train loss:0.00355539420110325\n",
      "train loss:0.010922299442158546\n",
      "train loss:0.0005047334419990697\n",
      "train loss:0.0027735419847007355\n",
      "train loss:0.0019804865344805866\n",
      "train loss:0.0016731272293698906\n",
      "train loss:0.006746215643336353\n",
      "train loss:0.001466582907633744\n",
      "train loss:0.0033700341957589785\n",
      "train loss:0.0005872833070878515\n",
      "train loss:0.0037023362466564436\n",
      "train loss:0.0018349306192556863\n",
      "train loss:0.016439567010030017\n",
      "train loss:0.0019291262703610952\n",
      "train loss:0.05068789973213942\n",
      "train loss:0.0008150840143808073\n",
      "train loss:0.002290511570949462\n",
      "train loss:0.0029317936198667567\n",
      "train loss:0.0038330189701632138\n",
      "train loss:0.0011149661488161885\n",
      "train loss:0.006213374843831347\n",
      "train loss:0.005037889646059206\n",
      "train loss:0.008963206244267155\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.009726823055139276\n",
      "train loss:0.0006421694488504564\n",
      "train loss:0.0007460216652558226\n",
      "train loss:0.001794220255659478\n",
      "train loss:0.003444911701407522\n",
      "train loss:0.008085963385501238\n",
      "train loss:0.0017085048035864825\n",
      "train loss:0.0027379274985867607\n",
      "train loss:0.010581050615126026\n",
      "train loss:0.0005459908609472727\n",
      "train loss:0.02154636354727069\n",
      "train loss:0.002068996246975381\n",
      "train loss:0.0011158125868133747\n",
      "train loss:0.000177916363985151\n",
      "train loss:0.004475623277296683\n",
      "train loss:0.0034958610232086267\n",
      "train loss:0.0502863588051369\n",
      "train loss:0.0025464391242667854\n",
      "train loss:0.017174386769070724\n",
      "train loss:0.001946615575971793\n",
      "train loss:0.0024818358041948417\n",
      "train loss:0.0047699957402018425\n",
      "train loss:0.013230649289876164\n",
      "train loss:0.0013351251346175718\n",
      "train loss:0.009364209603978782\n",
      "train loss:0.003973615315511393\n",
      "train loss:0.013322520267447702\n",
      "train loss:0.011389827827357485\n",
      "train loss:0.0008661101262568295\n",
      "train loss:0.0003337272714087054\n",
      "train loss:0.003990133753081203\n",
      "train loss:0.012319033291250898\n",
      "train loss:0.004686312598579612\n",
      "train loss:0.011068659357682378\n",
      "train loss:0.004869702262204397\n",
      "train loss:0.004834186995706723\n",
      "train loss:0.0016467717793876024\n",
      "train loss:0.0017121797366447923\n",
      "train loss:0.001599357111775414\n",
      "train loss:0.0006920431896860479\n",
      "train loss:0.0067582388247693324\n",
      "train loss:0.011522455446460385\n",
      "train loss:0.011050056039414599\n",
      "train loss:0.01135706284836397\n",
      "train loss:0.011272130548226657\n",
      "train loss:0.012010822358133333\n",
      "train loss:0.0031908858684174418\n",
      "train loss:0.019552838627313152\n",
      "train loss:0.003903754437178093\n",
      "train loss:0.007942680695811928\n",
      "train loss:0.00536590071658295\n",
      "train loss:0.0028503327541204303\n",
      "train loss:0.005755504533555813\n",
      "train loss:0.004393859690708044\n",
      "train loss:0.0021333026033998025\n",
      "train loss:0.005500156331232963\n",
      "train loss:0.0018587663118244926\n",
      "train loss:0.025357450193562767\n",
      "train loss:0.008590974591730333\n",
      "train loss:0.005920954121347266\n",
      "train loss:0.0058953677067109375\n",
      "train loss:0.0048296909705573135\n",
      "train loss:0.0068849102523400275\n",
      "train loss:0.018227502435804878\n",
      "train loss:0.004257906341630536\n",
      "train loss:0.020152280189017747\n",
      "train loss:0.007526574931550346\n",
      "train loss:0.007963629250633153\n",
      "train loss:0.010549655887355729\n",
      "train loss:0.005051836491650197\n",
      "train loss:0.0029264015979361597\n",
      "train loss:0.001073997971550742\n",
      "train loss:0.00631536457116193\n",
      "train loss:0.0063243504718334155\n",
      "train loss:0.03167613026544405\n",
      "train loss:0.0050798569134306295\n",
      "train loss:0.006061495337027956\n",
      "train loss:0.009456105124305218\n",
      "train loss:0.00471283620494412\n",
      "train loss:0.04209936023731084\n",
      "train loss:0.004955619601422292\n",
      "train loss:0.022212188885229377\n",
      "train loss:0.00749457978021192\n",
      "train loss:0.007880806051924347\n",
      "train loss:0.008501776881956817\n",
      "train loss:0.0009312950793056613\n",
      "train loss:0.0023468430624454827\n",
      "train loss:0.0007587981687021482\n",
      "train loss:0.0012933200836145243\n",
      "train loss:0.005044679641915829\n",
      "train loss:0.003051310451094252\n",
      "train loss:0.006102376694395824\n",
      "train loss:0.005692672056989317\n",
      "train loss:0.001707981818229605\n",
      "train loss:0.006405795554195919\n",
      "train loss:0.0024055329486489356\n",
      "train loss:0.008780289276029704\n",
      "train loss:0.002550766229089217\n",
      "train loss:0.010152319723792776\n",
      "train loss:0.01874409363528099\n",
      "train loss:0.001862288642423748\n",
      "train loss:0.013369762717503866\n",
      "train loss:0.0010973152414943124\n",
      "train loss:0.00527628857063239\n",
      "=== epoch:12, train acc:0.999, test acc:0.986 ===\n",
      "train loss:0.0032127830152936143\n",
      "train loss:0.0006893231681030701\n",
      "train loss:0.0017295460023384571\n",
      "train loss:0.0011876998688769027\n",
      "train loss:0.0029839296698653483\n",
      "train loss:0.003248376288639308\n",
      "train loss:0.01338402632865461\n",
      "train loss:0.000834356768002895\n",
      "train loss:0.001104777577879446\n",
      "train loss:0.0025454137160202408\n",
      "train loss:0.002247338545895049\n",
      "train loss:0.0035226927569619914\n",
      "train loss:0.0024449316053907406\n",
      "train loss:0.0019492205734257515\n",
      "train loss:0.001823118435525872\n",
      "train loss:0.0006968299206355158\n",
      "train loss:0.0005603944294454976\n",
      "train loss:0.0012536521915107496\n",
      "train loss:0.007500547195401486\n",
      "train loss:0.0026487488640552993\n",
      "train loss:0.00038705138884941015\n",
      "train loss:0.0010231100246991206\n",
      "train loss:0.0024676802851166927\n",
      "train loss:0.0023100741639168003\n",
      "train loss:0.0037174234807096957\n",
      "train loss:0.0007220525467168337\n",
      "train loss:0.0034563954627241955\n",
      "train loss:0.00022452759212589197\n",
      "train loss:0.00535985323008762\n",
      "train loss:0.0010568184927756742\n",
      "train loss:0.005684821701886323\n",
      "train loss:0.003860740323309428\n",
      "train loss:0.0009904338180074066\n",
      "train loss:0.0018491404386859164\n",
      "train loss:0.0016205458678963509\n",
      "train loss:0.0015814220692816894\n",
      "train loss:0.023776165158077647\n",
      "train loss:0.0031247468348533764\n",
      "train loss:0.09615419262220161\n",
      "train loss:0.004224705988882069\n",
      "train loss:0.005699754921899224\n",
      "train loss:0.000608235010842749\n",
      "train loss:0.004165257290364856\n",
      "train loss:0.004478221476551218\n",
      "train loss:0.0002475664357618745\n",
      "train loss:0.01149058404806841\n",
      "train loss:0.0026629714119286215\n",
      "train loss:0.0004917963879518958\n",
      "train loss:0.0018835765827976338\n",
      "train loss:0.004702311302065293\n",
      "train loss:0.0015462917531939924\n",
      "train loss:0.0029759999229290283\n",
      "train loss:0.0004614139474794336\n",
      "train loss:0.0018440443525121458\n",
      "train loss:0.005678644919699615\n",
      "train loss:0.002223954953687716\n",
      "train loss:0.0241268426105318\n",
      "train loss:0.010745122235433849\n",
      "train loss:0.005249371734429263\n",
      "train loss:0.0005723434972998431\n",
      "train loss:0.0075457596409996145\n",
      "train loss:0.0010671026608710659\n",
      "train loss:0.008547557149590858\n",
      "train loss:0.005552428879559589\n",
      "train loss:0.0017032509511890326\n",
      "train loss:0.0023390302406322773\n",
      "train loss:0.0016348911507672215\n",
      "train loss:0.01101838733876463\n",
      "train loss:0.0015142513372010825\n",
      "train loss:0.0014658936111143811\n",
      "train loss:0.0006091913346653439\n",
      "train loss:0.002703722879665445\n",
      "train loss:0.0015071666819038065\n",
      "train loss:0.00434093761575176\n",
      "train loss:0.0018855726084095364\n",
      "train loss:0.002826657086968332\n",
      "train loss:0.006998128315970459\n",
      "train loss:0.0055349115944642625\n",
      "train loss:0.0056824797112573384\n",
      "train loss:0.005937113928119711\n",
      "train loss:0.004362188728791141\n",
      "train loss:0.0018222992444655438\n",
      "train loss:0.012374069099431865\n",
      "train loss:0.0014871838596757058\n",
      "train loss:0.002650244288801177\n",
      "train loss:0.020003537156784556\n",
      "train loss:0.000581802912456537\n",
      "train loss:0.02972707908348596\n",
      "train loss:0.010539243654678279\n",
      "train loss:0.0006930454127648275\n",
      "train loss:0.003393268319734823\n",
      "train loss:0.0055790932950766205\n",
      "train loss:0.003710986186710626\n",
      "train loss:0.007371061713314094\n",
      "train loss:0.001559455714006738\n",
      "train loss:0.008364941878283986\n",
      "train loss:0.009460254996774345\n",
      "train loss:0.0049386835577693924\n",
      "train loss:0.0020595975182352315\n",
      "train loss:0.06681641061093851\n",
      "train loss:0.019148554767209267\n",
      "train loss:0.009124834944452879\n",
      "train loss:0.009471927850413996\n",
      "train loss:0.005412384804344672\n",
      "train loss:0.0016953327051721602\n",
      "train loss:0.002072637640743088\n",
      "train loss:0.0035009455561764895\n",
      "train loss:0.004922007332947399\n",
      "train loss:0.005808429029643403\n",
      "train loss:0.0018378474548720438\n",
      "train loss:0.007927952769769053\n",
      "train loss:0.013265025645591764\n",
      "train loss:0.004847119591009531\n",
      "train loss:0.00041331060978429506\n",
      "train loss:0.01494012783099415\n",
      "train loss:0.0017990647498151418\n",
      "train loss:0.0010862598716597435\n",
      "train loss:0.0002895717948856934\n",
      "train loss:0.040334889279857115\n",
      "train loss:0.0007583839491531742\n",
      "train loss:0.0010454507497057526\n",
      "train loss:0.010799231130558626\n",
      "train loss:0.0036488251535374\n",
      "train loss:0.0018195445938467116\n",
      "train loss:0.0027835516393796634\n",
      "train loss:0.004460611119274042\n",
      "train loss:0.008104757088996533\n",
      "train loss:0.007530476365306495\n",
      "train loss:0.01138546621724778\n",
      "train loss:0.00459760879612244\n",
      "train loss:0.008204908468682649\n",
      "train loss:0.005962459065730481\n",
      "train loss:0.006113841845699202\n",
      "train loss:0.001986698323759536\n",
      "train loss:0.000480867658919495\n",
      "train loss:0.001332372512009804\n",
      "train loss:0.01967032986519981\n",
      "train loss:0.003040565684201433\n",
      "train loss:0.009477142570327154\n",
      "train loss:0.00106544368071781\n",
      "train loss:0.0008920617153158011\n",
      "train loss:0.002827658188624494\n",
      "train loss:0.002959959997298907\n",
      "train loss:0.0021213720905854843\n",
      "train loss:0.010790667729183285\n",
      "train loss:0.00251070088730733\n",
      "train loss:0.005947300511044608\n",
      "train loss:0.005313645284815555\n",
      "train loss:0.0031831114050332337\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.005401236537566257\n",
      "train loss:0.008931805921516852\n",
      "train loss:0.006109756290901448\n",
      "train loss:0.0065006431570181315\n",
      "train loss:0.021000957667850498\n",
      "train loss:0.003437375257347162\n",
      "train loss:0.002702825049991428\n",
      "train loss:0.001621687770464514\n",
      "train loss:0.004226310506024396\n",
      "train loss:0.030930886179308746\n",
      "train loss:0.005968545238292466\n",
      "train loss:0.0006967831867857209\n",
      "train loss:0.010206779894319323\n",
      "train loss:0.0037186386684966975\n",
      "train loss:0.006982269248992589\n",
      "train loss:0.0031190346032732713\n",
      "train loss:0.006555797500908679\n",
      "train loss:0.013611263410923303\n",
      "train loss:0.001303862393400259\n",
      "train loss:0.00037558898398580516\n",
      "train loss:0.0043959464160898305\n",
      "train loss:0.0018462318098962365\n",
      "train loss:0.0016981772645735815\n",
      "train loss:0.007723076169177321\n",
      "train loss:0.009412462144499261\n",
      "train loss:0.003050489875247366\n",
      "train loss:0.0025258482117021656\n",
      "train loss:0.001461350021086322\n",
      "train loss:0.013635878121683521\n",
      "train loss:0.002647147611598614\n",
      "train loss:0.019968079165653744\n",
      "train loss:0.0007242957695895527\n",
      "train loss:0.024543449075288697\n",
      "train loss:0.004857202948878491\n",
      "train loss:0.008611963367134096\n",
      "train loss:0.004083565577461036\n",
      "train loss:0.002980785691835704\n",
      "train loss:0.00046608808186466866\n",
      "train loss:0.023551244603830086\n",
      "train loss:0.0017376485585405448\n",
      "train loss:0.0021293979597254696\n",
      "train loss:0.0006001926756149822\n",
      "train loss:0.004276171688583197\n",
      "train loss:0.0007039348841842201\n",
      "train loss:0.00047772131740794684\n",
      "train loss:0.001727188285033199\n",
      "train loss:0.004470650376102867\n",
      "train loss:0.005639060887241657\n",
      "train loss:0.0037789275535762635\n",
      "train loss:0.008987787388504647\n",
      "train loss:0.003623882566107005\n",
      "train loss:0.031204670654591826\n",
      "train loss:0.0006401014732241274\n",
      "train loss:0.0052111844934758025\n",
      "train loss:0.0011384692139115033\n",
      "train loss:0.0017200960215347707\n",
      "train loss:0.0027817855296965103\n",
      "train loss:0.005871409587295152\n",
      "train loss:0.0012577587294016253\n",
      "train loss:0.03802844428789205\n",
      "train loss:0.005617439467864427\n",
      "train loss:0.0065585574548511815\n",
      "train loss:0.0034801210156205267\n",
      "train loss:0.03233551601067684\n",
      "train loss:0.0027501881020645016\n",
      "train loss:0.002760564491588209\n",
      "train loss:0.015142424468077646\n",
      "train loss:0.008219253666535207\n",
      "train loss:0.0008044153392133817\n",
      "train loss:0.0018341639523565636\n",
      "train loss:0.0020464609057976564\n",
      "train loss:0.0036277825602510855\n",
      "train loss:0.003440107579197154\n",
      "train loss:0.0028146162576729856\n",
      "train loss:0.0023674180752922417\n",
      "train loss:0.0023387197827173852\n",
      "train loss:0.0004709682303262235\n",
      "train loss:0.0001382520476372239\n",
      "train loss:0.004007878057794368\n",
      "train loss:0.0017328104410441803\n",
      "train loss:0.0032696044882402227\n",
      "train loss:0.003849288362729938\n",
      "train loss:0.0007361139133933084\n",
      "train loss:0.003979833398625812\n",
      "train loss:0.0016018474013322816\n",
      "train loss:0.0009452219860677503\n",
      "train loss:0.0017743890518133049\n",
      "train loss:0.01280372998683197\n",
      "train loss:0.005224843237042932\n",
      "train loss:0.0010530944746540089\n",
      "train loss:0.005440241971540514\n",
      "train loss:0.0015789044913209877\n",
      "train loss:0.0050687412064745275\n",
      "train loss:0.0023563657005908323\n",
      "train loss:0.0021008432420147453\n",
      "train loss:0.011687797938552178\n",
      "train loss:0.0017340968015298677\n",
      "train loss:0.021572886393466103\n",
      "train loss:0.0003980257464763797\n",
      "train loss:0.00478779139222701\n",
      "train loss:0.0051904174674894\n",
      "train loss:0.0013159276067338185\n",
      "train loss:0.003238320612808117\n",
      "train loss:0.0022528935534477284\n",
      "train loss:0.004125185770993257\n",
      "train loss:0.006249118666424618\n",
      "train loss:0.0008997292235805802\n",
      "train loss:0.006842048712554941\n",
      "train loss:0.0019781633627710417\n",
      "train loss:0.011642684987555633\n",
      "train loss:0.004681382082469231\n",
      "train loss:0.009202956898772744\n",
      "train loss:0.041553559458937406\n",
      "train loss:0.0013806574334935095\n",
      "train loss:0.002144120548634597\n",
      "train loss:0.006114206768880133\n",
      "train loss:0.007588547884704597\n",
      "train loss:0.002484614102164302\n",
      "train loss:0.004064079264050086\n",
      "train loss:0.02777701390240775\n",
      "train loss:0.000726167806131968\n",
      "train loss:0.002044817599821268\n",
      "train loss:0.004535585684163866\n",
      "train loss:0.0137915648773917\n",
      "train loss:0.013143410456004081\n",
      "train loss:0.02485491362731251\n",
      "train loss:0.0035072433671779635\n",
      "train loss:0.026742531975624807\n",
      "train loss:0.002620473437067253\n",
      "train loss:0.0026366526238781533\n",
      "train loss:0.012436552956567917\n",
      "train loss:0.0028862954882377433\n",
      "train loss:0.0029899088177577624\n",
      "train loss:0.010815165298446847\n",
      "train loss:0.014877048587272623\n",
      "train loss:0.01797229816995505\n",
      "train loss:0.003586401302918061\n",
      "train loss:0.001912706769803028\n",
      "train loss:0.008318788651439996\n",
      "train loss:0.004159730590215339\n",
      "train loss:0.0005222498249065767\n",
      "train loss:0.000694777051449837\n",
      "train loss:0.0010155703877530208\n",
      "train loss:0.004230361000660335\n",
      "train loss:0.0009299039823271135\n",
      "train loss:0.0022889758701809997\n",
      "train loss:0.0006994270163575537\n",
      "train loss:0.005022398834222353\n",
      "train loss:0.0013047047015639862\n",
      "train loss:0.0029033848448858364\n",
      "train loss:0.006095164043190756\n",
      "train loss:0.0726225351810152\n",
      "train loss:0.0006700259714251183\n",
      "train loss:0.0008022646957924699\n",
      "train loss:0.002145706222314823\n",
      "train loss:0.005510338334700985\n",
      "train loss:0.001100485638193057\n",
      "train loss:0.0027815444956710215\n",
      "train loss:0.00218997946478592\n",
      "train loss:0.006787672477133935\n",
      "train loss:0.0015982827927204036\n",
      "train loss:0.0029078653044513135\n",
      "train loss:0.006329359933805155\n",
      "train loss:0.0012049013691184298\n",
      "train loss:0.011169648796176183\n",
      "train loss:0.0070298153926005155\n",
      "train loss:0.0015612835664042814\n",
      "train loss:0.0013530791760254614\n",
      "train loss:0.00397699227291878\n",
      "train loss:0.0041415914741869545\n",
      "train loss:0.0026029517987233037\n",
      "train loss:0.002731229789226285\n",
      "train loss:0.016306002336418827\n",
      "train loss:0.002678430037563058\n",
      "train loss:0.010552093891841356\n",
      "train loss:0.002228073437736004\n",
      "train loss:0.0136819451365137\n",
      "train loss:0.0026061567343231267\n",
      "train loss:0.002985151061217501\n",
      "train loss:0.006018345854881144\n",
      "train loss:0.0024472847450660775\n",
      "train loss:0.0016917489863202018\n",
      "train loss:0.0017912319374666621\n",
      "train loss:0.0037208196488284872\n",
      "train loss:0.0005219807044530138\n",
      "train loss:0.0006150151955815033\n",
      "train loss:0.002291804899031642\n",
      "train loss:0.0012312795055103361\n",
      "train loss:0.007949715848408121\n",
      "train loss:0.0029656231918391463\n",
      "train loss:0.008529984827654985\n",
      "train loss:0.0001325911565963822\n",
      "train loss:0.0023858881086306514\n",
      "train loss:0.0010113458989404796\n",
      "train loss:0.0038785410674427616\n",
      "train loss:0.0006907090449323244\n",
      "train loss:0.0037963954300757052\n",
      "train loss:0.000622534338151116\n",
      "train loss:0.006460127780805355\n",
      "train loss:0.013314282767056802\n",
      "train loss:0.0008402824833389158\n",
      "train loss:0.000901514503351541\n",
      "train loss:0.0019088023312933077\n",
      "train loss:0.0037416929219637103\n",
      "train loss:0.009061970406206961\n",
      "train loss:0.003318360851038778\n",
      "train loss:0.0017638149624999064\n",
      "train loss:0.0011897703243528897\n",
      "train loss:0.006927495706663661\n",
      "train loss:0.0038877907187893075\n",
      "train loss:0.06045551940902413\n",
      "train loss:0.004070639633290999\n",
      "train loss:0.00242428556398213\n",
      "train loss:0.006064033114071712\n",
      "train loss:0.0011530943715294317\n",
      "train loss:0.0018161495698930722\n",
      "train loss:0.002206045218948194\n",
      "train loss:0.09471203768995659\n",
      "train loss:0.003037803460641732\n",
      "train loss:0.0031723097822027547\n",
      "train loss:0.0016243645929839717\n",
      "train loss:0.0018685969381298368\n",
      "train loss:0.00038175758562299637\n",
      "train loss:0.0011315214124215144\n",
      "train loss:0.013993408621053001\n",
      "train loss:0.009220315360732898\n",
      "train loss:0.003928518592021368\n",
      "train loss:0.0030265475400890144\n",
      "train loss:0.002619138065089477\n",
      "train loss:0.012340044314977134\n",
      "train loss:0.006013227655168782\n",
      "train loss:0.004504721109659849\n",
      "train loss:0.001160282617754512\n",
      "train loss:0.0010685470025942952\n",
      "train loss:0.009841665647236278\n",
      "train loss:0.0032486744715844802\n",
      "train loss:0.0005393008055222248\n",
      "train loss:0.04227626923430404\n",
      "train loss:0.009928588148969504\n",
      "train loss:0.006262492196805256\n",
      "train loss:0.0036059048728757735\n",
      "train loss:0.01182070482615208\n",
      "train loss:0.0012225530621491987\n",
      "train loss:0.0026290316789915535\n",
      "train loss:0.005058571669325805\n",
      "train loss:0.007785123039404758\n",
      "train loss:0.0008065068966930486\n",
      "train loss:0.005679296803653803\n",
      "train loss:0.0007301134483433623\n",
      "train loss:0.0030914590905775897\n",
      "train loss:0.002792977088560208\n",
      "train loss:0.005118222700781974\n",
      "train loss:0.004524469500358592\n",
      "train loss:0.004737957503609695\n",
      "train loss:0.04165484632722698\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.04283476010258447\n",
      "train loss:0.005042665890555898\n",
      "train loss:0.002349752993744449\n",
      "train loss:0.002461893053600983\n",
      "train loss:0.023646968719597757\n",
      "train loss:0.005373544637372075\n",
      "train loss:0.0037602244636976796\n",
      "train loss:0.007472709951111025\n",
      "train loss:0.0028803761044642264\n",
      "train loss:0.03269390500937143\n",
      "train loss:0.001646519075326771\n",
      "train loss:0.004175037922793008\n",
      "train loss:0.005391026762202408\n",
      "train loss:0.008111884007815042\n",
      "train loss:0.0076061872923716845\n",
      "train loss:0.007617702616289193\n",
      "train loss:0.0065271157638618574\n",
      "train loss:0.0006385739476652432\n",
      "train loss:0.04792756383480112\n",
      "train loss:0.005046972511175996\n",
      "train loss:0.0017724245712868278\n",
      "train loss:0.012723256925181671\n",
      "train loss:0.003642015923320644\n",
      "train loss:0.006475227990633021\n",
      "train loss:0.0028940076601305436\n",
      "train loss:0.0014004495913234503\n",
      "train loss:0.0036987324169263903\n",
      "train loss:0.0041634731725921385\n",
      "train loss:0.0021827112305822555\n",
      "train loss:0.0018469797082253808\n",
      "train loss:0.004265033024151929\n",
      "train loss:0.001679992594033088\n",
      "train loss:0.0019404251711106508\n",
      "train loss:0.015175226119888655\n",
      "train loss:0.00311232929963626\n",
      "train loss:0.012070600907133014\n",
      "train loss:0.00534880300365005\n",
      "train loss:0.0070747943803782685\n",
      "train loss:0.0011732452674856058\n",
      "train loss:0.005630521057717644\n",
      "train loss:0.001187627591387102\n",
      "train loss:0.014521213368785842\n",
      "train loss:0.009062129255607173\n",
      "train loss:0.001756242455731066\n",
      "train loss:0.009236647985795243\n",
      "train loss:0.018387721380348006\n",
      "train loss:0.00020242920292261928\n",
      "train loss:0.003868525544524627\n",
      "train loss:0.0030273628570799804\n",
      "train loss:0.0036477386856098265\n",
      "train loss:0.001426620920749526\n",
      "train loss:0.00693943750304592\n",
      "train loss:0.008732659092632324\n",
      "train loss:0.0030697882279122142\n",
      "train loss:0.003476662482127706\n",
      "train loss:0.0023990006276949634\n",
      "train loss:0.00201309287258185\n",
      "train loss:0.0003497169807703124\n",
      "train loss:0.00037108327866339767\n",
      "train loss:0.005517130147337763\n",
      "train loss:0.0050209383097340994\n",
      "train loss:0.0008324701616100276\n",
      "train loss:0.0012008789719024626\n",
      "train loss:0.004240300593561708\n",
      "train loss:0.029288384482877378\n",
      "train loss:0.002589861821803999\n",
      "train loss:0.0008428735118847898\n",
      "train loss:0.0005258296564683413\n",
      "train loss:0.0005959880258829456\n",
      "train loss:0.004516745401658254\n",
      "train loss:0.0011819167914458527\n",
      "train loss:0.0020844862940213953\n",
      "train loss:0.0047547762339061215\n",
      "train loss:0.006528725673703456\n",
      "train loss:0.00019107289380127635\n",
      "train loss:0.008533883958680894\n",
      "train loss:0.002122261893483479\n",
      "train loss:0.003911216597282934\n",
      "train loss:0.0038966369965216367\n",
      "train loss:0.0006310766986106564\n",
      "train loss:0.004992483023054227\n",
      "train loss:0.0022692634836137897\n",
      "train loss:0.004748922434292191\n",
      "train loss:0.01483922318887567\n",
      "train loss:0.0008737258906092051\n",
      "train loss:0.002006449050972275\n",
      "train loss:0.0016380534948326447\n",
      "train loss:0.0006189750906898814\n",
      "train loss:0.0008796056881516802\n",
      "train loss:0.0030050809435109255\n",
      "train loss:0.01585134751055779\n",
      "train loss:0.005714940825182005\n",
      "train loss:0.0043039823975585915\n",
      "train loss:0.006527254303741315\n",
      "train loss:0.0001899461216785005\n",
      "train loss:0.005234298261262751\n",
      "train loss:0.04515152221569738\n",
      "train loss:0.0005098678511838919\n",
      "train loss:0.0010167847030326453\n",
      "train loss:0.0020420802057825034\n",
      "train loss:0.0009970718432095562\n",
      "train loss:0.0008414305808077943\n",
      "train loss:0.0007864903223849468\n",
      "train loss:0.0029767765921319606\n",
      "train loss:0.004446781068867683\n",
      "train loss:0.0024863383500660376\n",
      "train loss:0.00083844423785178\n",
      "train loss:0.007340837020199645\n",
      "train loss:0.0026955276920780998\n",
      "train loss:0.0002176274039194217\n",
      "train loss:0.0012890978423737934\n",
      "train loss:0.02548283908092779\n",
      "train loss:0.00349169842698837\n",
      "train loss:0.004708723973291651\n",
      "train loss:0.0002379722698041509\n",
      "train loss:0.002548394190082332\n",
      "train loss:0.0005422193517510308\n",
      "train loss:0.006609522671283048\n",
      "train loss:0.007198291127051663\n",
      "train loss:0.005039981198713378\n",
      "train loss:0.0025194812422616574\n",
      "train loss:0.003069967499078775\n",
      "train loss:0.003542563699418636\n",
      "train loss:0.003690949453337623\n",
      "train loss:0.0026557942470362937\n",
      "train loss:0.0008257319656707732\n",
      "train loss:0.032688692530865496\n",
      "train loss:0.0017186847717664314\n",
      "train loss:0.001816243545611404\n",
      "train loss:0.012585671634051268\n",
      "train loss:0.005567554570334331\n",
      "train loss:0.006701963700430625\n",
      "train loss:0.0035970388360953847\n",
      "train loss:0.0022937868844800477\n",
      "train loss:0.003897094657334952\n",
      "train loss:0.0009134704183666763\n",
      "train loss:0.003115545510887177\n",
      "train loss:0.0010663880589202694\n",
      "train loss:0.0018215799796095916\n",
      "train loss:0.0022632419422570224\n",
      "train loss:0.007764127968761476\n",
      "train loss:0.0009557542402266753\n",
      "train loss:0.0017051976985306742\n",
      "train loss:0.0019436943548871482\n",
      "train loss:0.004725161763391943\n",
      "train loss:0.00229375324330003\n",
      "train loss:0.0012090689445938957\n",
      "train loss:0.004615077364786531\n",
      "train loss:0.001968946063866499\n",
      "train loss:0.0008896574641404488\n",
      "train loss:0.002573003918610689\n",
      "train loss:0.0036676309223397097\n",
      "train loss:0.006022036166720691\n",
      "train loss:0.011381693723703443\n",
      "train loss:0.022200538958983645\n",
      "train loss:0.0007564781116197941\n",
      "train loss:0.0011392228794449698\n",
      "train loss:0.0023937570927630505\n",
      "train loss:0.0009069621613328913\n",
      "train loss:0.001015883787484992\n",
      "train loss:0.0007976816677090524\n",
      "train loss:0.0014307591872618841\n",
      "train loss:0.00043554049726239456\n",
      "train loss:0.0008842471311322596\n",
      "train loss:0.0015791068946118569\n",
      "train loss:0.007286503554836421\n",
      "train loss:0.0002079746305321765\n",
      "train loss:0.0013558033106542114\n",
      "train loss:0.028046807959948995\n",
      "train loss:0.0011476118955209445\n",
      "train loss:0.03382215027597801\n",
      "train loss:0.0022542367351560027\n",
      "train loss:0.00866009201231059\n",
      "train loss:0.0003332405829842898\n",
      "train loss:0.0005335900294011886\n",
      "train loss:0.005012490838526277\n",
      "train loss:0.002356779558491599\n",
      "train loss:0.007625902370511834\n",
      "train loss:0.0029027105109322277\n",
      "train loss:0.004405630315798468\n",
      "train loss:0.004661839313208593\n",
      "train loss:0.000793621419275851\n",
      "train loss:0.0032340807947299033\n",
      "train loss:0.0020282118037266415\n",
      "train loss:0.005911167582538021\n",
      "train loss:0.0025791904437851886\n",
      "train loss:0.0015888850993176567\n",
      "train loss:0.003234677301210395\n",
      "train loss:0.001308589275393114\n",
      "train loss:0.007044440009046436\n",
      "train loss:0.0028285957039539994\n",
      "train loss:8.565145794438587e-05\n",
      "train loss:0.0016179241375026796\n",
      "train loss:0.001555861099474139\n",
      "train loss:0.0003662485512437904\n",
      "train loss:0.0011709696083362254\n",
      "=== epoch:13, train acc:0.998, test acc:0.986 ===\n",
      "train loss:0.001139931431546421\n",
      "train loss:0.005481698857082806\n",
      "train loss:0.001553806727933862\n",
      "train loss:0.002401154321837993\n",
      "train loss:0.0003417327841956115\n",
      "train loss:0.0005505235140591207\n",
      "train loss:0.0006278981265995813\n",
      "train loss:0.0019205763416336188\n",
      "train loss:0.0027077483547863664\n",
      "train loss:0.0005671080674127602\n",
      "train loss:0.0009390638735173139\n",
      "train loss:0.00047217333583592563\n",
      "train loss:0.0007790309926127653\n",
      "train loss:0.016852359017315553\n",
      "train loss:0.00020463361258547298\n",
      "train loss:0.0014595328712891445\n",
      "train loss:0.0003764171615726769\n",
      "train loss:0.0016398028698326988\n",
      "train loss:0.009616115558054625\n",
      "train loss:0.0008051717478844731\n",
      "train loss:0.0015258412783756784\n",
      "train loss:0.00015765165726550106\n",
      "train loss:0.0005761432424522333\n",
      "train loss:0.00024674844050242276\n",
      "train loss:0.000497212974937639\n",
      "train loss:0.0018284513494956581\n",
      "train loss:0.00317394260503267\n",
      "train loss:0.01451986193107402\n",
      "train loss:0.0020908668789099585\n",
      "train loss:0.0008978819920670419\n",
      "train loss:0.001374760845041476\n",
      "train loss:0.004374927460834611\n",
      "train loss:0.0009060776388857177\n",
      "train loss:0.010696276525701692\n",
      "train loss:0.003371534094855509\n",
      "train loss:0.0031409420328340886\n",
      "train loss:0.00309560730684093\n",
      "train loss:0.0014693977247100375\n",
      "train loss:0.010352606187333822\n",
      "train loss:0.000843435305402548\n",
      "train loss:0.0009725394124344529\n",
      "train loss:0.0023090924397776856\n",
      "train loss:0.021046256086791126\n",
      "train loss:0.015695765505940828\n",
      "train loss:0.0002485994061198392\n",
      "train loss:0.002006220883536659\n",
      "train loss:0.004989482433212306\n",
      "train loss:0.0047275346483171285\n",
      "train loss:0.001933085740558784\n",
      "train loss:0.02764178951366944\n",
      "train loss:0.0034798970422733207\n",
      "train loss:0.000892324458624936\n",
      "train loss:0.00024935471002077923\n",
      "train loss:0.006629261527739335\n",
      "train loss:0.006083769749213229\n",
      "train loss:0.00451430547811572\n",
      "train loss:0.0014666574135588223\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.002482822224431249\n",
      "train loss:0.0018426880294087774\n",
      "train loss:0.0004831694813863057\n",
      "train loss:0.0014307925388332685\n",
      "train loss:0.003974855291955412\n",
      "train loss:0.014317818798399383\n",
      "train loss:0.011585527177495425\n",
      "train loss:0.006105150757921543\n",
      "train loss:0.0012610916095761634\n",
      "train loss:0.004144585586893721\n",
      "train loss:0.001271269725777077\n",
      "train loss:0.0023912018501745895\n",
      "train loss:0.004544662219326103\n",
      "train loss:0.026353259619713666\n",
      "train loss:0.0008667981074898312\n",
      "train loss:0.0008693521890713709\n",
      "train loss:0.0005350959271800111\n",
      "train loss:0.0012946272111456082\n",
      "train loss:0.006914366329506293\n",
      "train loss:0.005206534806760626\n",
      "train loss:0.0023912813983914694\n",
      "train loss:0.0055543750184218\n",
      "train loss:0.004545258229888112\n",
      "train loss:0.007194403616286902\n",
      "train loss:0.0013184328949649752\n",
      "train loss:0.0037725787970822005\n",
      "train loss:0.004116775812003947\n",
      "train loss:0.005765054784852937\n",
      "train loss:0.0010388507444586339\n",
      "train loss:0.0005758813859170919\n",
      "train loss:0.000705972715237816\n",
      "train loss:0.0025691706471548843\n",
      "train loss:0.0016403178753576727\n",
      "train loss:0.003775395667878501\n",
      "train loss:0.007898760068938509\n",
      "train loss:0.0006967368716071907\n",
      "train loss:0.0004752771902647478\n",
      "train loss:0.0120412960825348\n",
      "train loss:0.006558360386813412\n",
      "train loss:0.005650644243105908\n",
      "train loss:0.0009990512857514767\n",
      "train loss:0.0007926472770511488\n",
      "train loss:0.007975576730075228\n",
      "train loss:0.0005295005156532593\n",
      "train loss:0.018541496961033993\n",
      "train loss:0.03706890765744355\n",
      "train loss:0.0016077381359027162\n",
      "train loss:0.0033292838130311387\n",
      "train loss:0.014107756371081167\n",
      "train loss:0.0014192348869907906\n",
      "train loss:0.0009316130686888567\n",
      "train loss:0.005260673698736545\n",
      "train loss:0.04175239970010795\n",
      "train loss:0.0051551418216107285\n",
      "train loss:0.004718434140292474\n",
      "train loss:0.0014108310139126306\n",
      "train loss:0.0034375892710021543\n",
      "train loss:0.007465837816063792\n",
      "train loss:0.0050133273766566535\n",
      "train loss:0.0018358352088937418\n",
      "train loss:0.0064728364941732865\n",
      "train loss:0.0035500990983632994\n",
      "train loss:0.029050195713139236\n",
      "train loss:0.006038896678777169\n",
      "train loss:0.0009408941013123445\n",
      "train loss:0.0032666266307857135\n",
      "train loss:0.025685652324155556\n",
      "train loss:0.004115863567741417\n",
      "train loss:0.000600957589052274\n",
      "train loss:0.03847593689284795\n",
      "train loss:0.006895595381968492\n",
      "train loss:0.0030002701208496577\n",
      "train loss:0.0010986314363898805\n",
      "train loss:0.0044317836731922735\n",
      "train loss:0.003997294128528244\n",
      "train loss:0.002741880921295756\n",
      "train loss:0.0025608653274023525\n",
      "train loss:0.006311885681378361\n",
      "train loss:0.010420627219136551\n",
      "train loss:0.0005595676875312207\n",
      "train loss:0.0006240580622978244\n",
      "train loss:0.0002018497201291951\n",
      "train loss:0.0020924359862320692\n",
      "train loss:0.00028199340258725853\n",
      "train loss:0.000866134741156887\n",
      "train loss:0.008459817201126341\n",
      "train loss:0.002325806114614451\n",
      "train loss:0.010220465956028406\n",
      "train loss:0.003282098573653548\n",
      "train loss:0.017856413411698725\n",
      "train loss:0.0020120914999547266\n",
      "train loss:0.001227908727968655\n",
      "train loss:0.0022869894735355824\n",
      "train loss:0.0014066474984912585\n",
      "train loss:0.006820882786130853\n",
      "train loss:0.005595013495626051\n",
      "train loss:0.004875875283612119\n",
      "train loss:0.0033275049619446956\n",
      "train loss:0.009004725486750591\n",
      "train loss:0.001819402853669914\n",
      "train loss:0.0011691566545984754\n",
      "train loss:0.018743665757185307\n",
      "train loss:0.0028458706897156456\n",
      "train loss:0.0174427951516666\n",
      "train loss:0.0038274906051890068\n",
      "train loss:0.0006609937746371025\n",
      "train loss:0.0050403071970759805\n",
      "train loss:0.0012391676552169176\n",
      "train loss:0.014204116713993997\n",
      "train loss:0.001057348498847127\n",
      "train loss:0.002387904437098286\n",
      "train loss:0.018196536466057275\n",
      "train loss:0.005205854880260236\n",
      "train loss:0.00045163808183688555\n",
      "train loss:0.0017926265395179907\n",
      "train loss:0.0054543460364820506\n",
      "train loss:0.010416537875281136\n",
      "train loss:0.0012897966511254944\n",
      "train loss:0.0049222014323016434\n",
      "train loss:0.16104865674749622\n",
      "train loss:0.0065014042412731635\n",
      "train loss:0.00677588841871208\n",
      "train loss:0.0026605874593105994\n",
      "train loss:0.005303997593845834\n",
      "train loss:0.006985047723281398\n",
      "train loss:0.00129565624207603\n",
      "train loss:0.0038265174277845653\n",
      "train loss:0.0020943141633137526\n",
      "train loss:0.0006681453186422485\n",
      "train loss:0.009027740512873483\n",
      "train loss:0.0009968366420792386\n",
      "train loss:0.0018331601723800038\n",
      "train loss:0.0015252517026546645\n",
      "train loss:0.0019460060634109199\n",
      "train loss:0.0032378522889631787\n",
      "train loss:0.002813183803079203\n",
      "train loss:0.0010103227161402271\n",
      "train loss:0.0013016092249325132\n",
      "train loss:0.0007782242136289682\n",
      "train loss:0.003241542026107672\n",
      "train loss:0.0067683042291397134\n",
      "train loss:0.0016475115803249035\n",
      "train loss:0.0022230422086658296\n",
      "train loss:0.0032012418220272957\n",
      "train loss:0.0038899224168079233\n",
      "train loss:0.005733686605398958\n",
      "train loss:0.0020854029829964586\n",
      "train loss:0.0009402571742918977\n",
      "train loss:0.02608403863756479\n",
      "train loss:0.0016454157093923527\n",
      "train loss:0.012890645193196519\n",
      "train loss:0.0007623387040285653\n",
      "train loss:0.0013590233464589843\n",
      "train loss:0.0007013485946362136\n",
      "train loss:0.0017115340002240875\n",
      "train loss:0.00524095371842013\n",
      "train loss:0.004192308616013688\n",
      "train loss:0.0005833615618943657\n",
      "train loss:0.002979208628099485\n",
      "train loss:0.0003798888162068731\n",
      "train loss:0.007035377089132557\n",
      "train loss:0.0036253382095789376\n",
      "train loss:0.00036895214688362725\n",
      "train loss:0.006123536297390811\n",
      "train loss:0.0011755734139942396\n",
      "train loss:0.001764576530150357\n",
      "train loss:0.027768700726750053\n",
      "train loss:0.00389339249020464\n",
      "train loss:0.0023393655404709466\n",
      "train loss:0.008895467585640476\n",
      "train loss:0.0011204105238210344\n",
      "train loss:0.003729476629794934\n",
      "train loss:0.0008494190411641831\n",
      "train loss:0.002723932712034015\n",
      "train loss:0.026810895298594803\n",
      "train loss:0.0069642631361296935\n",
      "train loss:0.003691670279272473\n",
      "train loss:0.0003655304519563093\n",
      "train loss:0.0011108907748592933\n",
      "train loss:0.0033918258832751763\n",
      "train loss:0.007325816615606359\n",
      "train loss:0.005075657516513783\n",
      "train loss:0.0011559578391529771\n",
      "train loss:0.0021786356974141446\n",
      "train loss:0.0021374207333542776\n",
      "train loss:0.0011630051091216641\n",
      "train loss:0.0021892046231323627\n",
      "train loss:0.0035583711619868856\n",
      "train loss:0.0004537519709936856\n",
      "train loss:0.0008805128259144943\n",
      "train loss:0.0010758083200498568\n",
      "train loss:0.008127178274324704\n",
      "train loss:0.0007889186146187141\n",
      "train loss:0.0028768843340731417\n",
      "train loss:0.00295516038892943\n",
      "train loss:0.003796725541182969\n",
      "train loss:0.0015685458077868111\n",
      "train loss:0.0018919300154693936\n",
      "train loss:0.0028292525226807585\n",
      "train loss:0.004229494126034417\n",
      "train loss:0.0015966123873411475\n",
      "train loss:0.0015712037084279137\n",
      "train loss:0.0003632459216288305\n",
      "train loss:0.014084330406893646\n",
      "train loss:0.009740478447866163\n",
      "train loss:0.004930972447656633\n",
      "train loss:0.001087394540039202\n",
      "train loss:0.0010055782485169503\n",
      "train loss:0.0019168514909006188\n",
      "train loss:0.0028134632653293024\n",
      "train loss:0.0031311247679972464\n",
      "train loss:0.022301447530392902\n",
      "train loss:0.00874789874253127\n",
      "train loss:0.0002629163397164043\n",
      "train loss:6.345625336292367e-05\n",
      "train loss:0.013352170583811026\n",
      "train loss:0.0049556767947406865\n",
      "train loss:0.0022123797182642953\n",
      "train loss:0.0036240423229768693\n",
      "train loss:0.002875586340264332\n",
      "train loss:0.025704157664780992\n",
      "train loss:0.0007852512661608688\n",
      "train loss:0.0025890941310262173\n",
      "train loss:0.0028090946061971734\n",
      "train loss:0.0014252455994414447\n",
      "train loss:0.005235641333723856\n",
      "train loss:0.0011218328628767055\n",
      "train loss:0.010280359164042442\n",
      "train loss:0.0006688137507032182\n",
      "train loss:0.02298964344471848\n",
      "train loss:0.001683325021882397\n",
      "train loss:0.011045365874096873\n",
      "train loss:0.0037312485124496295\n",
      "train loss:0.001888664373075066\n",
      "train loss:0.0009208942528026277\n",
      "train loss:0.0019694207802387776\n",
      "train loss:0.0033767385945393234\n",
      "train loss:0.005259839033604631\n",
      "train loss:0.0009481178314423058\n",
      "train loss:0.005850069190312488\n",
      "train loss:0.0014965493976591086\n",
      "train loss:0.00047977537439143516\n",
      "train loss:0.0009670288944540732\n",
      "train loss:0.0003229063186774867\n",
      "train loss:0.0006834557582706137\n",
      "train loss:0.00025158884243448856\n",
      "train loss:0.0006044315041500932\n",
      "train loss:0.003105646596906738\n",
      "train loss:0.0018021629993118316\n",
      "train loss:0.009751229604549294\n",
      "train loss:0.0047851548896692\n",
      "train loss:0.02692081907507974\n",
      "train loss:0.0017616878778436034\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.005172119843483821\n",
      "train loss:0.002960334034163094\n",
      "train loss:0.0004302393943433811\n",
      "train loss:0.01118060202422874\n",
      "train loss:0.0036025665550401364\n",
      "train loss:0.0011607574911050604\n",
      "train loss:0.002437672836040543\n",
      "train loss:0.011404139996406406\n",
      "train loss:0.0003253524963756408\n",
      "train loss:0.009706928577142938\n",
      "train loss:0.004490724092169692\n",
      "train loss:0.0018045602528446272\n",
      "train loss:0.0036400640126186003\n",
      "train loss:0.0014829767534849155\n",
      "train loss:0.014649503896972577\n",
      "train loss:0.015297746411822202\n",
      "train loss:0.003500022496763535\n",
      "train loss:0.0016897836716977263\n",
      "train loss:0.0032800960589377316\n",
      "train loss:0.0020282865030119045\n",
      "train loss:0.0018675760253131653\n",
      "train loss:0.03673536342794876\n",
      "train loss:0.001705141318145123\n",
      "train loss:0.0012130176514959603\n",
      "train loss:0.007180254053951643\n",
      "train loss:0.0014588466301506753\n",
      "train loss:0.004318956655434521\n",
      "train loss:0.007156522862934664\n",
      "train loss:0.0018377392417346131\n",
      "train loss:0.0024214428542554236\n",
      "train loss:0.0031639189699800944\n",
      "train loss:0.006624260984785781\n",
      "train loss:0.002555080288102798\n",
      "train loss:0.010831104371451255\n",
      "train loss:0.0021897394631900926\n",
      "train loss:0.0016686418204328072\n",
      "train loss:0.00028367397284608886\n",
      "train loss:0.011216298912061386\n",
      "train loss:0.0029328503142467244\n",
      "train loss:0.0016124378801685507\n",
      "train loss:0.000602827985045744\n",
      "train loss:0.0026384816915679997\n",
      "train loss:0.009637260061933207\n",
      "train loss:0.001534907113161128\n",
      "train loss:0.006143439371865766\n",
      "train loss:0.0009113672664542393\n",
      "train loss:0.0010381625943671389\n",
      "train loss:0.010396697299307225\n",
      "train loss:0.00779037249820126\n",
      "train loss:0.00093801032224121\n",
      "train loss:0.00045754413305266003\n",
      "train loss:0.008077618968035827\n",
      "train loss:0.003012943929088825\n",
      "train loss:0.001699218443619998\n",
      "train loss:0.007813223029089713\n",
      "train loss:0.0013436531963660404\n",
      "train loss:0.0020081454839790047\n",
      "train loss:0.004970909610271819\n",
      "train loss:0.0020277962357017013\n",
      "train loss:0.0005531914353411972\n",
      "train loss:0.0021490952444893963\n",
      "train loss:0.0010171308459998776\n",
      "train loss:0.00727126012213487\n",
      "train loss:0.00022762641419999037\n",
      "train loss:0.00011069517106051708\n",
      "train loss:0.0020973881674884063\n",
      "train loss:0.00406908781755775\n",
      "train loss:0.00017632961799353647\n",
      "train loss:0.0039409140680467915\n",
      "train loss:0.005308208262568582\n",
      "train loss:0.00154106009747365\n",
      "train loss:0.0021818414405650986\n",
      "train loss:0.005032579455790029\n",
      "train loss:0.007063711553870261\n",
      "train loss:0.0010680187960367313\n",
      "train loss:0.0008034569910894758\n",
      "train loss:0.00060012093109648\n",
      "train loss:0.00021435549217453719\n",
      "train loss:0.006183788846382001\n",
      "train loss:0.002161255161291296\n",
      "train loss:0.000502145407460235\n",
      "train loss:0.00609691624032481\n",
      "train loss:0.0006418890144056762\n",
      "train loss:0.0015784745257556554\n",
      "train loss:0.0036753619293012863\n",
      "train loss:0.0007011542477070605\n",
      "train loss:0.00016649381113070815\n",
      "train loss:0.016230549491078987\n",
      "train loss:0.0014983925932448453\n",
      "train loss:0.022171086214572294\n",
      "train loss:0.0009157159609005301\n",
      "train loss:0.00556593931892506\n",
      "train loss:0.00011733355300070465\n",
      "train loss:0.004016510711774563\n",
      "train loss:0.004292282252782481\n",
      "train loss:0.0015235477926316876\n",
      "train loss:0.004464398471485053\n",
      "train loss:0.003079595061308055\n",
      "train loss:0.007089892024038393\n",
      "train loss:0.00371642521907977\n",
      "train loss:0.023423719624042327\n",
      "train loss:0.0013475602564152834\n",
      "train loss:0.0009155091432157096\n",
      "train loss:0.003472732865017102\n",
      "train loss:0.003945333586964515\n",
      "train loss:0.0008300889003399505\n",
      "train loss:0.0021156142200133483\n",
      "train loss:0.005893523871767038\n",
      "train loss:0.007204839946873318\n",
      "train loss:0.0018927750955438367\n",
      "train loss:0.0025551863851428318\n",
      "train loss:0.0028905065515141574\n",
      "train loss:0.02033906461248245\n",
      "train loss:0.0017524704620673554\n",
      "train loss:0.0002914842224001431\n",
      "train loss:0.003977376670392043\n",
      "train loss:0.006305030223648411\n",
      "train loss:0.005170648663163417\n",
      "train loss:0.005198965825006644\n",
      "train loss:0.006336096440732139\n",
      "train loss:0.003445132975302196\n",
      "train loss:0.003145748562329847\n",
      "train loss:0.0006067874308151215\n",
      "train loss:0.0012338004285346895\n",
      "train loss:0.002537774887658566\n",
      "train loss:0.0032298233640647394\n",
      "train loss:0.0002609951292468061\n",
      "train loss:0.0003722282248225209\n",
      "train loss:0.0019950263227314358\n",
      "train loss:0.00236194834216873\n",
      "train loss:0.0025055323339339074\n",
      "train loss:0.0012881375207937373\n",
      "train loss:0.012426639709985891\n",
      "train loss:0.0026918618727746683\n",
      "train loss:0.0006835839118078725\n",
      "train loss:0.003244005033703689\n",
      "train loss:0.0026904955838768702\n",
      "train loss:0.03826366154657843\n",
      "train loss:0.0006706065675727488\n",
      "train loss:0.02051740852811197\n",
      "train loss:0.0007748294957079985\n",
      "train loss:0.014845986277918109\n",
      "train loss:0.007898350855860176\n",
      "train loss:0.0019351950092116718\n",
      "train loss:0.0017441349493781042\n",
      "train loss:0.009280793824627273\n",
      "train loss:0.05345680648251649\n",
      "train loss:0.003169488316149807\n",
      "train loss:0.0010202842913020168\n",
      "train loss:0.0011197300876855073\n",
      "train loss:0.0009502336990809759\n",
      "train loss:0.0032815435708738578\n",
      "train loss:0.003909274069675342\n",
      "train loss:0.0036728780656145005\n",
      "train loss:0.00583322019665215\n",
      "train loss:0.005055933018674328\n",
      "train loss:0.005793117448193576\n",
      "train loss:0.0008273538704413078\n",
      "train loss:0.00046896175145803235\n",
      "train loss:0.0018479228635203482\n",
      "train loss:0.00031351541794383963\n",
      "train loss:0.0038896553408235535\n",
      "train loss:0.033462509091889296\n",
      "train loss:0.0007185992154045723\n",
      "train loss:0.00022922123086727527\n",
      "train loss:0.0012130294273079993\n",
      "train loss:0.0019506991546760658\n",
      "train loss:0.010497860062026979\n",
      "train loss:0.003324307979494422\n",
      "train loss:0.003605427087513095\n",
      "train loss:0.009999316743655546\n",
      "train loss:0.007445829998840419\n",
      "train loss:0.0013150620131285034\n",
      "train loss:0.0014337501921213133\n",
      "train loss:0.0021146552154150465\n",
      "train loss:0.00192718322140766\n",
      "train loss:0.0010496114505287276\n",
      "train loss:0.00023585985678602824\n",
      "train loss:0.0022689015139868733\n",
      "train loss:0.019823092720846903\n",
      "train loss:0.0006726486846552551\n",
      "train loss:0.0003371956830910555\n",
      "train loss:0.00039983762520503434\n",
      "train loss:0.009192570672573093\n",
      "train loss:0.009736816057463989\n",
      "train loss:0.0006617914953727842\n",
      "train loss:0.00020881933837248474\n",
      "train loss:0.0028895985265216377\n",
      "train loss:0.00044596548388689436\n",
      "train loss:0.0028274941718282485\n",
      "train loss:0.0044651231249376805\n",
      "train loss:0.001209998532046367\n",
      "train loss:0.0007110630807208925\n",
      "train loss:0.0017536542205289398\n",
      "train loss:0.0014280840747126792\n",
      "train loss:0.020166619442787255\n",
      "train loss:0.0031886525108103915\n",
      "train loss:0.006599229380651451\n",
      "train loss:0.0002432957467331915\n",
      "train loss:0.004493372767527241\n",
      "train loss:0.0024654328599294237\n",
      "train loss:0.006005557063484818\n",
      "train loss:0.0010717286151948112\n",
      "train loss:0.0009025777350594263\n",
      "train loss:0.0004844377142372566\n",
      "train loss:0.005627574808314947\n",
      "train loss:0.012140729942243703\n",
      "train loss:0.005523412930465712\n",
      "train loss:0.0002866229641461421\n",
      "train loss:0.00041383801930743107\n",
      "train loss:0.004998152194486999\n",
      "train loss:0.006798874063021396\n",
      "train loss:0.0027149030924489576\n",
      "train loss:0.0029437230205851665\n",
      "train loss:0.00046632813032227924\n",
      "train loss:0.00031264111267862013\n",
      "train loss:0.0012840668248915426\n",
      "train loss:0.0006317785874997658\n",
      "train loss:0.0014714581607821334\n",
      "train loss:0.005241346665005257\n",
      "train loss:0.0010638461584777542\n",
      "train loss:0.0007791196925409556\n",
      "train loss:0.0009323503968059481\n",
      "train loss:0.0018437216743636574\n",
      "train loss:0.001834968391199166\n",
      "train loss:0.003389853203649349\n",
      "train loss:0.020884615313092318\n",
      "train loss:0.000999329503252294\n",
      "train loss:0.0010032868895350092\n",
      "train loss:0.008261673949188624\n",
      "train loss:0.002418381388552464\n",
      "train loss:0.011519570434562042\n",
      "train loss:0.0014064476999947856\n",
      "train loss:0.006288801391882065\n",
      "train loss:0.0018539625253760309\n",
      "train loss:0.015074812182706928\n",
      "train loss:0.004209833208191158\n",
      "train loss:0.0007719320844399715\n",
      "train loss:0.012239398146671097\n",
      "train loss:0.002845141348797893\n",
      "train loss:0.002865388988752078\n",
      "train loss:0.0013402535234196596\n",
      "train loss:0.001042092937284961\n",
      "train loss:0.0015673015553903965\n",
      "train loss:0.0013483651193282715\n",
      "train loss:0.03275223136608581\n",
      "train loss:0.0027476165838889737\n",
      "train loss:0.009263726854126195\n",
      "train loss:0.0016458726279457965\n",
      "train loss:0.001376888987796394\n",
      "train loss:0.00689050500784242\n",
      "train loss:0.0010564318961737522\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.0024619008859617943\n",
      "train loss:0.0044031710989760105\n",
      "train loss:0.0009645375627437716\n",
      "train loss:0.008143517784517405\n",
      "train loss:0.003715708271316796\n",
      "train loss:0.0005802108104499626\n",
      "train loss:0.0005510660166440242\n",
      "train loss:0.008184863029135877\n",
      "train loss:0.002709192207775049\n",
      "train loss:0.0005741768355514737\n",
      "train loss:0.001023554383350541\n",
      "train loss:0.008459504909290722\n",
      "train loss:0.004778642242248427\n",
      "train loss:0.0036612471378594125\n",
      "train loss:0.0038366063977193334\n",
      "train loss:0.002180300370316321\n",
      "train loss:0.0007450775074089592\n",
      "train loss:0.004194570057683913\n",
      "train loss:0.0006937921172865883\n",
      "train loss:0.0013829064205002671\n",
      "train loss:0.0006885418068014206\n",
      "train loss:0.0006620596657882456\n",
      "train loss:0.009546385863016845\n",
      "train loss:0.0032652982538182405\n",
      "train loss:0.0062324503944407\n",
      "train loss:0.0016139461249738663\n",
      "train loss:0.0007846657530917209\n",
      "train loss:0.0007153754410930236\n",
      "train loss:0.0016347334807566925\n",
      "train loss:0.007257919018517823\n",
      "train loss:0.0010472970266908587\n",
      "train loss:0.0002369601080285874\n",
      "train loss:0.002730762010698836\n",
      "train loss:0.00203233658749108\n",
      "train loss:0.004252244381510676\n",
      "train loss:0.016517689390934533\n",
      "train loss:0.00365536942720633\n",
      "train loss:0.00032644658639990025\n",
      "=== epoch:14, train acc:0.997, test acc:0.988 ===\n",
      "train loss:0.003005975002340027\n",
      "train loss:0.005306472605933107\n",
      "train loss:0.0028093198292537926\n",
      "train loss:0.0018324799668958875\n",
      "train loss:0.005863418599268001\n",
      "train loss:0.002641607100083791\n",
      "train loss:0.00048479428282064704\n",
      "train loss:0.0037080942709647874\n",
      "train loss:0.003985788816235206\n",
      "train loss:0.015720446298074925\n",
      "train loss:0.008835453362965026\n",
      "train loss:0.0019555698227687736\n",
      "train loss:0.0066524069145988485\n",
      "train loss:0.00035152943703062415\n",
      "train loss:0.0018204023259079558\n",
      "train loss:0.00018319172571403889\n",
      "train loss:0.0016432864103218792\n",
      "train loss:0.0011294149031178043\n",
      "train loss:0.0037519614972017865\n",
      "train loss:0.000923739477016431\n",
      "train loss:0.00699179728257927\n",
      "train loss:0.0008519032105459137\n",
      "train loss:0.0030365717383872047\n",
      "train loss:0.006522900297859024\n",
      "train loss:0.003025358380414002\n",
      "train loss:0.00053628052601797\n",
      "train loss:0.0022543806332375412\n",
      "train loss:0.00027237720091668403\n",
      "train loss:0.009423699825348535\n",
      "train loss:0.0038078022100616464\n",
      "train loss:0.005211015909250633\n",
      "train loss:0.00690687714898837\n",
      "train loss:0.0019378239393385713\n",
      "train loss:0.001529070619086006\n",
      "train loss:0.0029322177677705372\n",
      "train loss:0.0013270508767352363\n",
      "train loss:0.002490540035963185\n",
      "train loss:0.004171777224343891\n",
      "train loss:0.0007420815349605114\n",
      "train loss:0.0006359493404001549\n",
      "train loss:0.00422292544464339\n",
      "train loss:0.0018485979907486674\n",
      "train loss:0.00037882979121402595\n",
      "train loss:0.00034797791538593775\n",
      "train loss:0.005942042030051788\n",
      "train loss:0.0019399278979660708\n",
      "train loss:0.0014930670620184894\n",
      "train loss:0.0025151129981051336\n",
      "train loss:0.0009126906330410805\n",
      "train loss:0.0006857321956377579\n",
      "train loss:0.0021437573052720295\n",
      "train loss:0.07420312735128264\n",
      "train loss:0.0020359231095255846\n",
      "train loss:0.0017929236465134481\n",
      "train loss:0.0023842961492472293\n",
      "train loss:0.0017849087574997877\n",
      "train loss:0.0020465272438788765\n",
      "train loss:0.0008019195818977837\n",
      "train loss:0.0019725528228379577\n",
      "train loss:0.0030065820022308985\n",
      "train loss:0.003162267249282153\n",
      "train loss:0.015137685519020809\n",
      "train loss:0.0007718377104188294\n",
      "train loss:0.004658038792635178\n",
      "train loss:0.0008202779973359259\n",
      "train loss:0.0017562730146496327\n",
      "train loss:0.0036535799831636444\n",
      "train loss:0.004766399914255325\n",
      "train loss:0.004292541903181978\n",
      "train loss:0.0028769210883420803\n",
      "train loss:0.0006549162176693367\n",
      "train loss:0.001044164746250419\n",
      "train loss:0.006210759627923448\n",
      "train loss:0.02656329628133211\n",
      "train loss:0.0024499476131831337\n",
      "train loss:0.007983690137461974\n",
      "train loss:0.0009885796655260959\n",
      "train loss:0.008750281247559909\n",
      "train loss:0.0015107747269361088\n",
      "train loss:0.0011475802508254982\n",
      "train loss:0.005577362718691221\n",
      "train loss:0.0015669101565463233\n",
      "train loss:0.004262757704691538\n",
      "train loss:0.0013061507094027597\n",
      "train loss:0.0021489991523860066\n",
      "train loss:0.012903470754222697\n",
      "train loss:0.006178055881954538\n",
      "train loss:0.004921316612744755\n",
      "train loss:0.00026919362287790944\n",
      "train loss:0.0010396277120944752\n",
      "train loss:0.01746882163357204\n",
      "train loss:0.005851086144076713\n",
      "train loss:0.0013102824495982229\n",
      "train loss:0.0001685473474020496\n",
      "train loss:0.000254730473207508\n",
      "train loss:0.002383103094001044\n",
      "train loss:0.004532710870516268\n",
      "train loss:0.004724641501020063\n",
      "train loss:0.002040229635991768\n",
      "train loss:0.0008946186307690143\n",
      "train loss:0.004309449591528175\n",
      "train loss:0.00122004817521508\n",
      "train loss:0.018465827382394735\n",
      "train loss:0.0014923063618322878\n",
      "train loss:0.0016128382540647054\n",
      "train loss:0.0016641670856607606\n",
      "train loss:0.0029399669973033805\n",
      "train loss:0.0022352723715528934\n",
      "train loss:0.0003788732304550863\n",
      "train loss:0.0007001075592620028\n",
      "train loss:0.009462230352711343\n",
      "train loss:0.001877074359969611\n",
      "train loss:0.000852815225639779\n",
      "train loss:0.004084472896723427\n",
      "train loss:0.005033508664926404\n",
      "train loss:0.0037678933174374258\n",
      "train loss:0.005184045775430925\n",
      "train loss:0.0006574115639097776\n",
      "train loss:0.0029249670191945987\n",
      "train loss:0.001637885473903016\n",
      "train loss:0.011768393490665538\n",
      "train loss:0.014750439509168094\n",
      "train loss:0.004909233093911171\n",
      "train loss:0.002865140278081433\n",
      "train loss:0.0009182810921310427\n",
      "train loss:0.0004771390030200296\n",
      "train loss:0.021955242514989193\n",
      "train loss:0.0017770140232461463\n",
      "train loss:0.00493977272489923\n",
      "train loss:0.0008211363705347825\n",
      "train loss:0.000996717877053858\n",
      "train loss:0.003912002501311626\n",
      "train loss:0.0038383565752274865\n",
      "train loss:0.005971390479165366\n",
      "train loss:0.001166641304512831\n",
      "train loss:0.0062457840593319325\n",
      "train loss:0.0011637835269571418\n",
      "train loss:0.0022733425879515505\n",
      "train loss:0.005417701845459049\n",
      "train loss:0.005998799429569691\n",
      "train loss:0.0013540532254826066\n",
      "train loss:0.00309317078614732\n",
      "train loss:0.0019407223893746523\n",
      "train loss:0.007636125451617514\n",
      "train loss:0.003276258198238426\n",
      "train loss:0.000643550258169945\n",
      "train loss:0.0003559201669983372\n",
      "train loss:0.0018768744939071935\n",
      "train loss:0.001241077655073763\n",
      "train loss:0.0010660020423256045\n",
      "train loss:0.003963574488610746\n",
      "train loss:0.0002311147416826238\n",
      "train loss:0.007166902626304223\n",
      "train loss:0.001457841813246074\n",
      "train loss:0.00047372818495405346\n",
      "train loss:0.0007714658078084104\n",
      "train loss:0.0056496513417143845\n",
      "train loss:0.0026680130783102098\n",
      "train loss:0.01014507749002858\n",
      "train loss:0.0013602011754965024\n",
      "train loss:0.0009730085842509471\n",
      "train loss:0.0013417860050727048\n",
      "train loss:0.0007562734325831293\n",
      "train loss:0.0011072840625642466\n",
      "train loss:0.0013389650505760415\n",
      "train loss:0.0014839315724662744\n",
      "train loss:0.0019819361969311807\n",
      "train loss:0.004507446140808135\n",
      "train loss:0.0004996522657425374\n",
      "train loss:0.001918829671729972\n",
      "train loss:0.00015726683538218705\n",
      "train loss:0.00041906339479754384\n",
      "train loss:0.0013129888272407663\n",
      "train loss:0.005399985080113435\n",
      "train loss:0.0010012491399338452\n",
      "train loss:0.0035248282174156977\n",
      "train loss:0.02816854032219572\n",
      "train loss:0.0019136135009985445\n",
      "train loss:0.0006072704803365128\n",
      "train loss:0.0005223203555182172\n",
      "train loss:0.007830159284316775\n",
      "train loss:0.00022483124600913149\n",
      "train loss:0.0003539987350307682\n",
      "train loss:0.001590623867302941\n",
      "train loss:0.0009722532498019548\n",
      "train loss:0.0008162336320924539\n",
      "train loss:0.0007665133577762728\n",
      "train loss:0.001280662467132306\n",
      "train loss:0.00030614267222938183\n",
      "train loss:0.00036350579764539155\n",
      "train loss:0.0007562942841739459\n",
      "train loss:0.006660274821452222\n",
      "train loss:0.0027143675903663206\n",
      "train loss:0.00048166707835681525\n",
      "train loss:0.0001524653239011182\n",
      "train loss:0.002571648926779114\n",
      "train loss:0.002967468852763712\n",
      "train loss:0.003457221723585828\n",
      "train loss:0.000730101052967588\n",
      "train loss:0.00045720115609479623\n",
      "train loss:0.0008456271579462644\n",
      "train loss:0.0008849387391157916\n",
      "train loss:0.0013301583899557811\n",
      "train loss:8.32713396399394e-05\n",
      "train loss:0.0011906250619243693\n",
      "train loss:0.0019400522408093593\n",
      "train loss:0.0020060518412033613\n",
      "train loss:0.0011944180681281462\n",
      "train loss:0.0006888175891955948\n",
      "train loss:0.0014642795627986369\n",
      "train loss:0.006727310864357337\n",
      "train loss:0.002987175506889795\n",
      "train loss:0.002635185923071953\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.0030860206047547325\n",
      "train loss:0.0003039846487049503\n",
      "train loss:0.0027521573357738244\n",
      "train loss:0.001567450917266395\n",
      "train loss:0.00038877809582497875\n",
      "train loss:0.009554060363363707\n",
      "train loss:0.0008694396484842238\n",
      "train loss:0.025319849790497385\n",
      "train loss:0.008641195503087767\n",
      "train loss:0.00316973420153358\n",
      "train loss:0.005292634534904398\n",
      "train loss:0.007381625107611412\n",
      "train loss:0.0035034568152888944\n",
      "train loss:0.0021091517381157734\n",
      "train loss:0.00022649411174959324\n",
      "train loss:0.003327557819867074\n",
      "train loss:0.0013238277791109338\n",
      "train loss:0.00015459744625605736\n",
      "train loss:0.0008334941630227786\n",
      "train loss:0.0011764080773719278\n",
      "train loss:0.00014710713773906402\n",
      "train loss:0.00035958629219385517\n",
      "train loss:0.004443327876908051\n",
      "train loss:0.0023668900245700938\n",
      "train loss:0.0016216118633562062\n",
      "train loss:0.006967189867405039\n",
      "train loss:0.0015061021653425784\n",
      "train loss:0.007679602236873912\n",
      "train loss:0.001151199902227181\n",
      "train loss:0.001042534047378888\n",
      "train loss:0.005876689924766897\n",
      "train loss:0.0011973043833753906\n",
      "train loss:0.015665884180361203\n",
      "train loss:0.002200479730497222\n",
      "train loss:0.0034344254525438787\n",
      "train loss:0.0011764016559940352\n",
      "train loss:0.0029019430088418983\n",
      "train loss:0.0026572872967085513\n",
      "train loss:0.015935105249845087\n",
      "train loss:0.000979096208412892\n",
      "train loss:0.0001619743037623168\n",
      "train loss:0.0005604258865043484\n",
      "train loss:0.0004706620322458744\n",
      "train loss:0.03004529733156824\n",
      "train loss:0.000647009969312067\n",
      "train loss:0.0003207350529896554\n",
      "train loss:0.002256620826360118\n",
      "train loss:0.0028710723294775404\n",
      "train loss:0.0036488366529829203\n",
      "train loss:0.0015952584596939496\n",
      "train loss:0.006139461664599827\n",
      "train loss:0.0004494665760173068\n",
      "train loss:0.011403973917110805\n",
      "train loss:0.0015776703640206782\n",
      "train loss:0.001321335020909049\n",
      "train loss:0.012616811535914554\n",
      "train loss:0.008949884435832228\n",
      "train loss:0.00020513314316183417\n",
      "train loss:0.002344257617136848\n",
      "train loss:0.0019918045088629694\n",
      "train loss:0.001522615461642767\n",
      "train loss:0.0011605390145389533\n",
      "train loss:0.0030946284476912537\n",
      "train loss:0.0007881637197821784\n",
      "train loss:0.003105717083179204\n",
      "train loss:0.004010519410461225\n",
      "train loss:0.004254088535526752\n",
      "train loss:0.012565065086149334\n",
      "train loss:0.001016440214693687\n",
      "train loss:0.004564444007279048\n",
      "train loss:0.0007452214757912519\n",
      "train loss:0.00041156717543585296\n",
      "train loss:0.004118391802560205\n",
      "train loss:0.0030124199446135346\n",
      "train loss:0.00686806516155871\n",
      "train loss:0.0015338924007873259\n",
      "train loss:0.005701005388488956\n",
      "train loss:0.0010449117802560396\n",
      "train loss:0.0006754257470282823\n",
      "train loss:0.0012443881911747478\n",
      "train loss:0.002910532298187693\n",
      "train loss:0.0002066538042901491\n",
      "train loss:0.0005453310575682165\n",
      "train loss:0.0011736496051047535\n",
      "train loss:0.0019953786099774578\n",
      "train loss:0.0004169021759978124\n",
      "train loss:0.00034124346537329673\n",
      "train loss:0.0010795330629644472\n",
      "train loss:0.0010923355192217028\n",
      "train loss:0.0007973612546937391\n",
      "train loss:0.0026394703624048397\n",
      "train loss:0.00035351890550668904\n",
      "train loss:0.002093028879757866\n",
      "train loss:0.0006696236240143692\n",
      "train loss:0.0006270889387891357\n",
      "train loss:0.0022298677362989406\n",
      "train loss:0.019632802568422675\n",
      "train loss:0.006156628163053167\n",
      "train loss:0.009657892738003474\n",
      "train loss:0.0193464412379712\n",
      "train loss:0.015153805651889046\n",
      "train loss:0.0020212260696982226\n",
      "train loss:0.0012630675168648674\n",
      "train loss:0.0017028370987933594\n",
      "train loss:0.002847985925301782\n",
      "train loss:0.0005224122244646107\n",
      "train loss:0.002320898608823263\n",
      "train loss:0.00045689905501298666\n",
      "train loss:0.0005701240007538063\n",
      "train loss:0.0010723644897342034\n",
      "train loss:0.0007579757860943552\n",
      "train loss:0.04814069838176324\n",
      "train loss:0.0006392928747561058\n",
      "train loss:0.004311960435872335\n",
      "train loss:0.00332912274506083\n",
      "train loss:0.001471885092684296\n",
      "train loss:0.0002903350686425556\n",
      "train loss:0.0011825454646255972\n",
      "train loss:0.013283104805684872\n",
      "train loss:0.0033905455270071662\n",
      "train loss:0.002249574675046442\n",
      "train loss:0.053420137357144855\n",
      "train loss:0.006545335462424028\n",
      "train loss:0.007333294187970079\n",
      "train loss:0.002871729203753446\n",
      "train loss:0.002655651790384802\n",
      "train loss:0.0036899778681470084\n",
      "train loss:0.0041169686653149\n",
      "train loss:0.009685251283916172\n",
      "train loss:0.009005097792198559\n",
      "train loss:0.0016277199196740055\n",
      "train loss:0.00261049830298994\n",
      "train loss:0.0035059567034923657\n",
      "train loss:0.003280109056919703\n",
      "train loss:0.002677005951411635\n",
      "train loss:0.004099936612143095\n",
      "train loss:0.0026408914256635407\n",
      "train loss:0.004219311677910603\n",
      "train loss:0.0005379146458509819\n",
      "train loss:0.021748219533994088\n",
      "train loss:0.0001297514221841175\n",
      "train loss:0.0011758954745540477\n",
      "train loss:0.00035728812480490424\n",
      "train loss:0.0001394451987937548\n",
      "train loss:0.0023304967390433856\n",
      "train loss:0.0016039589239099134\n",
      "train loss:0.0064852426708503245\n",
      "train loss:0.0020880552227459355\n",
      "train loss:0.0015270211555108207\n",
      "train loss:0.015999020637492714\n",
      "train loss:0.0010445741411388811\n",
      "train loss:0.002650854381079553\n",
      "train loss:0.002298712928170776\n",
      "train loss:0.0020699050835261425\n",
      "train loss:0.002579914369986952\n",
      "train loss:0.007889865642501605\n",
      "train loss:0.0009705324536003599\n",
      "train loss:0.00037209072717503324\n",
      "train loss:0.0023936347040562304\n",
      "train loss:0.001358226445238591\n",
      "train loss:0.007274539386149326\n",
      "train loss:0.02487130265632293\n",
      "train loss:0.0007109423307566819\n",
      "train loss:0.0005446151180671395\n",
      "train loss:0.002845734539512398\n",
      "train loss:0.0021727540429493436\n",
      "train loss:0.00114511065563958\n",
      "train loss:0.002283982137451084\n",
      "train loss:0.0016218659988100667\n",
      "train loss:0.0018181025671485255\n",
      "train loss:0.0025220504300265682\n",
      "train loss:0.0010906926212356646\n",
      "train loss:0.006822436592289121\n",
      "train loss:0.011142449765550344\n",
      "train loss:0.0015629950556720377\n",
      "train loss:0.0057712661369890735\n",
      "train loss:0.0054242706805701525\n",
      "train loss:0.0038664607837752326\n",
      "train loss:0.0005221051212672669\n",
      "train loss:0.011173248338126779\n",
      "train loss:0.0011321121852201506\n",
      "train loss:0.0019319013308830612\n",
      "train loss:0.004460959204587805\n",
      "train loss:0.0002723121045551386\n",
      "train loss:0.002003651925086175\n",
      "train loss:0.0005044766099290005\n",
      "train loss:0.0013929375626174003\n",
      "train loss:0.004197657997035105\n",
      "train loss:0.0024159207444139656\n",
      "train loss:0.004192529923353297\n",
      "train loss:0.0007437748623506177\n",
      "train loss:0.0006348659686230554\n",
      "train loss:0.004513338296934355\n",
      "train loss:0.0002804945594015537\n",
      "train loss:0.0004171093367104035\n",
      "train loss:0.0033565776938278558\n",
      "train loss:0.0015973035208717466\n",
      "train loss:0.0009293383670668861\n",
      "train loss:0.0010731147206014969\n",
      "train loss:0.0041025162433298715\n",
      "train loss:0.013404396870783623\n",
      "train loss:0.00037713466454496246\n",
      "train loss:0.0012635631360148852\n",
      "train loss:0.0006491308257816044\n",
      "train loss:0.0006684829661402002\n",
      "train loss:0.003784764976728988\n",
      "train loss:0.001076262783122494\n",
      "train loss:0.0037464910560973796\n",
      "train loss:0.001099106140822863\n",
      "train loss:0.000567649740803481\n",
      "train loss:0.005708752987652725\n",
      "train loss:0.001985825206465614\n",
      "train loss:0.00030306970993894584\n",
      "train loss:0.002539952345678272\n",
      "train loss:0.0018732980647163144\n",
      "train loss:0.0035922196706051636\n",
      "train loss:0.0034905844809172853\n",
      "train loss:0.0028851366135144757\n",
      "train loss:0.0013671764651174648\n",
      "train loss:0.002282948972058278\n",
      "train loss:9.059142316494018e-05\n",
      "train loss:0.007005111297103978\n",
      "train loss:0.002776265958921384\n",
      "train loss:0.0024916302662162516\n",
      "train loss:0.004419204709376551\n",
      "train loss:0.0018781803524929757\n",
      "train loss:0.0004605690458290441\n",
      "train loss:0.0029091413503675896\n",
      "train loss:0.00015547148022729002\n",
      "train loss:0.00010209834501288706\n",
      "train loss:0.0006420445731484897\n",
      "train loss:0.0038647382516371043\n",
      "train loss:0.0012035408249641622\n",
      "train loss:0.00038994707478937025\n",
      "train loss:0.004377373679542219\n",
      "train loss:0.00033328396173970065\n",
      "train loss:0.00410574900298314\n",
      "train loss:0.004073908298142397\n",
      "train loss:0.0017634120050561302\n",
      "train loss:0.00216016283082449\n",
      "train loss:0.006013499741425144\n",
      "train loss:0.00014035907372698334\n",
      "train loss:0.0025553065928160357\n",
      "train loss:0.0007718311542391251\n",
      "train loss:0.0007943703890827326\n",
      "train loss:0.0005232460196746558\n",
      "train loss:0.0006076331860211581\n",
      "train loss:0.000993482508252363\n",
      "train loss:0.0015353965719146273\n",
      "train loss:0.0032782308801070433\n",
      "train loss:0.008029434578118657\n",
      "train loss:0.0011090288098631787\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.00448884021166937\n",
      "train loss:0.0016922173088617374\n",
      "train loss:0.0013638349273202665\n",
      "train loss:0.0012100996871245407\n",
      "train loss:0.0007816645620785514\n",
      "train loss:0.0007151776691557777\n",
      "train loss:0.00173029411622663\n",
      "train loss:0.0008867554403332678\n",
      "train loss:0.0005344949898378826\n",
      "train loss:0.0015787437435623097\n",
      "train loss:0.0008205730022853258\n",
      "train loss:0.0008438257649032928\n",
      "train loss:0.002215583679929729\n",
      "train loss:0.0005306965567482659\n",
      "train loss:0.002197260684520304\n",
      "train loss:0.0013377749480091652\n",
      "train loss:0.00036831088576590095\n",
      "train loss:0.015202500267321941\n",
      "train loss:0.0006894297174209265\n",
      "train loss:0.0002574858976012156\n",
      "train loss:0.0012926742778793722\n",
      "train loss:0.001468953907651029\n",
      "train loss:0.024323773456390706\n",
      "train loss:0.00022264290996130913\n",
      "train loss:0.0039437889133602\n",
      "train loss:0.002876250509848935\n",
      "train loss:0.004374634327748165\n",
      "train loss:0.004090866571089442\n",
      "train loss:0.005634651265728952\n",
      "train loss:0.006100477331369116\n",
      "train loss:0.0007170161747761722\n",
      "train loss:0.0019976620856805537\n",
      "train loss:0.0012786948503367259\n",
      "train loss:0.004204550380254003\n",
      "train loss:0.008769958769357315\n",
      "train loss:0.0020711705194853248\n",
      "train loss:0.011509174696968527\n",
      "train loss:0.001508231703692649\n",
      "train loss:0.00953353292135425\n",
      "train loss:0.004661718120065858\n",
      "train loss:0.012070606490316\n",
      "train loss:0.0006341346077584893\n",
      "train loss:0.0013781577433125628\n",
      "train loss:0.006360746056044591\n",
      "train loss:0.0033193024064315396\n",
      "train loss:0.0021438228246482747\n",
      "train loss:0.001309245700826178\n",
      "train loss:0.0018609565086879745\n",
      "train loss:0.002930980785389685\n",
      "train loss:0.010621198465046127\n",
      "train loss:0.0015254361545459303\n",
      "train loss:0.002633697046933977\n",
      "train loss:0.0058200575937770276\n",
      "train loss:0.00024564639503278125\n",
      "train loss:0.00024715265184106056\n",
      "train loss:0.0007206574492590995\n",
      "train loss:0.0023492872201460336\n",
      "train loss:0.0010739868100454809\n",
      "train loss:0.002631742190985379\n",
      "train loss:0.003420494594581333\n",
      "train loss:0.006287171478245268\n",
      "train loss:0.006559543436215292\n",
      "train loss:0.0018951165256514142\n",
      "train loss:0.0010432181331000668\n",
      "train loss:0.008053550480026074\n",
      "train loss:0.001487453184401031\n",
      "train loss:0.00011870102177013417\n",
      "train loss:0.0013429177080012263\n",
      "train loss:0.007224424730699418\n",
      "train loss:0.0014465658240902395\n",
      "train loss:0.0003551876893544949\n",
      "train loss:0.0011609471398779678\n",
      "train loss:0.0032259930454302805\n",
      "train loss:0.001906930848074433\n",
      "train loss:0.000622079480642472\n",
      "train loss:0.00457454889751068\n",
      "train loss:0.0003780774805440857\n",
      "train loss:0.0006411752473229203\n",
      "train loss:0.01517839680261569\n",
      "train loss:0.004281672846446944\n",
      "train loss:0.005963364876029944\n",
      "train loss:0.010344872155656291\n",
      "train loss:0.0005616821233514936\n",
      "train loss:0.0008765755802476907\n",
      "train loss:0.0033438549926226744\n",
      "train loss:0.0007790203926691018\n",
      "train loss:0.00029115400307639397\n",
      "train loss:0.0006202697762905482\n",
      "train loss:0.001956114968468748\n",
      "train loss:0.007232161617303498\n",
      "train loss:0.0028850418858151618\n",
      "train loss:0.0008108217702667848\n",
      "train loss:0.001487499891050457\n",
      "train loss:0.0029121370557389833\n",
      "train loss:0.0004311595586922831\n",
      "train loss:0.00031093152740258793\n",
      "train loss:0.00010884745493682355\n",
      "train loss:0.00036185721972003393\n",
      "train loss:0.00137054748217965\n",
      "train loss:0.00042031305634539185\n",
      "train loss:0.019218167682510133\n",
      "train loss:0.0015708649743134413\n",
      "train loss:0.0033519701391634764\n",
      "train loss:0.00024137409550347623\n",
      "train loss:0.0010651673920256933\n",
      "train loss:0.0003781114230180221\n",
      "train loss:0.0005502601016512093\n",
      "train loss:0.002311048184292324\n",
      "train loss:0.0008433104187967857\n",
      "train loss:0.0011923679794387495\n",
      "train loss:0.0020361794848932756\n",
      "train loss:0.0017766831081301852\n",
      "train loss:0.003521012501284391\n",
      "train loss:0.00044085168746790045\n",
      "train loss:0.0016321754389014573\n",
      "train loss:0.0009018010693888363\n",
      "train loss:8.217460043583773e-05\n",
      "train loss:0.0008546831100417089\n",
      "train loss:0.004114143136071723\n",
      "train loss:0.0009842631066197555\n",
      "train loss:0.0005127517654519677\n",
      "train loss:0.00026852450958985937\n",
      "train loss:0.00043647817908491087\n",
      "train loss:0.005478511629795366\n",
      "train loss:0.0011102525253206153\n",
      "train loss:0.002231277469535396\n",
      "train loss:0.000650864293832343\n",
      "train loss:0.0003715013856656415\n",
      "train loss:0.003781866029522908\n",
      "train loss:0.0008635053727737642\n",
      "train loss:0.001966697403704717\n",
      "train loss:0.0005587504029785965\n",
      "train loss:0.0020047070418817794\n",
      "train loss:0.00010143578801923613\n",
      "train loss:0.002658334466517521\n",
      "=== epoch:15, train acc:0.999, test acc:0.987 ===\n",
      "train loss:0.0010019654596068236\n",
      "train loss:0.0020699190875702483\n",
      "train loss:0.00018097584867169146\n",
      "train loss:0.0005141678639255701\n",
      "train loss:0.0016995623619922907\n",
      "train loss:0.004355120463278097\n",
      "train loss:0.0001860944496325545\n",
      "train loss:0.0028696294819561554\n",
      "train loss:0.0003533763852571005\n",
      "train loss:0.0014324696957797268\n",
      "train loss:0.00034045424915354623\n",
      "train loss:0.00027123024316804865\n",
      "train loss:0.0016450068933576282\n",
      "train loss:0.004327707191104909\n",
      "train loss:0.0006792734393086862\n",
      "train loss:0.0024125901912170106\n",
      "train loss:0.003117244261167265\n",
      "train loss:6.126648724307788e-05\n",
      "train loss:0.0002506756064814444\n",
      "train loss:0.000671212052906405\n",
      "train loss:0.00047961736370287375\n",
      "train loss:0.005200676886892962\n",
      "train loss:0.0025270802251785335\n",
      "train loss:0.0008400101306436405\n",
      "train loss:0.0014636836825649483\n",
      "train loss:0.0003509534339042123\n",
      "train loss:0.003716581085179775\n",
      "train loss:0.0031994975177778396\n",
      "train loss:0.0019163409565935894\n",
      "train loss:0.0001310999967670497\n",
      "train loss:0.0015269417298741012\n",
      "train loss:0.0004561426934883949\n",
      "train loss:0.0011884118317416355\n",
      "train loss:0.0087606724714052\n",
      "train loss:3.371639617077569e-05\n",
      "train loss:0.0003831319847490881\n",
      "train loss:0.0004600537054198485\n",
      "train loss:0.0011645450806143753\n",
      "train loss:0.0185037548951994\n",
      "train loss:0.001921845707009947\n",
      "train loss:0.0004838970709480434\n",
      "train loss:0.006291333888344293\n",
      "train loss:0.016270389378018994\n",
      "train loss:0.0012365131843086684\n",
      "train loss:0.001644082691072279\n",
      "train loss:0.052144718627953834\n",
      "train loss:0.0020998395576327473\n",
      "train loss:0.0895052346915379\n",
      "train loss:0.00130335140496388\n",
      "train loss:0.012506137469220595\n",
      "train loss:0.0003210481292374571\n",
      "train loss:0.0017572245869311453\n",
      "train loss:0.0013128060771400011\n",
      "train loss:0.0074997132922851985\n",
      "train loss:0.0004810174855205049\n",
      "train loss:0.0005952453907890188\n",
      "train loss:0.002760981447927026\n",
      "train loss:0.00029542406176521265\n",
      "train loss:0.014739443324109893\n",
      "train loss:0.002443746711957363\n",
      "train loss:0.005138731639921127\n",
      "train loss:0.011377844880572995\n",
      "train loss:0.0032745313500086816\n",
      "train loss:0.0008839552240413577\n",
      "train loss:0.0019072833602359874\n",
      "train loss:0.00030957584065004434\n",
      "train loss:0.0017190652276708723\n",
      "train loss:0.009884929528368802\n",
      "train loss:0.0038177690921711045\n",
      "train loss:0.0021251073970807617\n",
      "train loss:0.0038146037220408674\n",
      "train loss:0.00365187362614559\n",
      "train loss:0.0025608517804306483\n",
      "train loss:0.0013484633399994562\n",
      "train loss:0.012674090577096748\n",
      "train loss:0.0018762763681282454\n",
      "train loss:0.000462970499599685\n",
      "train loss:0.0016909406424848261\n",
      "train loss:0.0004753068020243241\n",
      "train loss:0.0030355705432512006\n",
      "train loss:0.0008291032773644861\n",
      "train loss:0.007551108891490453\n",
      "train loss:0.004467496376384183\n",
      "train loss:0.0013353699415572218\n",
      "train loss:0.004079507578094293\n",
      "train loss:0.002204217184382046\n",
      "train loss:0.0010455405673715102\n",
      "train loss:0.0008455681368230523\n",
      "train loss:0.0006323675098457661\n",
      "train loss:0.0020249992113700664\n",
      "train loss:0.008177150384109877\n",
      "train loss:0.0005572091002763417\n",
      "train loss:0.003908263554544899\n",
      "train loss:0.015925218046899003\n",
      "train loss:0.001421212740652718\n",
      "train loss:0.0007597471571100466\n",
      "train loss:0.002370283873917432\n",
      "train loss:0.001727851630346669\n",
      "train loss:0.003468437828046638\n",
      "train loss:0.0017140146162791814\n",
      "train loss:0.01438861057608376\n",
      "train loss:0.0004967669461913165\n",
      "train loss:0.002635093282167409\n",
      "train loss:0.008536066142094293\n",
      "train loss:0.012538482917257605\n",
      "train loss:0.00021713926140980348\n",
      "train loss:0.003636008610563566\n",
      "train loss:0.0005088471562418604\n",
      "train loss:0.0077178862277428525\n",
      "train loss:0.0019208748989296795\n",
      "train loss:0.0008183705394390159\n",
      "train loss:0.0028374019661438123\n",
      "train loss:0.026786028821516643\n",
      "train loss:0.0017582109796338398\n",
      "train loss:0.008933244898697118\n",
      "train loss:0.04665322360504443\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.0050137906411424835\n",
      "train loss:0.001159244878066834\n",
      "train loss:0.006540871462905562\n",
      "train loss:0.0010943967402813433\n",
      "train loss:0.000728740570894304\n",
      "train loss:0.005477670760685337\n",
      "train loss:0.00695705088175956\n",
      "train loss:0.009785569963325337\n",
      "train loss:0.01225173912831593\n",
      "train loss:0.0015706892606855644\n",
      "train loss:0.004173206831491271\n",
      "train loss:0.005413138163589734\n",
      "train loss:0.0025399617450204918\n",
      "train loss:0.0010582539223511695\n",
      "train loss:0.0032826051895811803\n",
      "train loss:0.0020033001123844914\n",
      "train loss:0.001045298516968328\n",
      "train loss:0.0028394392521091157\n",
      "train loss:0.002110043511339407\n",
      "train loss:0.001109937050401847\n",
      "train loss:0.0015170983376925104\n",
      "train loss:0.0411874946178711\n",
      "train loss:0.004279131100941696\n",
      "train loss:0.0026646031222342104\n",
      "train loss:0.0007899367977056733\n",
      "train loss:0.0032631266824207196\n",
      "train loss:0.0008490986286663065\n",
      "train loss:0.0020085081964682596\n",
      "train loss:0.0018159215783171189\n",
      "train loss:0.001386234469927709\n",
      "train loss:0.0036247739673833106\n",
      "train loss:0.006728637169978569\n",
      "train loss:0.0008823565359926062\n",
      "train loss:0.001279835621712746\n",
      "train loss:0.00020273366283105033\n",
      "train loss:0.0020071151577662543\n",
      "train loss:0.0012377206916220484\n",
      "train loss:0.0005424749109088503\n",
      "train loss:0.004447451099394186\n",
      "train loss:0.0007393448338606297\n",
      "train loss:0.0010130022568140683\n",
      "train loss:0.002275476096944538\n",
      "train loss:0.013351288317425802\n",
      "train loss:0.0010715525317683697\n",
      "train loss:0.00254818103620616\n",
      "train loss:0.00035215620308592927\n",
      "train loss:0.010189159406761896\n",
      "train loss:0.005049758991962179\n",
      "train loss:4.912820614361122e-05\n",
      "train loss:0.0002701215848273705\n",
      "train loss:0.00012496499007286227\n",
      "train loss:0.0076037247157012666\n",
      "train loss:0.00301218833299967\n",
      "train loss:0.01091868441186713\n",
      "train loss:0.001845009919493097\n",
      "train loss:0.0006349759815184156\n",
      "train loss:0.015886069480580866\n",
      "train loss:0.002581465910197308\n",
      "train loss:0.0005729740326041177\n",
      "train loss:0.008433021504676435\n",
      "train loss:0.0007876896485817153\n",
      "train loss:0.00569908723730801\n",
      "train loss:0.0037587865883921697\n",
      "train loss:0.0028432015872994565\n",
      "train loss:0.0002185751785799132\n",
      "train loss:0.005572460200283496\n",
      "train loss:0.0031334439172277374\n",
      "train loss:0.00044104770976369147\n",
      "train loss:0.0016780192837291242\n",
      "train loss:0.0007377233181636637\n",
      "train loss:0.001559592026907113\n",
      "train loss:0.0010753524691553549\n",
      "train loss:0.0013203485615301586\n",
      "train loss:0.0036694138698055967\n",
      "train loss:0.02032935734586006\n",
      "train loss:0.000601311134966024\n",
      "train loss:0.0015183207367436302\n",
      "train loss:0.00853962973882779\n",
      "train loss:0.0005756377451073022\n",
      "train loss:0.0016288862362757355\n",
      "train loss:0.0005086913617696748\n",
      "train loss:0.00034165023585021873\n",
      "train loss:0.0023227880753078113\n",
      "train loss:0.0022917201314527806\n",
      "train loss:0.0003629575485226969\n",
      "train loss:0.0008292835970770669\n",
      "train loss:0.004932680928835323\n",
      "train loss:0.00023700263932397548\n",
      "train loss:0.0009337473401290851\n",
      "train loss:0.00017641383772906742\n",
      "train loss:0.007967811510902707\n",
      "train loss:0.0018772574634625186\n",
      "train loss:7.37553246507881e-05\n",
      "train loss:0.002476782423226116\n",
      "train loss:0.0013621855509711913\n",
      "train loss:0.0028256387813123695\n",
      "train loss:0.0010801367009008267\n",
      "train loss:0.0015341555839754083\n",
      "train loss:0.011318020476661174\n",
      "train loss:0.0007129214835587678\n",
      "train loss:0.0006474526706248491\n",
      "train loss:0.0005509187506596807\n",
      "train loss:0.0006641465731208286\n",
      "train loss:0.0005240776830998956\n",
      "train loss:0.0010213043719151725\n",
      "train loss:0.00044310151961619783\n",
      "train loss:0.0011861829888690787\n",
      "train loss:0.0002581195544929898\n",
      "train loss:0.001560535980608607\n",
      "train loss:0.01659929646898549\n",
      "train loss:0.0036112087393252636\n",
      "train loss:0.0023279773224732115\n",
      "train loss:0.001780683212730631\n",
      "train loss:0.01107168733486534\n",
      "train loss:0.0006054184110410712\n",
      "train loss:0.01024624274203468\n",
      "train loss:0.0017592533944267882\n",
      "train loss:0.0010714780780364508\n",
      "train loss:0.0021212847701683204\n",
      "train loss:0.0014502683292104265\n",
      "train loss:0.0007397162255363014\n",
      "train loss:0.009567214371073322\n",
      "train loss:0.00302663446064031\n",
      "train loss:0.0015854871374374254\n",
      "train loss:0.0005142874327265612\n",
      "train loss:0.0007251232767119552\n",
      "train loss:0.0139872703055766\n",
      "train loss:0.005192427067626573\n",
      "train loss:0.0027633399322647373\n",
      "train loss:0.0003944932391489896\n",
      "train loss:0.0009438060815919074\n",
      "train loss:0.00108906890572355\n",
      "train loss:0.0025709640768688115\n",
      "train loss:0.0013888009127849365\n",
      "train loss:0.002330845390560854\n",
      "train loss:0.004197429692487069\n",
      "train loss:0.008548811494376966\n",
      "train loss:0.0017701073538182565\n",
      "train loss:0.001482048988419699\n",
      "train loss:0.00229551947910627\n",
      "train loss:0.0010484136734084737\n",
      "train loss:0.04756963353381015\n",
      "train loss:0.0016563179158852412\n",
      "train loss:0.00035157911190765445\n",
      "train loss:0.0002404882796611811\n",
      "train loss:0.0024612141320469335\n",
      "train loss:0.00019042356442183254\n",
      "train loss:0.0027849533986204745\n",
      "train loss:0.0015809411056129986\n",
      "train loss:0.030200732046888362\n",
      "train loss:0.007039915301124562\n",
      "train loss:0.0036886312884372983\n",
      "train loss:0.0003629715575563076\n",
      "train loss:0.0018920140043509842\n",
      "train loss:0.0020729802267837726\n",
      "train loss:0.0025314067376711862\n",
      "train loss:0.004645608323823763\n",
      "train loss:0.0010211521316839827\n",
      "train loss:9.563505885856834e-05\n",
      "train loss:0.002454489052836759\n",
      "train loss:0.0035239916221377347\n",
      "train loss:0.0016950414621950344\n",
      "train loss:0.00198393112189949\n",
      "train loss:0.0034113290811809364\n",
      "train loss:0.002457608680085707\n",
      "train loss:9.29848203356191e-05\n",
      "train loss:0.003462272867573222\n",
      "train loss:0.0004323726806874772\n",
      "train loss:0.0003389409540932284\n",
      "train loss:0.0009310690837602602\n",
      "train loss:6.023394525846058e-05\n",
      "train loss:0.0025117575412504974\n",
      "train loss:0.00042047896141402354\n",
      "train loss:0.008626474692031278\n",
      "train loss:0.002409175248421136\n",
      "train loss:0.001966911692718021\n",
      "train loss:0.0008505177493216272\n",
      "train loss:0.0004111630535800193\n",
      "train loss:0.0011623223406781228\n",
      "train loss:0.002313599790386657\n",
      "train loss:0.00031814711804976816\n",
      "train loss:0.0006032545719317396\n",
      "train loss:0.0029079734471733052\n",
      "train loss:0.00013501834810058618\n",
      "train loss:0.001201211155985512\n",
      "train loss:0.0002767106697240902\n",
      "train loss:0.0007732462670747639\n",
      "train loss:0.002541355250433733\n",
      "train loss:0.0027682663408222594\n",
      "train loss:0.000935960271252563\n",
      "train loss:0.001460915835087455\n",
      "train loss:0.001951613563747699\n",
      "train loss:0.0014439046715984249\n",
      "train loss:0.00014673322767628466\n",
      "train loss:0.00042100588322804486\n",
      "train loss:0.0033508296110933305\n",
      "train loss:0.0017991743049492962\n",
      "train loss:0.0010544401801544092\n",
      "train loss:0.0006046148003327869\n",
      "train loss:0.00831181657498083\n",
      "train loss:0.0008355973036146052\n",
      "train loss:0.0017956559176229413\n",
      "train loss:0.006877965287828542\n",
      "train loss:0.0018962799072254463\n",
      "train loss:0.0067787008140334885\n",
      "train loss:0.0008003715256559291\n",
      "train loss:0.0014526898347642495\n",
      "train loss:0.003763120447788716\n",
      "train loss:0.0021336950084560047\n",
      "train loss:0.0007716611144905106\n",
      "train loss:0.0005083703542052036\n",
      "train loss:0.0003006237026572188\n",
      "train loss:0.0017193155754127879\n",
      "train loss:0.0017664624236164621\n",
      "train loss:0.00043616754160694907\n",
      "train loss:0.009393872197487108\n",
      "train loss:9.334880320367576e-05\n",
      "train loss:0.0002223853175071926\n",
      "train loss:0.0004789772331428715\n",
      "train loss:0.0004298482470457331\n",
      "train loss:0.007249497518964103\n",
      "train loss:0.00045949841492535495\n",
      "train loss:0.0009845820414887832\n",
      "train loss:0.0005650646181447904\n",
      "train loss:0.0016290186641579776\n",
      "train loss:0.00021789823231451653\n",
      "train loss:0.005175680543067241\n",
      "train loss:0.0017711183971906397\n",
      "train loss:0.0025383145983851494\n",
      "train loss:0.004795185425462144\n",
      "train loss:0.0010129145507979482\n",
      "train loss:0.00029941189237847236\n",
      "train loss:0.002842398357313995\n",
      "train loss:0.0011826909345111938\n",
      "train loss:0.0019409248385021205\n",
      "train loss:0.000501290340590416\n",
      "train loss:0.0011126376468091786\n",
      "train loss:0.0005566422517528517\n",
      "train loss:0.0011818160834322616\n",
      "train loss:0.0010168167191105314\n",
      "train loss:0.00046229852138144603\n",
      "train loss:0.001276533987451243\n",
      "train loss:0.0013025747022732542\n",
      "train loss:0.0026043548782861956\n",
      "train loss:0.0006631579517172274\n",
      "train loss:0.0006285566530150655\n",
      "train loss:6.832347467152107e-05\n",
      "train loss:0.00010178784885229978\n",
      "train loss:0.0012599206955972897\n",
      "train loss:7.846787563645457e-05\n",
      "train loss:0.0027952964717548163\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:7.108372540958698e-05\n",
      "train loss:0.0006118543777577215\n",
      "train loss:7.733700835878844e-05\n",
      "train loss:8.532459176532909e-05\n",
      "train loss:0.0008121061581559071\n",
      "train loss:0.0016064456710334937\n",
      "train loss:0.00044921507077074385\n",
      "train loss:0.00795934004857992\n",
      "train loss:0.0004884567374737358\n",
      "train loss:0.0016100262805347045\n",
      "train loss:0.0005271484443771833\n",
      "train loss:0.0005520010193955964\n",
      "train loss:0.002685716437137158\n",
      "train loss:0.001509302259875942\n",
      "train loss:0.0002411578105417555\n",
      "train loss:0.000978899569664285\n",
      "train loss:0.00032929182712850854\n",
      "train loss:0.001452342182004652\n",
      "train loss:0.0017914634728007537\n",
      "train loss:0.0032998057151139215\n",
      "train loss:0.0003642585828756222\n",
      "train loss:0.0011775435750899415\n",
      "train loss:0.001166366234263077\n",
      "train loss:0.001666402892276348\n",
      "train loss:0.0006649060926197163\n",
      "train loss:0.00010181818836357338\n",
      "train loss:0.005150649917176674\n",
      "train loss:0.00035905475424375256\n",
      "train loss:0.0004371474780682193\n",
      "train loss:0.0015988909503152563\n",
      "train loss:0.0002532166081854425\n",
      "train loss:0.0013320511752892411\n",
      "train loss:0.0001953891554064025\n",
      "train loss:0.00045094431655428034\n",
      "train loss:0.0026137332269827217\n",
      "train loss:0.002353876617739509\n",
      "train loss:0.003258663777653674\n",
      "train loss:0.025919753202631898\n",
      "train loss:0.0013602475268173102\n",
      "train loss:0.0011768178693915812\n",
      "train loss:0.005165379737146203\n",
      "train loss:0.0004558623628340961\n",
      "train loss:0.0002514797577009814\n",
      "train loss:0.0013634932888493087\n",
      "train loss:0.0006519643030460624\n",
      "train loss:0.002303523271821691\n",
      "train loss:0.00012674022325407364\n",
      "train loss:0.001941322900800748\n",
      "train loss:0.0032391626238922316\n",
      "train loss:0.0027382648472040845\n",
      "train loss:0.0028821603853863087\n",
      "train loss:0.0011437231134887949\n",
      "train loss:0.004326110470865468\n",
      "train loss:0.0022896018571250927\n",
      "train loss:0.0003323534677984277\n",
      "train loss:0.0004263446410765581\n",
      "train loss:0.0004842627072485571\n",
      "train loss:0.0028080087057917387\n",
      "train loss:0.0012191701273209254\n",
      "train loss:0.0015167778073710628\n",
      "train loss:0.00011265231129729746\n",
      "train loss:0.000580441684354256\n",
      "train loss:0.0013912536948142828\n",
      "train loss:0.000254198909795651\n",
      "train loss:0.0008151083386345548\n",
      "train loss:0.0013843209963749132\n",
      "train loss:0.005727060069930485\n",
      "train loss:2.94356822040019e-05\n",
      "train loss:0.058507571814088576\n",
      "train loss:0.002498176023470168\n",
      "train loss:0.0003375978601695016\n",
      "train loss:0.00010019757618850946\n",
      "train loss:0.001462510774199647\n",
      "train loss:0.0013501157170660385\n",
      "train loss:0.029129410061605934\n",
      "train loss:0.0014783261502651901\n",
      "train loss:0.00037836193339491737\n",
      "train loss:0.00794110201749039\n",
      "train loss:0.0023312488025638884\n",
      "train loss:0.003887635615646891\n",
      "train loss:0.008276203853004758\n",
      "train loss:0.005228260815315816\n",
      "train loss:0.002965063486487705\n",
      "train loss:0.0008209627903997891\n",
      "train loss:0.0012813513570205425\n",
      "train loss:0.0006984852866772178\n",
      "train loss:0.0007783064012270659\n",
      "train loss:0.01087382362043265\n",
      "train loss:0.0006738408370619322\n",
      "train loss:0.001037210426183353\n",
      "train loss:0.007076236202130865\n",
      "train loss:0.000666580436184858\n",
      "train loss:0.0007799650923436017\n",
      "train loss:0.0006550518130744105\n",
      "train loss:0.00032641345468564743\n",
      "train loss:0.00018710378479531748\n",
      "train loss:0.0020153320697606867\n",
      "train loss:0.0012142685708055763\n",
      "train loss:0.007393953974751562\n",
      "train loss:0.0004650522150538253\n",
      "train loss:0.0009236352790834338\n",
      "train loss:0.001192983154420189\n",
      "train loss:0.0010312956807507069\n",
      "train loss:0.0016241421780430834\n",
      "train loss:0.0008106974303143813\n",
      "train loss:9.478751812932857e-05\n",
      "train loss:0.0014439550453347737\n",
      "train loss:0.0020695875245851005\n",
      "train loss:0.00014512817297873798\n",
      "train loss:0.003538451093341055\n",
      "train loss:0.0005592286090412823\n",
      "train loss:0.0037894651443073687\n",
      "train loss:9.808859172288253e-05\n",
      "train loss:0.00042648747236159474\n",
      "train loss:0.003701172462374593\n",
      "train loss:0.003090556178631618\n",
      "train loss:0.0003343821301406985\n",
      "train loss:0.0029115947216070896\n",
      "train loss:0.005477076497600462\n",
      "train loss:0.0018252085287398798\n",
      "train loss:0.007605336022800795\n",
      "train loss:0.00040402890323466156\n",
      "train loss:0.005265788364949017\n",
      "train loss:0.00021796428503658167\n",
      "train loss:0.0014648972479552813\n",
      "train loss:0.0017544058389418738\n",
      "train loss:0.0007506078231353279\n",
      "train loss:0.0013349963779796942\n",
      "train loss:0.006533217251346324\n",
      "train loss:0.008097518018494532\n",
      "train loss:0.0003330402816149853\n",
      "train loss:0.002338404959732663\n",
      "train loss:0.0014175251213771614\n",
      "train loss:0.0012746404906586676\n",
      "train loss:0.0868540366403659\n",
      "train loss:0.0015537352864195312\n",
      "train loss:6.886517308341395e-05\n",
      "train loss:0.0014445207342632127\n",
      "train loss:0.0014840681564659863\n",
      "train loss:0.0031728194374066525\n",
      "train loss:0.00040703903967455194\n",
      "train loss:0.000732333073806344\n",
      "train loss:0.0024498861535471187\n",
      "train loss:0.0008753780765661582\n",
      "train loss:0.00025068517935397905\n",
      "train loss:0.005948759483761652\n",
      "train loss:0.007520751738320309\n",
      "train loss:0.0063764893841683655\n",
      "train loss:0.0005402063326772667\n",
      "train loss:0.00581798050654981\n",
      "train loss:0.00507145137669464\n",
      "train loss:0.00039422553049321815\n",
      "train loss:0.0021166103810718205\n",
      "train loss:0.0025317824205606733\n",
      "train loss:0.0005455578093638304\n",
      "train loss:0.0004149584096902492\n",
      "train loss:0.006492109641324805\n",
      "train loss:0.006197950917584614\n",
      "train loss:0.0019892578788004737\n",
      "train loss:0.0016878862083767657\n",
      "train loss:0.0039256650269511245\n",
      "train loss:0.0010219153536180938\n",
      "train loss:0.0006050314228171244\n",
      "train loss:0.0027987595953548193\n",
      "train loss:0.0006756862118399734\n",
      "train loss:0.00046688377019591927\n",
      "train loss:0.0016687635110399785\n",
      "train loss:0.001449511575412337\n",
      "train loss:0.0006252562212391334\n",
      "train loss:0.0024673867758303863\n",
      "train loss:0.001201596522839826\n",
      "train loss:0.01100390746653567\n",
      "train loss:0.004409501206263503\n",
      "train loss:0.0031578311022028454\n",
      "train loss:0.0025977318878726095\n",
      "train loss:0.0005068253683830916\n",
      "train loss:0.004595919033368353\n",
      "train loss:0.0002776540949202076\n",
      "train loss:0.0013611619740682172\n",
      "train loss:0.00014030155269131756\n",
      "train loss:0.0011356555107686823\n",
      "train loss:0.0007016474308048375\n",
      "train loss:0.001089039759141143\n",
      "train loss:0.0005241819313851023\n",
      "train loss:0.000860659994552458\n",
      "train loss:0.0011197003120369622\n",
      "train loss:9.937173969459175e-05\n",
      "train loss:0.001959799156167921\n",
      "train loss:0.004843831549733675\n",
      "train loss:0.002248061510117597\n",
      "train loss:0.0008708990900808497\n",
      "train loss:9.007986614089578e-05\n",
      "train loss:0.003302482890345499\n",
      "train loss:0.0036590452694309\n",
      "train loss:0.002357736659426505\n",
      "train loss:0.0004542761696932381\n",
      "train loss:0.002410408141455874\n",
      "train loss:0.002427698864819217\n",
      "train loss:0.0004074998039886615\n",
      "train loss:0.0069061175955066135\n",
      "train loss:0.0006120469638375847\n",
      "train loss:0.0012125037833919906\n",
      "train loss:0.0009437912110476064\n",
      "train loss:0.0017253665562322826\n",
      "train loss:0.0015383615185721343\n",
      "train loss:0.0004483867512008463\n",
      "train loss:0.000809789116728838\n",
      "train loss:0.0015744356987327198\n",
      "train loss:0.0011765983547588948\n",
      "train loss:0.0014980936222051347\n",
      "train loss:0.004749764825759305\n",
      "train loss:0.0019276677115710834\n",
      "train loss:0.00039652965580647814\n",
      "train loss:0.0036651702075500177\n",
      "train loss:0.0012860542894248094\n",
      "train loss:0.0009764495327953002\n",
      "train loss:0.0005266583189325214\n",
      "train loss:0.0013515700271041608\n",
      "train loss:0.002373628166034489\n",
      "train loss:0.0004313089157349081\n",
      "train loss:0.00029248218920529954\n",
      "train loss:0.0003861997460729255\n",
      "train loss:0.0007823544804637189\n",
      "train loss:0.000157716280613572\n",
      "train loss:0.0004702103046045011\n",
      "train loss:0.0008507578588378909\n",
      "train loss:0.00075258097662689\n",
      "train loss:0.0020791738077380016\n",
      "train loss:0.0006437459537450363\n",
      "train loss:0.00018926662515994893\n",
      "train loss:0.0018182709486104997\n",
      "train loss:0.0006270421661039399\n",
      "train loss:0.0035871841447882523\n",
      "=== epoch:16, train acc:0.999, test acc:0.985 ===\n",
      "train loss:0.002768580018891914\n",
      "train loss:0.0013726221865630287\n",
      "train loss:0.0034260898038222755\n",
      "train loss:0.003583371972167822\n",
      "train loss:0.0021789416063313872\n",
      "train loss:0.0022443548518119765\n",
      "train loss:0.0005881384181648155\n",
      "train loss:0.00014437472796573813\n",
      "train loss:4.278143194433321e-05\n",
      "train loss:0.0005769090537322626\n",
      "train loss:0.0005324470682462616\n",
      "train loss:0.00045168293695405136\n",
      "train loss:0.0016587578713824986\n",
      "train loss:0.0014684054692183717\n",
      "train loss:0.0008299952571309212\n",
      "train loss:0.0002417847267538067\n",
      "train loss:0.000985962738776473\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.0030488550128455892\n",
      "train loss:0.0016025193892437665\n",
      "train loss:0.0034980714160731037\n",
      "train loss:0.00032300137376342034\n",
      "train loss:0.00023204612705636846\n",
      "train loss:0.0036378555642381837\n",
      "train loss:0.001254251534368622\n",
      "train loss:0.0005377624088778178\n",
      "train loss:0.0027361694133527102\n",
      "train loss:0.002251145551798976\n",
      "train loss:0.0008248487146915253\n",
      "train loss:0.00034661406231213963\n",
      "train loss:9.42600828218141e-05\n",
      "train loss:0.000704716314097518\n",
      "train loss:0.00013919160819404695\n",
      "train loss:6.984526809832421e-05\n",
      "train loss:0.0028418836522402114\n",
      "train loss:8.278889343851564e-05\n",
      "train loss:0.0009621725988428556\n",
      "train loss:0.0014428853050660673\n",
      "train loss:0.0024423804239405867\n",
      "train loss:0.0007864565210532186\n",
      "train loss:0.0006236425678055806\n",
      "train loss:0.00302178348440557\n",
      "train loss:0.0001298028266542418\n",
      "train loss:0.12466984971506141\n",
      "train loss:0.0005264926927165303\n",
      "train loss:0.00406315740633723\n",
      "train loss:0.00295552889461659\n",
      "train loss:0.0006326700812211132\n",
      "train loss:0.0006488311926334218\n",
      "train loss:0.0007146826506043666\n",
      "train loss:0.0018823164283089347\n",
      "train loss:0.0007918642840955727\n",
      "train loss:0.0009305089389353255\n",
      "train loss:0.0008280786298388367\n",
      "train loss:0.00031911073901278315\n",
      "train loss:0.00018834966850471798\n",
      "train loss:0.0009519893718052361\n",
      "train loss:0.0009498080115336089\n",
      "train loss:0.003589898602808472\n",
      "train loss:0.0007787932767892078\n",
      "train loss:0.0033913446905427637\n",
      "train loss:0.0006575696188648445\n",
      "train loss:0.0034740342699338496\n",
      "train loss:0.0024135030821450976\n",
      "train loss:0.006374365187497493\n",
      "train loss:0.0010092988543372963\n",
      "train loss:0.0002194502673732859\n",
      "train loss:0.00019299842871833766\n",
      "train loss:0.0008595943607567214\n",
      "train loss:0.0005065145009808544\n",
      "train loss:0.0020840044374797278\n",
      "train loss:0.00043993940641907757\n",
      "train loss:0.004127920395309977\n",
      "train loss:0.0002559005645049276\n",
      "train loss:0.0010372952726944134\n",
      "train loss:0.0019389819115726151\n",
      "train loss:0.00077279454541888\n",
      "train loss:0.0006929013834604064\n",
      "train loss:0.0021422986469484123\n",
      "train loss:0.0004842976473933157\n",
      "train loss:0.001835385836695473\n",
      "train loss:0.0038421804461502406\n",
      "train loss:0.009681334493708347\n",
      "train loss:0.013763677213524115\n",
      "train loss:0.0003856870078776451\n",
      "train loss:0.000341889028125117\n",
      "train loss:0.0042697527850683245\n",
      "train loss:0.007880892737638997\n",
      "train loss:0.0005678367594342989\n",
      "train loss:0.0015593265518950828\n",
      "train loss:0.00018048671254415965\n",
      "train loss:0.00018963299577075068\n",
      "train loss:0.0024125131189230388\n",
      "train loss:0.005354158529631324\n",
      "train loss:0.0005200131074956282\n",
      "train loss:0.0015993710247629697\n",
      "train loss:0.0041694513973423546\n",
      "train loss:0.008312615784502032\n",
      "train loss:0.0013161606002061762\n",
      "train loss:0.001246566856496007\n",
      "train loss:0.0048910069289467735\n",
      "train loss:0.001595097326570009\n",
      "train loss:0.0008692813937453262\n",
      "train loss:0.000264355109199679\n",
      "train loss:0.003781477284049303\n",
      "train loss:0.00016640013182889245\n",
      "train loss:0.000511554947957411\n",
      "train loss:0.016547148611314143\n",
      "train loss:9.2134279017416e-05\n",
      "train loss:0.0009933633336538302\n",
      "train loss:0.0030171427407143904\n",
      "train loss:0.008527451604361263\n",
      "train loss:0.0008569107913912297\n",
      "train loss:0.0009950821960997877\n",
      "train loss:0.0006681022225934355\n",
      "train loss:0.0011432373493121873\n",
      "train loss:0.005145114539043642\n",
      "train loss:0.00236087036523693\n",
      "train loss:0.001985910311265306\n",
      "train loss:0.002489070163601522\n",
      "train loss:0.008913720576458693\n",
      "train loss:0.0005689080611881753\n",
      "train loss:0.0006698637174064381\n",
      "train loss:0.0018277758655336205\n",
      "train loss:0.0007628399709825714\n",
      "train loss:0.00013714744070378722\n",
      "train loss:0.0009709014755011144\n",
      "train loss:0.0015754976432590952\n",
      "train loss:0.000704935048342782\n",
      "train loss:0.004489397120735913\n",
      "train loss:0.0013200797097895633\n",
      "train loss:0.003301686705043438\n",
      "train loss:0.003195572032156418\n",
      "train loss:0.002326955889392045\n",
      "train loss:0.0011554030110781832\n",
      "train loss:0.000479519463735026\n",
      "train loss:0.0010055657908494945\n",
      "train loss:0.0007964269278440708\n",
      "train loss:0.0016795719366144695\n",
      "train loss:0.002754641907269133\n",
      "train loss:0.0005945636097680079\n",
      "train loss:0.001048311758460274\n",
      "train loss:0.0034960348671748227\n",
      "train loss:0.0007773546143947938\n",
      "train loss:0.0018367687128830262\n",
      "train loss:0.000226194880460046\n",
      "train loss:6.96950800149822e-05\n",
      "train loss:0.0010954520568333599\n",
      "train loss:0.0071009243860374535\n",
      "train loss:0.0015854686096711554\n",
      "train loss:0.0012199433352587034\n",
      "train loss:6.60336336801879e-05\n",
      "train loss:0.00047588802346999455\n",
      "train loss:0.0003366603995150449\n",
      "train loss:0.002483588759034658\n",
      "train loss:0.0002268079930591139\n",
      "train loss:0.0004376180359169407\n",
      "train loss:0.0003295660776920011\n",
      "train loss:0.0023831183635443843\n",
      "train loss:0.0019923341170961476\n",
      "train loss:0.00018168215948173705\n",
      "train loss:0.001082190331569267\n",
      "train loss:0.00011887070584984104\n",
      "train loss:0.0012279518341630528\n",
      "train loss:0.0012317587863778078\n",
      "train loss:0.0028186447144202013\n",
      "train loss:0.0019727371402906532\n",
      "train loss:0.013631576018934864\n",
      "train loss:0.0022033077911674166\n",
      "train loss:0.00014274082967698882\n",
      "train loss:0.008697174345052756\n",
      "train loss:8.613729729309816e-05\n",
      "train loss:3.638486237902249e-05\n",
      "train loss:0.001442328587328417\n",
      "train loss:0.0003523525537804176\n",
      "train loss:0.004179584731688818\n",
      "train loss:0.0003545984267833192\n",
      "train loss:0.0004486150646097126\n",
      "train loss:0.00373872988200626\n",
      "train loss:0.0012113368477723332\n",
      "train loss:0.0021270923406864132\n",
      "train loss:0.0009450930169894973\n",
      "train loss:0.0049297532480739705\n",
      "train loss:0.0024572007909200795\n",
      "train loss:0.0009334283265633029\n",
      "train loss:0.002159375907141717\n",
      "train loss:0.00483518163471628\n",
      "train loss:0.0010510208239777425\n",
      "train loss:0.001231586155189029\n",
      "train loss:0.0008277997440557303\n",
      "train loss:0.0026543642456056137\n",
      "train loss:7.64696598452952e-05\n",
      "train loss:3.3233763193733985e-05\n",
      "train loss:0.0025303096445584592\n",
      "train loss:0.01753314294938745\n",
      "train loss:0.0037146821374201174\n",
      "train loss:0.0010069371471611043\n",
      "train loss:0.004665786705733146\n",
      "train loss:0.002661063671500362\n",
      "train loss:0.00018850930498920968\n",
      "train loss:0.003915355313006252\n",
      "train loss:0.000317950950398827\n",
      "train loss:0.004345328177177747\n",
      "train loss:0.0034785717777071168\n",
      "train loss:0.007164131737865145\n",
      "train loss:0.002141171375409196\n",
      "train loss:0.0005575062506907501\n",
      "train loss:0.001120772671447035\n",
      "train loss:0.0009758372907501548\n",
      "train loss:0.009301825835031956\n",
      "train loss:0.0021403511677894975\n",
      "train loss:0.0022802710525738376\n",
      "train loss:0.002228026987381614\n",
      "train loss:0.0030784662614089897\n",
      "train loss:0.0011786674435102875\n",
      "train loss:0.00047434969173768167\n",
      "train loss:0.00020154846722881487\n",
      "train loss:0.0005484280368108988\n",
      "train loss:0.0026338772518646227\n",
      "train loss:0.00013535584141571023\n",
      "train loss:0.0004247476687949925\n",
      "train loss:0.003733616632045606\n",
      "train loss:0.0004301169690351281\n",
      "train loss:0.003466054662501547\n",
      "train loss:0.0016030732256206944\n",
      "train loss:0.000447071971357632\n",
      "train loss:0.005161754300064027\n",
      "train loss:0.0018227826776795533\n",
      "train loss:0.00047563222896235323\n",
      "train loss:0.0010684908647176094\n",
      "train loss:0.00015422741332485405\n",
      "train loss:0.002272983843398669\n",
      "train loss:0.00031291988610930306\n",
      "train loss:0.001978019961756915\n",
      "train loss:0.0016645272543332726\n",
      "train loss:0.0008947346290847859\n",
      "train loss:0.00024806361309178933\n",
      "train loss:0.0006064849650521365\n",
      "train loss:0.0002981984698370093\n",
      "train loss:0.012603308838839358\n",
      "train loss:0.00032274154972445365\n",
      "train loss:0.014006033931735266\n",
      "train loss:0.0001184877723729693\n",
      "train loss:0.0003178205905761227\n",
      "train loss:0.00017507830078636083\n",
      "train loss:0.0023206035390577477\n",
      "train loss:0.003394683328003181\n",
      "train loss:0.0007633562926089945\n",
      "train loss:0.0016208651642266295\n",
      "train loss:0.0012601208495893884\n",
      "train loss:0.00014694545958172193\n",
      "train loss:0.0022516381528167183\n",
      "train loss:0.000993867420009594\n",
      "train loss:0.0005463972706799323\n",
      "train loss:0.003923047362673038\n",
      "train loss:0.0005323365258788062\n",
      "train loss:0.0007754353228176733\n",
      "train loss:0.0003789301485260781\n",
      "train loss:0.004474609806983025\n",
      "train loss:0.002613030737481249\n",
      "train loss:0.0012177533041321468\n",
      "train loss:0.001653695351927873\n",
      "train loss:0.0005988097968852501\n",
      "train loss:0.0011179764893128532\n",
      "train loss:0.0011364834049668144\n",
      "train loss:0.0004029389698237701\n",
      "train loss:0.0005637309832482123\n",
      "train loss:7.043334175518002e-05\n",
      "train loss:9.325680634285276e-05\n",
      "train loss:0.0022774560667848226\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.01572199608503978\n",
      "train loss:0.016783676603866322\n",
      "train loss:0.0004434706446588523\n",
      "train loss:0.001966594225528315\n",
      "train loss:0.0007928396470461806\n",
      "train loss:0.0010206178194949664\n",
      "train loss:0.0005281537025264827\n",
      "train loss:0.0013931086817163946\n",
      "train loss:0.00028258309031468194\n",
      "train loss:0.002834474253322836\n",
      "train loss:0.002721772227001824\n",
      "train loss:0.003148157310803794\n",
      "train loss:0.0006284767693325267\n",
      "train loss:0.006832474985966825\n",
      "train loss:0.0027865974432630036\n",
      "train loss:0.0002440864645217877\n",
      "train loss:0.002869263263199535\n",
      "train loss:0.001873062433497109\n",
      "train loss:0.0006740578244818922\n",
      "train loss:0.002002989512553853\n",
      "train loss:0.0016953511525192161\n",
      "train loss:0.0019639881501762376\n",
      "train loss:0.004176792922972433\n",
      "train loss:0.0038074934011863796\n",
      "train loss:0.0002473607782034264\n",
      "train loss:0.025858748185092956\n",
      "train loss:0.0006806966440994072\n",
      "train loss:0.0005579970870078423\n",
      "train loss:0.005877453367103714\n",
      "train loss:8.988912620811878e-05\n",
      "train loss:0.0027629720421385746\n",
      "train loss:0.00023059993897479942\n",
      "train loss:0.000316805159385209\n",
      "train loss:0.000458874702378948\n",
      "train loss:0.00028701236951324775\n",
      "train loss:0.0006784067545126109\n",
      "train loss:0.0033838506808611443\n",
      "train loss:0.0001234492390894183\n",
      "train loss:0.008212919123031258\n",
      "train loss:0.0005809827258411556\n",
      "train loss:0.0035939076479748868\n",
      "train loss:0.0033851285215623487\n",
      "train loss:0.002017782830118328\n",
      "train loss:0.00031461556893432345\n",
      "train loss:0.0019019852491357202\n",
      "train loss:0.0009974799277491177\n",
      "train loss:0.002263011921523198\n",
      "train loss:0.01901321424358445\n",
      "train loss:0.00022660883383480014\n",
      "train loss:0.00024731535763640905\n",
      "train loss:0.0006721127710847611\n",
      "train loss:0.001488270077304811\n",
      "train loss:0.007878456498869403\n",
      "train loss:0.0006242361480716791\n",
      "train loss:0.003342519181142642\n",
      "train loss:0.015622365505741304\n",
      "train loss:0.004715821613223105\n",
      "train loss:0.016511100314749998\n",
      "train loss:0.0023686872817096473\n",
      "train loss:0.0004434341303003702\n",
      "train loss:0.005128749046152066\n",
      "train loss:0.00024672825159532377\n",
      "train loss:0.002595134388666059\n",
      "train loss:0.001488948082890849\n",
      "train loss:9.240159342927723e-05\n",
      "train loss:0.004824288708556161\n",
      "train loss:0.0002361133906071624\n",
      "train loss:0.0020764246878431365\n",
      "train loss:0.001210987589553538\n",
      "train loss:0.0017471375099269936\n",
      "train loss:0.00017685956747978384\n",
      "train loss:0.0029664626318048294\n",
      "train loss:0.0069323348814857196\n",
      "train loss:0.0007282963485727554\n",
      "train loss:0.00012464526701561716\n",
      "train loss:0.0016981043625155614\n",
      "train loss:0.00023853506462275667\n",
      "train loss:0.00029839660445149724\n",
      "train loss:0.0036482472503629225\n",
      "train loss:0.0007569798277068192\n",
      "train loss:0.00010114383070301674\n",
      "train loss:0.003133274483007244\n",
      "train loss:0.00016203725394949367\n",
      "train loss:0.01282577072946146\n",
      "train loss:0.0022145855365919113\n",
      "train loss:0.0027560836538023823\n",
      "train loss:0.0005142440408266323\n",
      "train loss:0.001452442151267857\n",
      "train loss:0.0029958547043227863\n",
      "train loss:0.0013860015148299634\n",
      "train loss:0.0004771099192658949\n",
      "train loss:0.0019365416079523091\n",
      "train loss:9.729449730594644e-05\n",
      "train loss:0.0014811523765788437\n",
      "train loss:0.0002175957359283602\n",
      "train loss:0.0012707975477177212\n",
      "train loss:0.0041782021474077715\n",
      "train loss:0.0003516277265694955\n",
      "train loss:0.0011286515623074559\n",
      "train loss:0.002119018341259098\n",
      "train loss:0.0006464737984428426\n",
      "train loss:0.00514017821995166\n",
      "train loss:0.000998923938126025\n",
      "train loss:0.000592072453693631\n",
      "train loss:0.00026046093392417065\n",
      "train loss:0.0005908712767109204\n",
      "train loss:0.008346664288868136\n",
      "train loss:0.00020951901538896866\n",
      "train loss:0.0026777111181389935\n",
      "train loss:0.0012749138455349352\n",
      "train loss:0.000705933002882138\n",
      "train loss:0.029805552418419402\n",
      "train loss:0.0001241161888002377\n",
      "train loss:0.009819092445280562\n",
      "train loss:0.0018808278862526959\n",
      "train loss:0.0011147322803236532\n",
      "train loss:0.0005508432341225154\n",
      "train loss:0.0006734467826536187\n",
      "train loss:0.003168733081483734\n",
      "train loss:0.0008690591093212188\n",
      "train loss:0.0021685652353628953\n",
      "train loss:5.7989486945375525e-05\n",
      "train loss:0.0012494535474627574\n",
      "train loss:0.002039301060998435\n",
      "train loss:0.0015501597491266363\n",
      "train loss:0.0003752043052587206\n",
      "train loss:0.0020809456123352683\n",
      "train loss:0.0005975944246356071\n",
      "train loss:0.0010275741258828897\n",
      "train loss:0.002039990507325854\n",
      "train loss:0.004518882396268183\n",
      "train loss:0.00349809406368867\n",
      "train loss:0.00854763536873646\n",
      "train loss:0.0004989815727443102\n",
      "train loss:0.0011521422356174896\n",
      "train loss:0.003134283230605473\n",
      "train loss:0.00031046258508897316\n",
      "train loss:0.0016141404051233143\n",
      "train loss:0.0019039099083665674\n",
      "train loss:0.0003945676814063518\n",
      "train loss:0.01145097469182533\n",
      "train loss:0.0033218862932659406\n",
      "train loss:0.001087995837474273\n",
      "train loss:0.001903523280798923\n",
      "train loss:0.004290400082814318\n",
      "train loss:0.0004125040757966565\n",
      "train loss:0.001602713295763945\n",
      "train loss:0.00884250945345525\n",
      "train loss:0.0008213702771359618\n",
      "train loss:0.00324902995099201\n",
      "train loss:0.0006931532528798737\n",
      "train loss:0.0007406993135787359\n",
      "train loss:4.558566944826375e-05\n",
      "train loss:0.001485582380708765\n",
      "train loss:0.0041562699955235375\n",
      "train loss:0.002925927706306229\n",
      "train loss:0.0008293810857429891\n",
      "train loss:0.01193057919445589\n",
      "train loss:0.00717945723461047\n",
      "train loss:0.0004708884625563522\n",
      "train loss:0.0008073901747100585\n",
      "train loss:0.0022876485542989776\n",
      "train loss:0.0008120653548798539\n",
      "train loss:0.03048126483593712\n",
      "train loss:0.0004574357962907708\n",
      "train loss:0.00032922941957415504\n",
      "train loss:0.008524719396872093\n",
      "train loss:2.9984390285254357e-05\n",
      "train loss:0.006762912112603948\n",
      "train loss:0.0026260987820275142\n",
      "train loss:0.008391293639772762\n",
      "train loss:0.00452761342278235\n",
      "train loss:0.0043448324172946345\n",
      "train loss:0.016049414681750314\n",
      "train loss:0.00020483163990431076\n",
      "train loss:0.001883510995875681\n",
      "train loss:0.00031716317203921574\n",
      "train loss:0.000836414061274874\n",
      "train loss:0.0005925051092658229\n",
      "train loss:0.0009921762767867628\n",
      "train loss:0.00129636035743791\n",
      "train loss:0.0007272139984302779\n",
      "train loss:0.0018205133332668036\n",
      "train loss:0.002007063776759136\n",
      "train loss:0.0014489458374339751\n",
      "train loss:0.0003338710875589499\n",
      "train loss:0.0006428800062299713\n",
      "train loss:0.0004311002604369649\n",
      "train loss:0.0020511197186584987\n",
      "train loss:0.00011710741380370746\n",
      "train loss:0.00024087431242750365\n",
      "train loss:0.0006696503472668645\n",
      "train loss:0.0006495363133653165\n",
      "train loss:0.0008144577391681425\n",
      "train loss:0.002762922408327531\n",
      "train loss:0.0013664845839872636\n",
      "train loss:0.036176032190366574\n",
      "train loss:0.0024333653578105375\n",
      "train loss:0.002237029729369905\n",
      "train loss:0.0015118736379118084\n",
      "train loss:3.1238808027850625e-05\n",
      "train loss:0.0008606473809883901\n",
      "train loss:0.0022244563910555726\n",
      "train loss:0.0005751745173505553\n",
      "train loss:0.004538540678802914\n",
      "train loss:0.0020704538672477995\n",
      "train loss:0.00010485903256759424\n",
      "train loss:0.013507105587059101\n",
      "train loss:0.0004894868621251232\n",
      "train loss:0.0023489770415934773\n",
      "train loss:0.000977392947826807\n",
      "train loss:0.00040773788843374257\n",
      "train loss:0.00131036446138617\n",
      "train loss:0.00022611021039140893\n",
      "train loss:0.0001992011958965018\n",
      "train loss:0.0034878842433961645\n",
      "train loss:0.00022893027536863408\n",
      "train loss:0.0002528611178811043\n",
      "train loss:0.0011664375454209534\n",
      "train loss:0.0006291574127049064\n",
      "train loss:0.0006374112353644223\n",
      "train loss:0.0001532996561136859\n",
      "train loss:0.004214111838729481\n",
      "train loss:0.0003476234388980553\n",
      "train loss:0.0008931946831924922\n",
      "train loss:0.002687147618366002\n",
      "train loss:0.0031644033725672653\n",
      "train loss:0.0007919356030243323\n",
      "train loss:7.486013399692949e-05\n",
      "train loss:0.000361333176219895\n",
      "train loss:0.002636867059264057\n",
      "train loss:0.0013376183939102799\n",
      "train loss:0.0015481795657536737\n",
      "train loss:0.0018245845229721343\n",
      "train loss:0.0006258399298498617\n",
      "train loss:0.0030111019698418457\n",
      "train loss:3.9167130400425985e-05\n",
      "train loss:0.0002902103146125841\n",
      "train loss:0.000249706642573539\n",
      "train loss:0.007833367902118705\n",
      "train loss:0.0031505182221689344\n",
      "train loss:0.0004631611738995826\n",
      "train loss:0.0019277829875967124\n",
      "train loss:0.002399057744994045\n",
      "train loss:0.0005096897930241407\n",
      "train loss:0.000631970334041879\n",
      "train loss:0.0004281854517877071\n",
      "train loss:0.0076585115723221435\n",
      "train loss:0.004353888604850959\n",
      "train loss:6.648732300732704e-05\n",
      "train loss:0.0033945343312196757\n",
      "train loss:0.003032532145656697\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.0036090229954103496\n",
      "train loss:0.0003708528242599052\n",
      "train loss:0.0024996107946904035\n",
      "train loss:0.0006991735350549725\n",
      "train loss:0.0002846079911251919\n",
      "train loss:0.004053412976760995\n",
      "train loss:0.0015547339393681156\n",
      "train loss:0.001593596787383922\n",
      "train loss:0.0024286153098532597\n",
      "train loss:0.0001881072673850124\n",
      "train loss:0.003965138228308941\n",
      "train loss:0.0005863201982093024\n",
      "train loss:0.00044174807255558356\n",
      "train loss:0.004052648543917985\n",
      "train loss:0.0019133571332015694\n",
      "train loss:0.0020003738358466737\n",
      "train loss:0.002370894310229768\n",
      "train loss:0.003930864765191686\n",
      "train loss:0.00019663800435041064\n",
      "train loss:0.005403596652188361\n",
      "train loss:0.0001531189795923477\n",
      "train loss:0.0006528300985766113\n",
      "train loss:0.0054250667137156735\n",
      "train loss:0.00046097302043204396\n",
      "train loss:0.0008288199211507638\n",
      "train loss:0.012873144592460117\n",
      "train loss:0.0019191790858764084\n",
      "train loss:0.00025408617474675607\n",
      "train loss:0.0021278235957499\n",
      "train loss:0.00036301718625744386\n",
      "train loss:0.000521107672380499\n",
      "train loss:0.0008589851448292216\n",
      "train loss:0.002465624071244212\n",
      "train loss:0.0014428652395458768\n",
      "train loss:0.0003996491483826893\n",
      "train loss:0.0006787769120075329\n",
      "train loss:0.03293135191107235\n",
      "train loss:0.005152934914288667\n",
      "train loss:0.0009226049494644031\n",
      "train loss:0.0012946706359114627\n",
      "train loss:0.0022752202287598324\n",
      "train loss:0.0016843242674389855\n",
      "train loss:0.0009652977128124281\n",
      "train loss:0.00151002229034233\n",
      "train loss:0.00739752433980246\n",
      "train loss:0.040260483642323645\n",
      "train loss:0.001237283112426831\n",
      "train loss:0.0018766626176611584\n",
      "train loss:0.0019614790884563867\n",
      "train loss:0.008188897947818413\n",
      "train loss:0.0010420057582970575\n",
      "train loss:0.0035280019666387584\n",
      "train loss:0.003763952171385681\n",
      "train loss:0.0007421651233657803\n",
      "train loss:9.839139108467146e-05\n",
      "train loss:0.0023636187498299356\n",
      "train loss:0.0028569434278867345\n",
      "train loss:0.0025303830236239845\n",
      "train loss:0.0002989841134119901\n",
      "train loss:0.005180018049706668\n",
      "train loss:0.0029192060005114617\n",
      "train loss:0.0027590909070364243\n",
      "train loss:0.0005324313153082687\n",
      "train loss:0.006378180412472623\n",
      "train loss:0.0014947416130487096\n",
      "train loss:0.004302661173896029\n",
      "train loss:0.0012807512941149588\n",
      "train loss:0.0020370905578264097\n",
      "train loss:0.0008744305029174844\n",
      "train loss:0.0026944236326046167\n",
      "train loss:0.002316906201132179\n",
      "train loss:0.004489405203090763\n",
      "train loss:0.0041740247136798385\n",
      "train loss:0.0005767600067666857\n",
      "train loss:2.7945888636423812e-05\n",
      "train loss:0.0004535286316172358\n",
      "train loss:0.000499287429237293\n",
      "train loss:0.0026161817057852436\n",
      "train loss:0.0004202460997361709\n",
      "=== epoch:17, train acc:0.998, test acc:0.986 ===\n",
      "train loss:0.005093600329467256\n",
      "train loss:0.000641675456254958\n",
      "train loss:0.0046623133200037635\n",
      "train loss:0.0005763480506830926\n",
      "train loss:0.0008299539010577607\n",
      "train loss:0.00012986055863343382\n",
      "train loss:0.0016267179797787685\n",
      "train loss:0.0001703495949704772\n",
      "train loss:0.004013614650846507\n",
      "train loss:0.001123837994925613\n",
      "train loss:0.0017983597775251005\n",
      "train loss:0.0040423870294208\n",
      "train loss:0.0010118700005355846\n",
      "train loss:0.0020657380520985795\n",
      "train loss:0.0007293449395855203\n",
      "train loss:0.0018282001729345763\n",
      "train loss:0.0009134760717470609\n",
      "train loss:0.0054912863231128504\n",
      "train loss:0.0014898718026696378\n",
      "train loss:0.0006017678012742765\n",
      "train loss:0.006029011218728617\n",
      "train loss:0.013586232096522193\n",
      "train loss:0.0031391919507946075\n",
      "train loss:0.0004975471743259789\n",
      "train loss:0.00035015203284494763\n",
      "train loss:0.011356957390662647\n",
      "train loss:0.0040237985103670874\n",
      "train loss:0.0004557502540285296\n",
      "train loss:0.0006390114109197033\n",
      "train loss:0.0028378465126510195\n",
      "train loss:0.001164654442793013\n",
      "train loss:0.0013389116116239682\n",
      "train loss:0.00027635648158474605\n",
      "train loss:0.001082440757782406\n",
      "train loss:0.000705684728662885\n",
      "train loss:0.000778804557610207\n",
      "train loss:0.000659483826731973\n",
      "train loss:0.00017756043771785496\n",
      "train loss:0.00032171244273072934\n",
      "train loss:0.0008694733768339008\n",
      "train loss:0.004769709896308836\n",
      "train loss:0.001998020215459781\n",
      "train loss:0.0008201446694052943\n",
      "train loss:0.0011704762771011419\n",
      "train loss:0.0012093247951561865\n",
      "train loss:0.001478634285581875\n",
      "train loss:0.0006868836369360306\n",
      "train loss:0.001639653416507541\n",
      "train loss:0.003004469273363401\n",
      "train loss:0.003481169604710794\n",
      "train loss:0.00034901782756748906\n",
      "train loss:0.0008561949931307965\n",
      "train loss:0.002340003342904026\n",
      "train loss:0.0006350404185601079\n",
      "train loss:0.00015937053912330016\n",
      "train loss:0.00025077532218687306\n",
      "train loss:0.0006271340580570208\n",
      "train loss:0.00018782895425891938\n",
      "train loss:0.0004666833621433148\n",
      "train loss:0.001528318946291238\n",
      "train loss:0.0015182760773794295\n",
      "train loss:0.0007413341403269418\n",
      "train loss:0.001568953013747872\n",
      "train loss:0.0014948479022658257\n",
      "train loss:0.0017031983888886118\n",
      "train loss:0.0011596790695866308\n",
      "train loss:0.0016275899032157958\n",
      "train loss:0.001005053696337115\n",
      "train loss:0.0007193700474179503\n",
      "train loss:0.0014156563480800858\n",
      "train loss:0.00046118159920047663\n",
      "train loss:0.002216663711049162\n",
      "train loss:0.0023836254116596\n",
      "train loss:0.0014324718865640629\n",
      "train loss:0.0038211879738176053\n",
      "train loss:0.00041831483071580396\n",
      "train loss:0.0013887346815571874\n",
      "train loss:0.0019155695506209319\n",
      "train loss:0.0009418105859973539\n",
      "train loss:0.004712941796433597\n",
      "train loss:0.0005500487144404127\n",
      "train loss:0.0027986723597665125\n",
      "train loss:0.0049452753039559635\n",
      "train loss:0.024975436115312503\n",
      "train loss:0.00042328974669887285\n",
      "train loss:6.618599651003584e-05\n",
      "train loss:0.0016330869856455508\n",
      "train loss:0.0009238300082988884\n",
      "train loss:0.03250930021014034\n",
      "train loss:0.00041949533850194455\n",
      "train loss:0.003059921861470821\n",
      "train loss:0.0005113824342090469\n",
      "train loss:0.0003063831079893537\n",
      "train loss:0.0014678207330592428\n",
      "train loss:0.0005604673883322437\n",
      "train loss:0.0009492640481648306\n",
      "train loss:0.0014099660196092573\n",
      "train loss:0.004787610063588282\n",
      "train loss:0.0021035033429168933\n",
      "train loss:0.00046046360822389116\n",
      "train loss:0.0012798010641571836\n",
      "train loss:4.971901113709004e-05\n",
      "train loss:0.00043591817484215983\n",
      "train loss:0.0006848769033958468\n",
      "train loss:0.0005553404882482372\n",
      "train loss:0.0019648285654441755\n",
      "train loss:0.0006089264925606694\n",
      "train loss:0.0017713082623464118\n",
      "train loss:9.73555405136806e-05\n",
      "train loss:0.0006691779943633749\n",
      "train loss:0.00013877777629684585\n",
      "train loss:0.0008841823814665532\n",
      "train loss:0.0031178919067053664\n",
      "train loss:0.0016288276139052006\n",
      "train loss:0.0003507914828011975\n",
      "train loss:0.0003305761553018128\n",
      "train loss:0.0030149015609513734\n",
      "train loss:0.00019835363711749842\n",
      "train loss:2.6321542762032358e-05\n",
      "train loss:0.0002971281961206089\n",
      "train loss:9.191816781657673e-05\n",
      "train loss:0.0021665148578941867\n",
      "train loss:0.0001312347717728164\n",
      "train loss:0.0008344372261142874\n",
      "train loss:0.0011084830980448213\n",
      "train loss:0.00022517439240263653\n",
      "train loss:0.0011911362164340731\n",
      "train loss:0.0028055609624465555\n",
      "train loss:0.005090602606129998\n",
      "train loss:0.0007675219204462541\n",
      "train loss:0.002178667751784686\n",
      "train loss:0.03800803580233434\n",
      "train loss:0.004141236880315357\n",
      "train loss:4.231785385813113e-05\n",
      "train loss:0.007900974598199762\n",
      "train loss:0.0024060861650611626\n",
      "train loss:0.0012335735197890165\n",
      "train loss:0.0016775340712270098\n",
      "train loss:0.0012512598164429\n",
      "train loss:0.0036400462491670573\n",
      "train loss:0.0009344573059907037\n",
      "train loss:0.0070267548496886125\n",
      "train loss:0.024104026820544272\n",
      "train loss:0.00014182857912976144\n",
      "train loss:0.0004711709937245825\n",
      "train loss:0.0005674512872676162\n",
      "train loss:0.0044042514415960025\n",
      "train loss:0.0019723863713688268\n",
      "train loss:0.021549266064172415\n",
      "train loss:0.009988167986106548\n",
      "train loss:0.00608937672921265\n",
      "train loss:0.0035199546410644694\n",
      "train loss:0.002799875654802578\n",
      "train loss:0.0011348010873430472\n",
      "train loss:0.018650822250476696\n",
      "train loss:0.0020403258830975065\n",
      "train loss:0.0031392836693914018\n",
      "train loss:0.0003035750259144066\n",
      "train loss:0.001228922511814276\n",
      "train loss:0.002202841016818416\n",
      "train loss:0.002114470305347998\n",
      "train loss:0.00838383104478833\n",
      "train loss:0.0026454082369425096\n",
      "train loss:0.0002655367089739924\n",
      "train loss:0.0005898927850687798\n",
      "train loss:0.0015889650223842764\n",
      "train loss:0.002028750561802019\n",
      "train loss:0.0008616397703365558\n",
      "train loss:0.00510204691385745\n",
      "train loss:0.0012784238730468274\n",
      "train loss:0.00019068544632034807\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.002238316766058557\n",
      "train loss:0.0024006229170349495\n",
      "train loss:0.0005523096405926779\n",
      "train loss:0.005039885171882724\n",
      "train loss:0.00030484787345134794\n",
      "train loss:0.0020527327463638356\n",
      "train loss:0.00016351429658921856\n",
      "train loss:0.004571580819896824\n",
      "train loss:0.0016556151316070228\n",
      "train loss:0.002151314816770995\n",
      "train loss:0.0032720354252072027\n",
      "train loss:0.0005496861088185885\n",
      "train loss:0.010665779698419444\n",
      "train loss:0.0017642315988574905\n",
      "train loss:0.001162815662239912\n",
      "train loss:0.004286860310501534\n",
      "train loss:0.004058566626679441\n",
      "train loss:0.00122937324992574\n",
      "train loss:0.0014697584920448854\n",
      "train loss:0.003419131553719729\n",
      "train loss:0.00044073736274441054\n",
      "train loss:0.0011140686851038575\n",
      "train loss:0.0020545125530775877\n",
      "train loss:0.0005206593909858211\n",
      "train loss:0.003875813381009682\n",
      "train loss:0.0006615662990203204\n",
      "train loss:0.000502893422464337\n",
      "train loss:0.0006493112400839218\n",
      "train loss:0.000873334249881855\n",
      "train loss:0.0033260330720864604\n",
      "train loss:0.0014863794738000236\n",
      "train loss:0.003272239925248116\n",
      "train loss:0.0014780349760291328\n",
      "train loss:0.0016686401681196158\n",
      "train loss:0.0003036452177152441\n",
      "train loss:0.0005365154234981884\n",
      "train loss:0.06163001282525327\n",
      "train loss:3.8358787976685245e-05\n",
      "train loss:0.0021718807478254653\n",
      "train loss:0.002189355165162191\n",
      "train loss:0.002080033268994795\n",
      "train loss:0.00044506558742903285\n",
      "train loss:0.0007069960823317961\n",
      "train loss:0.014459332815530565\n",
      "train loss:0.007118859114294227\n",
      "train loss:0.0007013565049237259\n",
      "train loss:0.0005797400950901427\n",
      "train loss:0.0012906478545476798\n",
      "train loss:0.00047001027458007724\n",
      "train loss:0.001655353716889181\n",
      "train loss:0.00043614767818606336\n",
      "train loss:0.0033900326000233356\n",
      "train loss:0.0003897507094032386\n",
      "train loss:0.00023722631261745026\n",
      "train loss:0.0008470976970323807\n",
      "train loss:0.00016319363377661215\n",
      "train loss:0.0040164915126069045\n",
      "train loss:0.0029854313688516695\n",
      "train loss:0.0022644765498829027\n",
      "train loss:0.0008801533033619101\n",
      "train loss:0.007295858632311013\n",
      "train loss:0.005288470700942151\n",
      "train loss:0.0015542581866461501\n",
      "train loss:0.0006433578137028501\n",
      "train loss:0.0012709581818567107\n",
      "train loss:4.449043231254144e-05\n",
      "train loss:0.005188349614649379\n",
      "train loss:0.0008915768715569528\n",
      "train loss:0.0014961874867761757\n",
      "train loss:0.04212066941387303\n",
      "train loss:0.001024431065157828\n",
      "train loss:0.0011062117251894646\n",
      "train loss:0.000671524354161997\n",
      "train loss:0.0026853660260792024\n",
      "train loss:0.00018391171776999032\n",
      "train loss:0.00027842556712955486\n",
      "train loss:0.0006829656349310593\n",
      "train loss:0.00016130449213562988\n",
      "train loss:0.0002726331218231078\n",
      "train loss:0.00036163639928248927\n",
      "train loss:0.006698420928226054\n",
      "train loss:0.003293395167741671\n",
      "train loss:0.0003730412523491486\n",
      "train loss:0.000683341195146224\n",
      "train loss:0.003509906327213448\n",
      "train loss:0.0008522726981165062\n",
      "train loss:0.031094626470216487\n",
      "train loss:0.0035162522957513194\n",
      "train loss:0.0002772058956843011\n",
      "train loss:0.00048555099593912984\n",
      "train loss:0.0004678495550210221\n",
      "train loss:0.0005797659104832443\n",
      "train loss:0.00026173622656023183\n",
      "train loss:0.0006339944719633686\n",
      "train loss:0.0004675299313254828\n",
      "train loss:0.0013250519526918144\n",
      "train loss:0.0010087313250123902\n",
      "train loss:0.004374369364409997\n",
      "train loss:0.0013582046641216106\n",
      "train loss:0.003958479070298011\n",
      "train loss:0.0008536192322172538\n",
      "train loss:0.0016205863396798028\n",
      "train loss:0.0110308634041197\n",
      "train loss:0.0004754457995902526\n",
      "train loss:0.0008033484768419705\n",
      "train loss:0.002486738914480385\n",
      "train loss:0.005477615006705194\n",
      "train loss:0.01717882048207292\n",
      "train loss:0.0008275589193256484\n",
      "train loss:0.0001742605128409604\n",
      "train loss:0.0015105288789721112\n",
      "train loss:0.00037660726277238094\n",
      "train loss:0.0027636052228979698\n",
      "train loss:0.0005375418894858731\n",
      "train loss:0.0006730772259333137\n",
      "train loss:0.00036183093306874477\n",
      "train loss:0.00036970942896713673\n",
      "train loss:0.018748749941679424\n",
      "train loss:0.007692181660378774\n",
      "train loss:0.0020558111856477327\n",
      "train loss:0.0009841548351730645\n",
      "train loss:0.005432995927043838\n",
      "train loss:0.002361982010447198\n",
      "train loss:0.0003717328916106978\n",
      "train loss:0.0009865625552005098\n",
      "train loss:0.001005966984233886\n",
      "train loss:0.0003896013181118071\n",
      "train loss:0.0003880927976091054\n",
      "train loss:0.002026475381642594\n",
      "train loss:0.0014610604170156862\n",
      "train loss:0.007128965251780539\n",
      "train loss:0.002229702016385917\n",
      "train loss:0.000701873714093081\n",
      "train loss:0.002460004478644989\n",
      "train loss:0.0018363138224358308\n",
      "train loss:0.00034293680895853217\n",
      "train loss:0.02311687965399711\n",
      "train loss:0.0010639322072256339\n",
      "train loss:0.0008834379580496627\n",
      "train loss:0.0018743973281799761\n",
      "train loss:0.0011693871043224893\n",
      "train loss:0.0003068860674975948\n",
      "train loss:0.0005550032701274244\n",
      "train loss:0.00545086670053118\n",
      "train loss:0.022702710688499574\n",
      "train loss:0.0016187787079093548\n",
      "train loss:0.0008387504637712756\n",
      "train loss:0.0038487968411997993\n",
      "train loss:0.0011870090231929388\n",
      "train loss:0.0008953662935634698\n",
      "train loss:0.0006167974606788395\n",
      "train loss:0.0025154365980612076\n",
      "train loss:0.00022029372124790215\n",
      "train loss:0.001649377896269199\n",
      "train loss:0.01330161377145974\n",
      "train loss:0.00273004343243289\n",
      "train loss:0.0014796636271133456\n",
      "train loss:0.00035824873123005115\n",
      "train loss:0.0002705770805926216\n",
      "train loss:0.00017422927903808843\n",
      "train loss:0.0012589651441831282\n",
      "train loss:0.002635685058618055\n",
      "train loss:0.0008804527897471946\n",
      "train loss:0.0013374755156859003\n",
      "train loss:0.0025400289732193733\n",
      "train loss:0.0021339902741810547\n",
      "train loss:0.00800725325182576\n",
      "train loss:0.00030096312415131115\n",
      "train loss:0.00031952072013605024\n",
      "train loss:0.0002336223977270313\n",
      "train loss:0.007647240014610594\n",
      "train loss:0.00019504248210381814\n",
      "train loss:0.0006640829752474225\n",
      "train loss:0.0030320220765213696\n",
      "train loss:0.0049783290399338645\n",
      "train loss:0.0009894782593466286\n",
      "train loss:0.0029905204833616567\n",
      "train loss:0.0014300664400000507\n",
      "train loss:0.0019094076911254575\n",
      "train loss:0.00021697758298387204\n",
      "train loss:0.0003297161040940263\n",
      "train loss:0.0034909242802464097\n",
      "train loss:6.554614535135152e-05\n",
      "train loss:0.003292989071097074\n",
      "train loss:0.0014054827788341497\n",
      "train loss:0.001163883285943988\n",
      "train loss:0.0054308139189164165\n",
      "train loss:8.620303422002769e-05\n",
      "train loss:0.0010616314592194762\n",
      "train loss:0.005652944774132048\n",
      "train loss:0.001423584758429321\n",
      "train loss:0.002255857074823929\n",
      "train loss:0.0011120133566178956\n",
      "train loss:0.00025965276082713347\n",
      "train loss:0.0005500675668123922\n",
      "train loss:0.0007269759134307067\n",
      "train loss:0.0025555629535030616\n",
      "train loss:0.001123276056511443\n",
      "train loss:0.00011071982112900024\n",
      "train loss:0.009687781651372716\n",
      "train loss:0.0011138225942653901\n",
      "train loss:0.0002690459392553187\n",
      "train loss:0.0019223843208700411\n",
      "train loss:0.0013207280643582659\n",
      "train loss:0.002764516715752773\n",
      "train loss:0.0038493755967127646\n",
      "train loss:0.00039704959172258593\n",
      "train loss:0.0013145049599620651\n",
      "train loss:0.0034984269731581463\n",
      "train loss:0.001614076384601452\n",
      "train loss:0.0009401602569492959\n",
      "train loss:0.0002210878674117265\n",
      "train loss:0.005680361046933099\n",
      "train loss:0.00038827830690430957\n",
      "train loss:0.00032910120906201747\n",
      "train loss:0.0005232099264268287\n",
      "train loss:0.0016027135973007355\n",
      "train loss:0.003980056715306416\n",
      "train loss:0.0006294683330727153\n",
      "train loss:0.0035944698003690266\n",
      "train loss:0.0016091989381607711\n",
      "train loss:0.0012984861694972513\n",
      "train loss:0.0007525218848873047\n",
      "train loss:0.014613701634568392\n",
      "train loss:0.0020560601192260784\n",
      "train loss:0.000373693258111668\n",
      "train loss:0.0016833932696563346\n",
      "train loss:6.960137685847685e-05\n",
      "train loss:0.002705804380092188\n",
      "train loss:0.0013380735939996138\n",
      "train loss:0.00015274113161289305\n",
      "train loss:0.0003202044747001287\n",
      "train loss:0.0038186061558230767\n",
      "train loss:0.0011898960810291144\n",
      "train loss:0.001096032876396621\n",
      "train loss:0.0002327975756397754\n",
      "train loss:0.00013840880376937904\n",
      "train loss:0.0003955431318065576\n",
      "train loss:0.0003586114813454855\n",
      "train loss:0.00012919552529125488\n",
      "train loss:0.014429207262539899\n",
      "train loss:0.0003594676160623529\n",
      "train loss:0.002181668106344899\n",
      "train loss:0.0003409635598974656\n",
      "train loss:0.0008021201596006437\n",
      "train loss:0.00015361880705776226\n",
      "train loss:6.769479263511312e-05\n",
      "train loss:0.00015421170283395186\n",
      "train loss:0.002136716181407346\n",
      "train loss:0.0004990138548552119\n",
      "train loss:0.001051735922196467\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.0005885358588179498\n",
      "train loss:0.0004169381745527352\n",
      "train loss:9.305094034642551e-05\n",
      "train loss:5.795428960222493e-05\n",
      "train loss:0.01550699103080439\n",
      "train loss:0.0007133741975517189\n",
      "train loss:0.0002656854423168918\n",
      "train loss:0.0003183034640070883\n",
      "train loss:0.0018332316512370097\n",
      "train loss:0.0001802679178216221\n",
      "train loss:4.352790065061413e-05\n",
      "train loss:0.0046884863276723445\n",
      "train loss:0.0004895644316483517\n",
      "train loss:0.0007091436424164306\n",
      "train loss:0.000525740635925563\n",
      "train loss:0.00017777791893333278\n",
      "train loss:0.0018862670435169592\n",
      "train loss:0.0006230914420898959\n",
      "train loss:0.001774435319082506\n",
      "train loss:0.00012575504872120187\n",
      "train loss:0.001124142067372602\n",
      "train loss:0.0006856265577823498\n",
      "train loss:0.0007776100395542238\n",
      "train loss:0.00035163823353855946\n",
      "train loss:0.0005522348069693596\n",
      "train loss:0.002913832123089256\n",
      "train loss:0.0014821808234421298\n",
      "train loss:0.0027554270343713044\n",
      "train loss:0.00010107352099102159\n",
      "train loss:0.15964703115786608\n",
      "train loss:0.003459708472030206\n",
      "train loss:0.00336332141219533\n",
      "train loss:0.0027635213448625323\n",
      "train loss:0.013701638599889631\n",
      "train loss:0.0024657093181821815\n",
      "train loss:0.0021369399390065032\n",
      "train loss:7.105255792601298e-05\n",
      "train loss:0.0003919701130239856\n",
      "train loss:0.0027356829636241676\n",
      "train loss:0.0021160790692382127\n",
      "train loss:0.0002107183188181855\n",
      "train loss:0.000533482015888393\n",
      "train loss:0.0024538813800315078\n",
      "train loss:0.0005965198298889446\n",
      "train loss:0.004296451200981135\n",
      "train loss:0.0021429807103638832\n",
      "train loss:0.0014925658213510839\n",
      "train loss:0.001287854470873403\n",
      "train loss:0.0020315495727100696\n",
      "train loss:0.0002483135347057934\n",
      "train loss:0.00023283460203929254\n",
      "train loss:0.00035986190854487074\n",
      "train loss:0.00011777915114650475\n",
      "train loss:0.00034776097582528393\n",
      "train loss:0.0032598726324107492\n",
      "train loss:0.0010242056829930155\n",
      "train loss:0.000663101643084354\n",
      "train loss:0.001363565755053517\n",
      "train loss:0.0023252781733780255\n",
      "train loss:0.005382246896461623\n",
      "train loss:0.008282955161503057\n",
      "train loss:0.0018151980287974604\n",
      "train loss:0.0004100930716550411\n",
      "train loss:0.0015668739601313539\n",
      "train loss:8.751739725148335e-05\n",
      "train loss:0.0014979045965285607\n",
      "train loss:0.0006278158248956483\n",
      "train loss:0.0013884178372301772\n",
      "train loss:0.0004055482604863149\n",
      "train loss:6.668511722954011e-05\n",
      "train loss:0.0033500376677854018\n",
      "train loss:0.0015025409448849944\n",
      "train loss:0.004091617477591667\n",
      "train loss:0.002402479704765317\n",
      "train loss:0.002685557540708185\n",
      "train loss:0.0012947253073279322\n",
      "train loss:0.004445976809839028\n",
      "train loss:9.18283006183785e-05\n",
      "train loss:0.0005739629310780555\n",
      "train loss:0.000849243526228239\n",
      "train loss:0.000536177356513487\n",
      "train loss:0.0009638041846368146\n",
      "train loss:0.0005882649533905874\n",
      "train loss:0.0004524770562516878\n",
      "train loss:0.002651586790920463\n",
      "train loss:0.0005726487684526933\n",
      "train loss:0.002210346946765584\n",
      "train loss:0.0006544942806472545\n",
      "train loss:0.00027794230541692747\n",
      "train loss:0.0034940924429622705\n",
      "train loss:0.0008496433971981232\n",
      "train loss:0.0006235178836173627\n",
      "train loss:0.0012707169716024412\n",
      "train loss:0.00024486215306105324\n",
      "train loss:0.003381998730137048\n",
      "train loss:0.0015198330728121274\n",
      "train loss:0.0017269240297965113\n",
      "train loss:0.0001736904558717316\n",
      "train loss:8.298012297860155e-05\n",
      "train loss:0.0009074942419955421\n",
      "train loss:0.0023671585781174075\n",
      "train loss:0.0004169541272605098\n",
      "train loss:0.0002981017327885462\n",
      "train loss:0.0003806023946265806\n",
      "train loss:0.0010018546653525952\n",
      "train loss:0.0019161437564904327\n",
      "train loss:0.0004190667226737313\n",
      "train loss:0.0017571714521385053\n",
      "train loss:0.0010577463468146025\n",
      "train loss:0.0006716178463714113\n",
      "train loss:0.00106177289787174\n",
      "train loss:0.000463073907658089\n",
      "train loss:0.0009963312842408106\n",
      "train loss:0.0018976296551795314\n",
      "train loss:0.0024702706092684756\n",
      "train loss:0.0008745091949263153\n",
      "train loss:0.0008127311818655374\n",
      "train loss:0.0009184174600508697\n",
      "train loss:0.008778548661409806\n",
      "train loss:0.010908272974661803\n",
      "train loss:0.0030675568380736434\n",
      "train loss:0.0008461941332333788\n",
      "train loss:0.0026342660636854646\n",
      "train loss:0.0024126411858675268\n",
      "train loss:0.0010604150228849388\n",
      "train loss:0.0010402059800976248\n",
      "train loss:0.003764007871685732\n",
      "train loss:0.002234900775249479\n",
      "train loss:0.00207817216208725\n",
      "train loss:0.0004912738326642758\n",
      "train loss:0.04377041103846107\n",
      "train loss:0.0012017936066199839\n",
      "train loss:0.0004604747924757334\n",
      "train loss:0.0037858000916195754\n",
      "train loss:0.0015007589895558874\n",
      "train loss:0.00293592672187628\n",
      "train loss:0.013735556121039539\n",
      "train loss:0.0039572590106136535\n",
      "train loss:0.0014996179836210038\n",
      "train loss:0.0001281215543068839\n",
      "train loss:0.005321425965141932\n",
      "train loss:0.002216791356761599\n",
      "train loss:0.0020339672023708495\n",
      "train loss:0.0011801090382700657\n",
      "train loss:0.0014095514181942253\n",
      "train loss:0.0036483514508922565\n",
      "train loss:0.0008556196860688911\n",
      "train loss:0.00018241503677909383\n",
      "train loss:0.006289223930824114\n",
      "train loss:0.0012594189602594579\n",
      "train loss:0.0024707632919275632\n",
      "train loss:0.0018732065055511798\n",
      "train loss:8.573013608830719e-05\n",
      "train loss:0.0006292234978153561\n",
      "train loss:0.0015333827891633412\n",
      "train loss:0.0011080633506827648\n",
      "train loss:7.711260935206077e-05\n",
      "train loss:0.00016135812894817452\n",
      "train loss:0.000324693900264295\n",
      "train loss:0.008749376729063573\n",
      "train loss:0.0001425583181104605\n",
      "train loss:0.0007547074417490934\n",
      "train loss:0.0031441387059653707\n",
      "train loss:0.0035490439211524377\n",
      "train loss:0.00010229035522210699\n",
      "train loss:0.0027171323883557175\n",
      "train loss:0.0008056997316414623\n",
      "train loss:0.00042629094657002843\n",
      "train loss:0.002970783179484354\n",
      "train loss:0.005914927787364096\n",
      "train loss:0.0005459146941596362\n",
      "train loss:0.0024806042674472804\n",
      "train loss:0.0027154633740918525\n",
      "train loss:0.0011957375180614831\n",
      "train loss:0.00017549764127093893\n",
      "train loss:0.0052118336111244366\n",
      "train loss:0.03924058852574437\n",
      "train loss:0.0021268767128697643\n",
      "=== epoch:18, train acc:1.0, test acc:0.987 ===\n",
      "train loss:0.0006116195029446106\n",
      "train loss:0.0015170560326382362\n",
      "train loss:0.0005032077537286237\n",
      "train loss:0.002201806979647249\n",
      "train loss:0.0019136630259028629\n",
      "train loss:0.05131855789838667\n",
      "train loss:0.0020595544582064284\n",
      "train loss:0.0004993261530346554\n",
      "train loss:0.004647200585142244\n",
      "train loss:0.0018123309618499708\n",
      "train loss:0.000579296315323101\n",
      "train loss:0.0002644605868374749\n",
      "train loss:0.00043138542417041716\n",
      "train loss:0.0019436306795470228\n",
      "train loss:0.003972297880311935\n",
      "train loss:0.002392503940230852\n",
      "train loss:0.0010770141563795\n",
      "train loss:0.0007621586239155509\n",
      "train loss:0.02208248834556752\n",
      "train loss:0.021261998608326976\n",
      "train loss:0.002996420255869752\n",
      "train loss:0.00011813677900037633\n",
      "train loss:0.0015049388726154917\n",
      "train loss:5.059589277493595e-05\n",
      "train loss:0.0019137579666546395\n",
      "train loss:0.0032637946302470715\n",
      "train loss:0.000590119630580958\n",
      "train loss:0.0007645508676975371\n",
      "train loss:0.0028787397874112026\n",
      "train loss:0.002349003135613685\n",
      "train loss:0.0009784875542530093\n",
      "train loss:0.0005527324818570766\n",
      "train loss:0.0025009595059787048\n",
      "train loss:0.0030157009485055203\n",
      "train loss:0.0018881332086570792\n",
      "train loss:0.0018280245685277402\n",
      "train loss:0.002647843890386664\n",
      "train loss:0.002280479167472661\n",
      "train loss:0.00409336807579086\n",
      "train loss:0.0016666616579757818\n",
      "train loss:0.003091006991701588\n",
      "train loss:0.0024455615437804002\n",
      "train loss:0.03896038230240732\n",
      "train loss:0.0017578247339649006\n",
      "train loss:0.001717777690111835\n",
      "train loss:0.01981169904197971\n",
      "train loss:0.0019491107290577573\n",
      "train loss:0.0032368142490667956\n",
      "train loss:0.0008095359321685787\n",
      "train loss:0.0027018297725308667\n",
      "train loss:0.0009090985091317959\n",
      "train loss:0.0002765911912282835\n",
      "train loss:0.0034126567035567073\n",
      "train loss:0.0003640809347569198\n",
      "train loss:0.002159931399695619\n",
      "train loss:0.003540312985748602\n",
      "train loss:0.001325315917117783\n",
      "train loss:0.00029679764546023486\n",
      "train loss:0.0007564208490417108\n",
      "train loss:0.0006820780728906347\n",
      "train loss:0.0020250704544864102\n",
      "train loss:0.002129281110856716\n",
      "train loss:0.0003604931946974883\n",
      "train loss:0.0029158784699706763\n",
      "train loss:0.007223557771234572\n",
      "train loss:2.2618164426747475e-05\n",
      "train loss:0.004266899340038987\n",
      "train loss:0.00028216255574023034\n",
      "train loss:0.004479290555296103\n",
      "train loss:0.0010179525642882345\n",
      "train loss:0.0005023745370902398\n",
      "train loss:0.001787678929682685\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.00039631378524353423\n",
      "train loss:5.713339573895412e-05\n",
      "train loss:0.008463248029837098\n",
      "train loss:0.001170157014370586\n",
      "train loss:0.0007727746130140714\n",
      "train loss:0.0005340942816646543\n",
      "train loss:0.002241811993979744\n",
      "train loss:0.0031259856072828485\n",
      "train loss:0.0008232156509561046\n",
      "train loss:0.0007948238910809307\n",
      "train loss:0.011710187076071766\n",
      "train loss:0.0012586029774314831\n",
      "train loss:0.003951537560373587\n",
      "train loss:0.0013686376355628782\n",
      "train loss:0.002181052188298539\n",
      "train loss:0.021337530246558583\n",
      "train loss:0.004144154429473135\n",
      "train loss:0.0029548799692861454\n",
      "train loss:0.0019944598438855154\n",
      "train loss:1.088796047193442e-05\n",
      "train loss:0.0004124337152056507\n",
      "train loss:0.0008047794857889409\n",
      "train loss:0.013702009669743545\n",
      "train loss:0.00030626385277673554\n",
      "train loss:0.019254537005730817\n",
      "train loss:0.0006920590731025022\n",
      "train loss:0.004554379700038285\n",
      "train loss:0.0005697459385227419\n",
      "train loss:0.0015417242389068869\n",
      "train loss:0.001959744245958521\n",
      "train loss:0.0006611391798678249\n",
      "train loss:0.006148774680917696\n",
      "train loss:0.0028931860137292164\n",
      "train loss:0.0014868781883949566\n",
      "train loss:0.0010912187037543568\n",
      "train loss:0.0018626734937133888\n",
      "train loss:0.002731361137044129\n",
      "train loss:0.00205008707071372\n",
      "train loss:0.002025102002019386\n",
      "train loss:0.0017638868760236613\n",
      "train loss:0.0009961756007403214\n",
      "train loss:0.0007358352421339365\n",
      "train loss:0.0014445172443153164\n",
      "train loss:0.0012947263232227582\n",
      "train loss:0.0002499820030722728\n",
      "train loss:0.002355886010909926\n",
      "train loss:0.00012378720462212153\n",
      "train loss:0.00023718322869154305\n",
      "train loss:0.001909937526857912\n",
      "train loss:0.0009132985276259449\n",
      "train loss:0.0019811764903548542\n",
      "train loss:0.0016736841324575447\n",
      "train loss:0.00446023990220148\n",
      "train loss:0.0011370540245579587\n",
      "train loss:0.001059591385323982\n",
      "train loss:0.009092535080114445\n",
      "train loss:0.0005657513543927715\n",
      "train loss:0.0013575724770252746\n",
      "train loss:0.005552429980614187\n",
      "train loss:0.0064173954146815515\n",
      "train loss:0.0017497958461849615\n",
      "train loss:0.005613676291347909\n",
      "train loss:3.47268521836284e-05\n",
      "train loss:0.0031569965586592873\n",
      "train loss:0.003819889475475981\n",
      "train loss:0.0014616681224862852\n",
      "train loss:0.0007962437933137357\n",
      "train loss:0.009457732825750832\n",
      "train loss:0.0002481364081850692\n",
      "train loss:0.004448123715882689\n",
      "train loss:0.0004323877310313246\n",
      "train loss:0.002092740399118237\n",
      "train loss:0.010333061768470033\n",
      "train loss:0.0002558708608979483\n",
      "train loss:0.0007952676796574176\n",
      "train loss:0.002605327616176307\n",
      "train loss:0.0007859444061823509\n",
      "train loss:0.00011313451122240598\n",
      "train loss:0.0019294980224201109\n",
      "train loss:0.006907772504788351\n",
      "train loss:0.01779632846959227\n",
      "train loss:0.0003956311993502781\n",
      "train loss:0.004049949390085955\n",
      "train loss:0.0019810063299765127\n",
      "train loss:0.0021697232624090248\n",
      "train loss:0.0016326968402516806\n",
      "train loss:0.00017587823478981555\n",
      "train loss:0.000810846055445308\n",
      "train loss:0.0001016357160442774\n",
      "train loss:0.028387847546717276\n",
      "train loss:0.009228380993040814\n",
      "train loss:0.002674259344643219\n",
      "train loss:9.002937271294151e-05\n",
      "train loss:0.003166257447481863\n",
      "train loss:0.0009657761165148098\n",
      "train loss:0.000917521628054149\n",
      "train loss:0.0013394960824634294\n",
      "train loss:0.013914477608572234\n",
      "train loss:0.0012695564403193784\n",
      "train loss:0.0007970784275205808\n",
      "train loss:0.0004523888347973647\n",
      "train loss:0.00029384324048790814\n",
      "train loss:0.00042395911352703685\n",
      "train loss:0.0012234200464004367\n",
      "train loss:0.011330643478486193\n",
      "train loss:0.013706502885005595\n",
      "train loss:0.0036081681609577538\n",
      "train loss:0.0001762021009018835\n",
      "train loss:0.00017854481666357375\n",
      "train loss:0.00523574534596408\n",
      "train loss:0.00014209776388476628\n",
      "train loss:0.0016181306242161147\n",
      "train loss:7.001851938313618e-05\n",
      "train loss:0.0007567305804374335\n",
      "train loss:0.0012856831225304748\n",
      "train loss:0.0004139680259931198\n",
      "train loss:0.003641739970215754\n",
      "train loss:0.0008183450230801595\n",
      "train loss:0.0006427608185531608\n",
      "train loss:0.0007205672446849131\n",
      "train loss:0.001616140790613463\n",
      "train loss:0.001142077619023344\n",
      "train loss:0.0004552843886149966\n",
      "train loss:0.0006742846440715608\n",
      "train loss:0.00045581046707540067\n",
      "train loss:0.0013633897641918882\n",
      "train loss:0.00024009534954397892\n",
      "train loss:0.0035071951032312598\n",
      "train loss:0.010967442774750605\n",
      "train loss:0.00040547937563709883\n",
      "train loss:0.0021724025305648173\n",
      "train loss:0.002722587503307331\n",
      "train loss:0.0003252847550869275\n",
      "train loss:0.00010391299458837595\n",
      "train loss:0.002640537995203741\n",
      "train loss:0.003476308678014256\n",
      "train loss:0.00011381138170410054\n",
      "train loss:0.003966990907447599\n",
      "train loss:0.0010274585355580653\n",
      "train loss:0.0013846839929238428\n",
      "train loss:0.007631504845538278\n",
      "train loss:0.0010181499787424182\n",
      "train loss:0.0024792901523030433\n",
      "train loss:6.557710039615727e-05\n",
      "train loss:5.4067691394059845e-05\n",
      "train loss:0.0013826883246556066\n",
      "train loss:0.00017797077799121174\n",
      "train loss:0.0022226099131636857\n",
      "train loss:0.0008890381457482454\n",
      "train loss:0.0001596688732104664\n",
      "train loss:0.0014748553576017175\n",
      "train loss:0.004492334766340895\n",
      "train loss:0.001407846205732105\n",
      "train loss:0.0005134642722463939\n",
      "train loss:0.00019417849208344028\n",
      "train loss:0.0029036880761429107\n",
      "train loss:0.00023762910854607854\n",
      "train loss:0.0003448950188451847\n",
      "train loss:0.00018193991404336332\n",
      "train loss:0.00025438881069161326\n",
      "train loss:0.0002944344919243308\n",
      "train loss:0.0017699101578316301\n",
      "train loss:0.009807704357106949\n",
      "train loss:0.002848742937487115\n",
      "train loss:0.002116121188128195\n",
      "train loss:0.0011078999784311608\n",
      "train loss:0.0011052505973567378\n",
      "train loss:0.00030926648766685985\n",
      "train loss:0.00022560400312968736\n",
      "train loss:0.003678697136175659\n",
      "train loss:0.001217846644018438\n",
      "train loss:0.0006579951023832667\n",
      "train loss:0.0003660400273713269\n",
      "train loss:0.0002860481800706276\n",
      "train loss:0.0014390026744074272\n",
      "train loss:0.007612326370388401\n",
      "train loss:0.0023923829305002196\n",
      "train loss:0.0007648553438340549\n",
      "train loss:0.0003293030949369189\n",
      "train loss:0.0004764853606509116\n",
      "train loss:0.00028048771666789067\n",
      "train loss:0.003066974508456844\n",
      "train loss:0.002771869757887228\n",
      "train loss:0.01625921413565235\n",
      "train loss:0.011487131223772581\n",
      "train loss:0.00017986370013344582\n",
      "train loss:0.00011060844143317432\n",
      "train loss:0.0002845749540741278\n",
      "train loss:0.00014314419437879742\n",
      "train loss:0.0001982953169067589\n",
      "train loss:0.00010040447844714934\n",
      "train loss:4.6601667885623587e-05\n",
      "train loss:0.00018463096478660423\n",
      "train loss:0.00013829183114393427\n",
      "train loss:0.00023598285944759686\n",
      "train loss:0.0006491510160176422\n",
      "train loss:0.00212925836713683\n",
      "train loss:0.0011642089541005283\n",
      "train loss:0.0008164882878888452\n",
      "train loss:0.00044547855455725723\n",
      "train loss:8.301870574208643e-05\n",
      "train loss:0.0005930585696905909\n",
      "train loss:0.0018197088179566533\n",
      "train loss:0.00046955998936398395\n",
      "train loss:0.005807676035227447\n",
      "train loss:0.0025366035005306205\n",
      "train loss:0.000406361907110293\n",
      "train loss:0.0022397964546702967\n",
      "train loss:0.0014758104977591387\n",
      "train loss:0.008327964166196897\n",
      "train loss:0.00018843981300794516\n",
      "train loss:0.00038334279763135794\n",
      "train loss:0.002251522957694867\n",
      "train loss:0.000501339843155939\n",
      "train loss:0.00029290048393356907\n",
      "train loss:0.0002606250722534129\n",
      "train loss:7.677281780838056e-05\n",
      "train loss:0.004573182050572839\n",
      "train loss:0.001486033735219043\n",
      "train loss:0.0002665961967917068\n",
      "train loss:0.00026712560717473253\n",
      "train loss:0.0004929736655555214\n",
      "train loss:3.34256854671431e-05\n",
      "train loss:0.0001484224689599334\n",
      "train loss:0.0015290749117310598\n",
      "train loss:0.002105144242399157\n",
      "train loss:0.0025100693094426457\n",
      "train loss:0.0004386304789802143\n",
      "train loss:0.001176306029023841\n",
      "train loss:0.0004265669893506506\n",
      "train loss:0.0006663544617005452\n",
      "train loss:0.005129705363867122\n",
      "train loss:0.00015074308285028705\n",
      "train loss:0.001910592824600574\n",
      "train loss:0.0006675612876135306\n",
      "train loss:0.00022338603586337673\n",
      "train loss:0.001393298094501072\n",
      "train loss:0.0009236750182179826\n",
      "train loss:0.00023934697619364432\n",
      "train loss:0.0006112700700063608\n",
      "train loss:0.000207960867415062\n",
      "train loss:0.0029245731950138625\n",
      "train loss:0.0002982698460369674\n",
      "train loss:0.0015537140392124877\n",
      "train loss:0.0015466212981128282\n",
      "train loss:0.0010773404354253039\n",
      "train loss:0.0030567376661586256\n",
      "train loss:0.0001051443129215401\n",
      "train loss:1.4573415430075612e-05\n",
      "train loss:0.00013743589585096976\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.0015087655433543839\n",
      "train loss:0.004780627472987925\n",
      "train loss:0.0014073577693893044\n",
      "train loss:0.0018096788751928918\n",
      "train loss:0.003918022863270269\n",
      "train loss:0.0008418152367699892\n",
      "train loss:0.0002732943730698356\n",
      "train loss:0.000406062253139865\n",
      "train loss:0.0072393863855335\n",
      "train loss:0.0017654368139786896\n",
      "train loss:0.00038436530966216875\n",
      "train loss:0.0012890931749047912\n",
      "train loss:0.0005977237788730841\n",
      "train loss:0.000601961528889993\n",
      "train loss:0.00044165335551678926\n",
      "train loss:0.0005345034006612396\n",
      "train loss:8.761786780101288e-05\n",
      "train loss:0.00025364437225930273\n",
      "train loss:0.002535345605318645\n",
      "train loss:0.0010481853986496483\n",
      "train loss:0.0021293415003157097\n",
      "train loss:0.0008612844429107174\n",
      "train loss:0.00035491982746023426\n",
      "train loss:0.00011747419746162982\n",
      "train loss:0.00029637098193669586\n",
      "train loss:0.0011519272381961606\n",
      "train loss:0.0010111739260838003\n",
      "train loss:0.00015180871530099207\n",
      "train loss:0.0017629612957360135\n",
      "train loss:0.0025611127111955833\n",
      "train loss:0.00020460768189323026\n",
      "train loss:0.00019457846657823397\n",
      "train loss:0.0007080277012339298\n",
      "train loss:0.0009256837251420207\n",
      "train loss:0.0013822600818132879\n",
      "train loss:0.005454446744641484\n",
      "train loss:7.950820468820981e-05\n",
      "train loss:0.0010617238012320001\n",
      "train loss:0.00042002016661284294\n",
      "train loss:0.0009751470110349136\n",
      "train loss:3.0718816388414526e-05\n",
      "train loss:0.00035947848983421056\n",
      "train loss:0.00023243473983970884\n",
      "train loss:0.00011495359439327623\n",
      "train loss:0.0006986183696290997\n",
      "train loss:0.0010031651256693262\n",
      "train loss:9.28114036486558e-05\n",
      "train loss:0.0017725761065677697\n",
      "train loss:0.0014230275246039344\n",
      "train loss:0.0006193163625682137\n",
      "train loss:0.0003696385889506625\n",
      "train loss:0.0016680806459519095\n",
      "train loss:0.0007521782983594529\n",
      "train loss:0.0015565088279012533\n",
      "train loss:0.0004988762360611901\n",
      "train loss:0.0009241156221717716\n",
      "train loss:0.011943107398141552\n",
      "train loss:0.0010681697396874433\n",
      "train loss:0.0008732804914057538\n",
      "train loss:0.00037773889431421613\n",
      "train loss:1.3723029631706382e-05\n",
      "train loss:0.0008018592665207748\n",
      "train loss:0.005482679761269755\n",
      "train loss:0.001396138767965059\n",
      "train loss:7.059309732488289e-05\n",
      "train loss:0.0017385111403275494\n",
      "train loss:0.0032852311674365286\n",
      "train loss:0.0006476874215738883\n",
      "train loss:0.0017420607926287215\n",
      "train loss:0.00324214738060207\n",
      "train loss:0.0006382716410607995\n",
      "train loss:0.00045471261077773115\n",
      "train loss:0.00467487729403197\n",
      "train loss:0.0008116577715628127\n",
      "train loss:0.00022774061402597689\n",
      "train loss:0.004311897869618336\n",
      "train loss:0.0001524295030815104\n",
      "train loss:0.0011599261652616736\n",
      "train loss:0.0018777933764130474\n",
      "train loss:0.0026841582704008036\n",
      "train loss:0.0005865166920880132\n",
      "train loss:0.0008690076009516945\n",
      "train loss:0.00041034091373264194\n",
      "train loss:0.00016731298887254892\n",
      "train loss:0.0009566602419402827\n",
      "train loss:0.0003013316322428644\n",
      "train loss:0.0006322245957747681\n",
      "train loss:9.89907793887467e-05\n",
      "train loss:0.0005619503577818594\n",
      "train loss:0.0023291226039739276\n",
      "train loss:0.01371102556914529\n",
      "train loss:0.002327315924497867\n",
      "train loss:0.001019859516082942\n",
      "train loss:0.0002331542710010603\n",
      "train loss:0.001301383056666994\n",
      "train loss:5.4724947701630625e-05\n",
      "train loss:0.003752765867090947\n",
      "train loss:0.0014595377540764275\n",
      "train loss:0.002225248997436503\n",
      "train loss:0.00025421248524622837\n",
      "train loss:0.0002315504705034431\n",
      "train loss:0.0025392741029619187\n",
      "train loss:0.00018494669435862918\n",
      "train loss:0.001101301401525123\n",
      "train loss:0.00015868134873064623\n",
      "train loss:0.0021192421829640557\n",
      "train loss:0.0012319170247866377\n",
      "train loss:0.0053007794239930805\n",
      "train loss:0.00019507381220664963\n",
      "train loss:0.0005155003205387942\n",
      "train loss:0.00827847670412767\n",
      "train loss:0.005654536396210196\n",
      "train loss:0.006689432247623911\n",
      "train loss:0.0009075146284654634\n",
      "train loss:0.00022806892873122428\n",
      "train loss:0.007595530510192148\n",
      "train loss:0.00018571951722509485\n",
      "train loss:0.00014197902781665225\n",
      "train loss:0.0005155909343046697\n",
      "train loss:0.0009740888143855893\n",
      "train loss:0.0002078427536695002\n",
      "train loss:0.0016638820151121134\n",
      "train loss:0.0030362464295020236\n",
      "train loss:0.00020049063501883385\n",
      "train loss:0.0027846189370233985\n",
      "train loss:0.0027168233375970564\n",
      "train loss:0.0005990662045677577\n",
      "train loss:0.0020082931595184765\n",
      "train loss:0.0028848977608849236\n",
      "train loss:0.0008756687547313\n",
      "train loss:0.0007631911286147099\n",
      "train loss:0.0008850486708175552\n",
      "train loss:0.001026115959805956\n",
      "train loss:0.003747363004091015\n",
      "train loss:0.00210985493453295\n",
      "train loss:0.0023260866364128445\n",
      "train loss:0.00028183765198923794\n",
      "train loss:0.0005267003104307832\n",
      "train loss:0.0006862727871207516\n",
      "train loss:0.0012542939311386081\n",
      "train loss:0.0001729205578826428\n",
      "train loss:0.0007570817542492234\n",
      "train loss:6.234551098035959e-05\n",
      "train loss:0.0013303323303694434\n",
      "train loss:0.001643481237570825\n",
      "train loss:0.00264966133112794\n",
      "train loss:0.0017821767365983016\n",
      "train loss:0.003705231575989962\n",
      "train loss:0.0017009891174382603\n",
      "train loss:0.0020737877853344465\n",
      "train loss:0.0009291980005659142\n",
      "train loss:0.0022473528959411244\n",
      "train loss:0.0001895644759754382\n",
      "train loss:0.00038125147664114884\n",
      "train loss:0.0007825775919300587\n",
      "train loss:0.001135219444118924\n",
      "train loss:0.0012381658825529362\n",
      "train loss:0.0001143840785519147\n",
      "train loss:0.0002538957478222124\n",
      "train loss:0.0020466439150799683\n",
      "train loss:0.003221060817547784\n",
      "train loss:1.8324427808778812e-05\n",
      "train loss:0.0002546534951691452\n",
      "train loss:0.0006119746236212609\n",
      "train loss:0.00012968395012772854\n",
      "train loss:0.0012340384218892917\n",
      "train loss:0.0009416143767113709\n",
      "train loss:0.0009335686053262453\n",
      "train loss:0.0002313631068189348\n",
      "train loss:0.0001275559274256987\n",
      "train loss:0.002112057519108279\n",
      "train loss:0.001083396098671238\n",
      "train loss:0.0026603920602242485\n",
      "train loss:0.0006316911269377531\n",
      "train loss:0.0021046816777513123\n",
      "train loss:0.0006564555958078162\n",
      "train loss:0.00017182645133463785\n",
      "train loss:0.001930659298547185\n",
      "train loss:0.0008674470905222589\n",
      "train loss:0.0012125323949580278\n",
      "train loss:0.0003312389117368629\n",
      "train loss:0.0009821770051997203\n",
      "train loss:2.7515763568023683e-05\n",
      "train loss:0.0004998925991158505\n",
      "train loss:0.0012873815551504315\n",
      "train loss:0.0013641957244204545\n",
      "train loss:0.0015805763673105513\n",
      "train loss:0.0005232716190544312\n",
      "train loss:0.001891542559724564\n",
      "train loss:0.0031408872123585624\n",
      "train loss:0.0017285546269843576\n",
      "train loss:0.00042419811135886075\n",
      "train loss:0.00011548132495841243\n",
      "train loss:0.007108964317389242\n",
      "train loss:0.0016413211338150845\n",
      "train loss:0.000734595073183663\n",
      "train loss:0.0022703435726136555\n",
      "train loss:0.00059008398522209\n",
      "train loss:0.00993344885491497\n",
      "train loss:0.001131102696477032\n",
      "train loss:0.004425620514670262\n",
      "train loss:0.002906795243829343\n",
      "train loss:0.0017346839572072753\n",
      "train loss:0.0014616493884376863\n",
      "train loss:0.001031060803455674\n",
      "train loss:0.001024845808186272\n",
      "train loss:0.00047107082183192145\n",
      "train loss:0.0006994166440557927\n",
      "train loss:0.0011960425102411692\n",
      "train loss:0.00017986794506157672\n",
      "train loss:0.00167764837643612\n",
      "train loss:0.0002858308796193329\n",
      "train loss:0.018664447704970572\n",
      "train loss:0.00031679726464811214\n",
      "train loss:0.00227727692742954\n",
      "train loss:0.0014174564094389377\n",
      "train loss:0.0016582837967220809\n",
      "train loss:3.389243621167567e-05\n",
      "train loss:0.0037524495731738328\n",
      "train loss:0.0001326451466800195\n",
      "train loss:1.0897030007307707e-05\n",
      "train loss:0.002813062295565115\n",
      "train loss:0.0003892004269931938\n",
      "train loss:0.03936039091160093\n",
      "train loss:0.00020456585387830991\n",
      "train loss:0.002377753095177334\n",
      "train loss:0.006102453325804239\n",
      "train loss:0.0003606840342584609\n",
      "train loss:0.0015580041693275322\n",
      "train loss:0.0011994819224633118\n",
      "train loss:0.000798913229137478\n",
      "train loss:0.00013849439137198375\n",
      "train loss:0.0007346248969704886\n",
      "train loss:0.0016915788277390973\n",
      "train loss:0.0023852486461357226\n",
      "train loss:0.0008386864947579529\n",
      "train loss:0.00026992701473035614\n",
      "train loss:0.0021356141888998546\n",
      "train loss:0.00026444831861279617\n",
      "train loss:0.00023290982072267423\n",
      "train loss:7.149511447125579e-05\n",
      "train loss:0.00022647085537247927\n",
      "train loss:0.0013205695511411238\n",
      "train loss:0.0004275008984206258\n",
      "train loss:0.0007290419704103515\n",
      "train loss:0.012299049527013281\n",
      "train loss:0.0010642926194498598\n",
      "train loss:4.963571337709969e-05\n",
      "train loss:0.0005762445426717505\n",
      "train loss:0.000532871363086979\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.0011602434271995431\n",
      "train loss:0.00021282658836957707\n",
      "train loss:0.009916209121614785\n",
      "train loss:0.0022920247521795484\n",
      "train loss:0.0020540332853267508\n",
      "train loss:0.0003163275231550581\n",
      "train loss:0.00015267797862119234\n",
      "train loss:0.0005145413968797251\n",
      "train loss:0.002506006492211075\n",
      "train loss:0.00036596560718799785\n",
      "train loss:0.0007895174662277505\n",
      "train loss:0.0024402978521786407\n",
      "train loss:0.000814751050523147\n",
      "train loss:0.006595780325252749\n",
      "train loss:0.0026932954689360073\n",
      "train loss:0.005555171384304686\n",
      "train loss:0.0009105054102849519\n",
      "train loss:0.0012797755831234403\n",
      "train loss:0.0021618720574200436\n",
      "train loss:0.001278549121671112\n",
      "train loss:0.00013153539228118367\n",
      "train loss:0.00026456040947731805\n",
      "train loss:0.00010597054390883787\n",
      "train loss:0.0029942849079340143\n",
      "train loss:0.00010244483428359521\n",
      "train loss:0.0015850034108861215\n",
      "train loss:0.0024257177514383117\n",
      "train loss:0.001223300801069912\n",
      "=== epoch:19, train acc:0.997, test acc:0.987 ===\n",
      "train loss:0.005050430326556918\n",
      "train loss:0.0014907055063938923\n",
      "train loss:0.0005706724381941133\n",
      "train loss:0.0020947331047660007\n",
      "train loss:0.0001775975770390197\n",
      "train loss:0.001579935185286823\n",
      "train loss:0.00015747559206066283\n",
      "train loss:0.000676279666189004\n",
      "train loss:0.0020880634251438605\n",
      "train loss:0.0006517634276273908\n",
      "train loss:0.0002856341220605176\n",
      "train loss:0.006119478522990007\n",
      "train loss:0.0010140891298626193\n",
      "train loss:0.0001924357056316279\n",
      "train loss:0.0021581326120110418\n",
      "train loss:0.0008216600677319447\n",
      "train loss:0.007315402350401854\n",
      "train loss:0.0003080102890051027\n",
      "train loss:0.00310964703985123\n",
      "train loss:0.0021674484254161994\n",
      "train loss:0.0025763305633366355\n",
      "train loss:0.0001004359220785267\n",
      "train loss:0.0009701174208359766\n",
      "train loss:6.245677974139394e-05\n",
      "train loss:0.00012573438716025057\n",
      "train loss:0.0008099109393547077\n",
      "train loss:0.0006660412307983442\n",
      "train loss:0.0009082229892379704\n",
      "train loss:0.006664678925877337\n",
      "train loss:0.0028815240210903147\n",
      "train loss:0.000417175253099415\n",
      "train loss:0.0006863040844843514\n",
      "train loss:0.00019726769983514946\n",
      "train loss:0.0004862739077748203\n",
      "train loss:0.00010857092926837759\n",
      "train loss:0.00019565451526500595\n",
      "train loss:0.0020726218093977647\n",
      "train loss:0.00019298494006753545\n",
      "train loss:0.035997029006375664\n",
      "train loss:0.00111061341885725\n",
      "train loss:0.0015524006560205534\n",
      "train loss:0.010949003514479375\n",
      "train loss:0.00026421509535541295\n",
      "train loss:0.01620542593101929\n",
      "train loss:0.00218489773079463\n",
      "train loss:0.00017987252024218335\n",
      "train loss:0.0016332809356227535\n",
      "train loss:0.00036478425647008627\n",
      "train loss:0.0016220139185620483\n",
      "train loss:0.003145070667268008\n",
      "train loss:9.1623576414435e-05\n",
      "train loss:0.0002570426145015313\n",
      "train loss:0.00042028349503409816\n",
      "train loss:4.0547741605107676e-05\n",
      "train loss:0.00016784088392606886\n",
      "train loss:0.0017774709918941297\n",
      "train loss:0.003416883290551737\n",
      "train loss:0.0012569549879560948\n",
      "train loss:0.004148227414904603\n",
      "train loss:0.0013730585898023345\n",
      "train loss:0.00013937921713423173\n",
      "train loss:0.0007817965485553989\n",
      "train loss:0.00139354501314797\n",
      "train loss:0.0003569364039723004\n",
      "train loss:0.0017541369422811467\n",
      "train loss:0.005512281985162212\n",
      "train loss:0.006245572661502803\n",
      "train loss:0.004856336640557679\n",
      "train loss:0.010372180610941133\n",
      "train loss:0.0003104821759829696\n",
      "train loss:0.0006429992034653868\n",
      "train loss:0.0007514678359733237\n",
      "train loss:0.00018070935938539976\n",
      "train loss:0.0022344535554798695\n",
      "train loss:0.0007789963153054182\n",
      "train loss:0.0015199817333193333\n",
      "train loss:0.0003546488180583496\n",
      "train loss:0.0008387528943431041\n",
      "train loss:0.0001295280493406472\n",
      "train loss:0.002052105290922755\n",
      "train loss:0.0005174132660905404\n",
      "train loss:0.0002874831875044259\n",
      "train loss:0.002869497695624317\n",
      "train loss:0.0026778919091970652\n",
      "train loss:0.0009522926188014298\n",
      "train loss:0.00035771308917624723\n",
      "train loss:0.0012522958499046092\n",
      "train loss:0.0013304797916828608\n",
      "train loss:0.002701478689848022\n",
      "train loss:0.00023496281432471505\n",
      "train loss:0.0017022500363669869\n",
      "train loss:0.0006620051539271985\n",
      "train loss:0.0006974964347698082\n",
      "train loss:0.0006542995079075831\n",
      "train loss:0.0012956698229424763\n",
      "train loss:0.0009038600382188913\n",
      "train loss:0.00043620753800696204\n",
      "train loss:0.0017625393854029474\n",
      "train loss:0.0009223888560868411\n",
      "train loss:0.0004988463675048952\n",
      "train loss:0.00015159150000533989\n",
      "train loss:0.0018395168096292044\n",
      "train loss:0.0014054707924164617\n",
      "train loss:0.001397103783036375\n",
      "train loss:5.038641041967222e-05\n",
      "train loss:5.881850415436442e-05\n",
      "train loss:0.0013766873196055848\n",
      "train loss:0.002110796076919827\n",
      "train loss:0.0003646685598084139\n",
      "train loss:0.0006883849117084005\n",
      "train loss:0.00467503891821816\n",
      "train loss:0.0026702456262357637\n",
      "train loss:0.0020589835101338474\n",
      "train loss:0.0019033923368809824\n",
      "train loss:0.0009725586064695609\n",
      "train loss:0.0006641130142572217\n",
      "train loss:0.0006820350157274665\n",
      "train loss:0.00011140823451167505\n",
      "train loss:0.0018086566868745816\n",
      "train loss:0.0041473049931837315\n",
      "train loss:0.004585639307955187\n",
      "train loss:0.00011226537016186893\n",
      "train loss:0.00025338286395308287\n",
      "train loss:0.00017705672670884916\n",
      "train loss:0.0011448320463905007\n",
      "train loss:0.0026322230855505228\n",
      "train loss:0.0003346014131570652\n",
      "train loss:0.00018871539549982118\n",
      "train loss:0.0006891693803644298\n",
      "train loss:0.000856063763066379\n",
      "train loss:0.00027147559800372816\n",
      "train loss:0.0013176857157615835\n",
      "train loss:0.0004547044728540562\n",
      "train loss:0.00031750366475102166\n",
      "train loss:0.0008679320301690998\n",
      "train loss:0.001021414263523096\n",
      "train loss:0.00018749448073254353\n",
      "train loss:0.0006394032386953956\n",
      "train loss:8.643337014115586e-05\n",
      "train loss:0.0005086356377604299\n",
      "train loss:0.0009623418260318048\n",
      "train loss:0.0004190406846010182\n",
      "train loss:0.0004867129612253577\n",
      "train loss:0.0008600665260850037\n",
      "train loss:0.0025913829151885497\n",
      "train loss:0.00011636835497062456\n",
      "train loss:0.00043923811998854476\n",
      "train loss:0.003474803856305224\n",
      "train loss:0.0004610897555221118\n",
      "train loss:3.132025513563931e-05\n",
      "train loss:0.0010014854542785162\n",
      "train loss:0.0019778515600903396\n",
      "train loss:0.0016602043821224946\n",
      "train loss:0.004120297906953651\n",
      "train loss:0.0014455040572108376\n",
      "train loss:6.041619294828841e-05\n",
      "train loss:0.0006304497142372578\n",
      "train loss:0.0002476620774641416\n",
      "train loss:0.00014601540631174433\n",
      "train loss:0.0025694615593731514\n",
      "train loss:0.0011066234017010621\n",
      "train loss:0.0010263235421573247\n",
      "train loss:0.00033134227576339783\n",
      "train loss:0.00010588296937443295\n",
      "train loss:0.00018732744280936176\n",
      "train loss:0.0007428518526742109\n",
      "train loss:5.574564645652015e-05\n",
      "train loss:0.0015100369263869797\n",
      "train loss:0.0003556505036119361\n",
      "train loss:0.0007009805256763588\n",
      "train loss:0.001721534940219569\n",
      "train loss:0.00039362095927985186\n",
      "train loss:0.00016825493844276832\n",
      "train loss:0.0013803667490089196\n",
      "train loss:0.0004416177671188535\n",
      "train loss:0.0007553918819448284\n",
      "train loss:0.000585324571441474\n",
      "train loss:0.0007111824240732458\n",
      "train loss:0.0008357617084034574\n",
      "train loss:0.00048425592883341665\n",
      "train loss:5.901016404013702e-05\n",
      "train loss:0.0013007922826844287\n",
      "train loss:0.0001263753583883373\n",
      "train loss:0.00023531544881989758\n",
      "train loss:0.0005545449916494145\n",
      "train loss:0.0013486362651140738\n",
      "train loss:3.751890109221749e-05\n",
      "train loss:0.00032087406511491267\n",
      "train loss:0.0001171152249042074\n",
      "train loss:0.00025010009453377735\n",
      "train loss:8.020564822023721e-05\n",
      "train loss:0.00037032735987152987\n",
      "train loss:0.0006811248723959008\n",
      "train loss:0.00013587539172766816\n",
      "train loss:0.0002334154775231908\n",
      "train loss:0.00018939903210069144\n",
      "train loss:0.0030337910082548054\n",
      "train loss:0.00010641963170121343\n",
      "train loss:0.00023418656937470968\n",
      "train loss:0.0028213914886277445\n",
      "train loss:0.00019457486398661444\n",
      "train loss:0.0005786313283891381\n",
      "train loss:0.0012962669788575587\n",
      "train loss:0.00046696169924581685\n",
      "train loss:0.0011596253050146072\n",
      "train loss:5.411334241464289e-05\n",
      "train loss:0.0015170726069082604\n",
      "train loss:0.00156444665964766\n",
      "train loss:2.6428884658539358e-05\n",
      "train loss:8.346604607399559e-05\n",
      "train loss:0.0013106315102321996\n",
      "train loss:0.0023282179659266282\n",
      "train loss:0.00025061144377469253\n",
      "train loss:9.9306771063007e-05\n",
      "train loss:0.0003402293211197788\n",
      "train loss:0.0007265123373266057\n",
      "train loss:0.0002461348598966951\n",
      "train loss:0.0015964890467676629\n",
      "train loss:0.005545904317463565\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.00011781712740824032\n",
      "train loss:0.0024121760740345778\n",
      "train loss:0.0001326514210687828\n",
      "train loss:0.0016098862041074335\n",
      "train loss:0.0015846189079887706\n",
      "train loss:0.00020211494776119362\n",
      "train loss:0.00024646935001482027\n",
      "train loss:4.165857132046115e-05\n",
      "train loss:0.0018696818100033836\n",
      "train loss:0.000613231166025305\n",
      "train loss:0.001753150206293529\n",
      "train loss:0.0010207029392117802\n",
      "train loss:0.001226880926177277\n",
      "train loss:0.001934155744875881\n",
      "train loss:0.0006257258380352146\n",
      "train loss:0.0005507257659041423\n",
      "train loss:0.0002185346284263069\n",
      "train loss:0.00015941945800159368\n",
      "train loss:0.0005875314553497387\n",
      "train loss:0.00033002581896489423\n",
      "train loss:0.0023938461962071506\n",
      "train loss:0.0012580584931059055\n",
      "train loss:0.0014968647538792998\n",
      "train loss:0.0007300990301841169\n",
      "train loss:0.0004470172208862341\n",
      "train loss:0.00014011353803014868\n",
      "train loss:0.0001963254598693228\n",
      "train loss:0.0018974698380871263\n",
      "train loss:0.00011607356006410345\n",
      "train loss:0.0022664199059283146\n",
      "train loss:0.0005449977907742648\n",
      "train loss:0.0011237388815387665\n",
      "train loss:0.001954966611406486\n",
      "train loss:0.00030980339607439733\n",
      "train loss:0.0019176398021677982\n",
      "train loss:0.000301367433318292\n",
      "train loss:0.0013106095497257262\n",
      "train loss:0.0006826938138533128\n",
      "train loss:0.000167841380271582\n",
      "train loss:0.0013689598181984006\n",
      "train loss:2.9645730995008155e-05\n",
      "train loss:0.0013232943359577267\n",
      "train loss:0.0005696403337858761\n",
      "train loss:8.062355571846291e-05\n",
      "train loss:0.0046453950054646895\n",
      "train loss:0.0014624628258047587\n",
      "train loss:5.084858741110595e-05\n",
      "train loss:0.0009410779054493243\n",
      "train loss:0.004113826133728644\n",
      "train loss:0.0014019532549259263\n",
      "train loss:0.0022435489374132084\n",
      "train loss:3.627627997777752e-05\n",
      "train loss:0.003315203064350876\n",
      "train loss:5.536437536311171e-05\n",
      "train loss:4.6113982950600896e-05\n",
      "train loss:0.00011341469873333844\n",
      "train loss:0.0015784454507529655\n",
      "train loss:0.00015944201456473558\n",
      "train loss:0.00039407354501564\n",
      "train loss:0.0016669709982398493\n",
      "train loss:0.0002799965159164103\n",
      "train loss:0.0009129226905346743\n",
      "train loss:0.0002281245823549728\n",
      "train loss:0.0006160884871082594\n",
      "train loss:0.0016513941041111544\n",
      "train loss:0.0032457710976611293\n",
      "train loss:0.005738475396556994\n",
      "train loss:0.0005702241623381893\n",
      "train loss:0.0010285345871697887\n",
      "train loss:0.00021367928711613044\n",
      "train loss:0.0010156211658572938\n",
      "train loss:0.007751551767133342\n",
      "train loss:0.0022222104076139956\n",
      "train loss:0.0010627886194575719\n",
      "train loss:0.0005062413084768912\n",
      "train loss:0.0009185736383397029\n",
      "train loss:0.0001606537438011096\n",
      "train loss:0.0009079822450939942\n",
      "train loss:0.0004525564834027621\n",
      "train loss:0.0039209677441778895\n",
      "train loss:0.000804937448266733\n",
      "train loss:0.013813955026372608\n",
      "train loss:0.0013378195119789255\n",
      "train loss:0.001454218025314042\n",
      "train loss:0.0003578982263725838\n",
      "train loss:0.004922746415053365\n",
      "train loss:0.0006306227163955526\n",
      "train loss:6.39306649274115e-05\n",
      "train loss:0.00043534504497506085\n",
      "train loss:0.00033149817600594984\n",
      "train loss:0.00035751702123909735\n",
      "train loss:6.090429595064905e-05\n",
      "train loss:0.0005956333768077862\n",
      "train loss:0.0007495377167305397\n",
      "train loss:0.00032320487300293834\n",
      "train loss:0.0005159139207216109\n",
      "train loss:0.00023600817443916142\n",
      "train loss:0.002528011089785785\n",
      "train loss:0.00025879938007831435\n",
      "train loss:0.00010787923820633874\n",
      "train loss:0.00011280013454524538\n",
      "train loss:0.0008049251854876809\n",
      "train loss:0.0003245638335921892\n",
      "train loss:0.002860303728248977\n",
      "train loss:0.0003940001006011039\n",
      "train loss:0.0002455289108754729\n",
      "train loss:0.00015916171173338127\n",
      "train loss:2.2158292627740606e-05\n",
      "train loss:5.5314585419276145e-05\n",
      "train loss:0.0019449477948726107\n",
      "train loss:9.434576879507822e-05\n",
      "train loss:0.00013717488052391875\n",
      "train loss:1.0277371911392025e-05\n",
      "train loss:0.00020777288216713378\n",
      "train loss:0.0002028494356873068\n",
      "train loss:0.0004450169101197471\n",
      "train loss:3.377136674529735e-05\n",
      "train loss:0.0010445565408107795\n",
      "train loss:0.0019788894936380082\n",
      "train loss:9.479686056549506e-05\n",
      "train loss:0.001283971972572026\n",
      "train loss:0.00014529424867855455\n",
      "train loss:0.001171230568476411\n",
      "train loss:6.248243908384704e-05\n",
      "train loss:0.0003340026131589949\n",
      "train loss:0.0010464935141481513\n",
      "train loss:2.358361190216288e-05\n",
      "train loss:1.7010202615632528e-06\n",
      "train loss:0.0014087950522530992\n",
      "train loss:0.004672880698280506\n",
      "train loss:0.0016732214467234398\n",
      "train loss:0.00010593171227296615\n",
      "train loss:0.0016603487558839209\n",
      "train loss:0.0001422978487440381\n",
      "train loss:0.001104312158940829\n",
      "train loss:0.00197790642176071\n",
      "train loss:0.00035763862880845693\n",
      "train loss:0.016055126966136125\n",
      "train loss:0.0021075355747390855\n",
      "train loss:4.043237035798889e-05\n",
      "train loss:0.0004871689718848428\n",
      "train loss:0.00034427089823257874\n",
      "train loss:0.0008382202308127932\n",
      "train loss:0.0021648899958391886\n",
      "train loss:0.00027356983640855514\n",
      "train loss:0.0007077650205903184\n",
      "train loss:0.0008952944268484296\n",
      "train loss:5.247373222006199e-05\n",
      "train loss:3.782221993624054e-05\n",
      "train loss:0.0001875309199613689\n",
      "train loss:0.0013022221337818595\n",
      "train loss:0.0014249136088388624\n",
      "train loss:0.0004457697826398682\n",
      "train loss:0.0035933661196210363\n",
      "train loss:0.00048103135703901937\n",
      "train loss:0.0005547259498550296\n",
      "train loss:7.228920185094655e-05\n",
      "train loss:0.00015605403957105496\n",
      "train loss:0.0007101372491681156\n",
      "train loss:0.0001268839812703904\n",
      "train loss:7.689791585693252e-05\n",
      "train loss:5.2059455251141503e-05\n",
      "train loss:0.00045208183742612954\n",
      "train loss:0.00026781906534254597\n",
      "train loss:0.00015077491756108915\n",
      "train loss:0.0009786820201766195\n",
      "train loss:1.336996503977449e-05\n",
      "train loss:0.003292399731661602\n",
      "train loss:0.0015251870096611331\n",
      "train loss:5.355659694407402e-05\n",
      "train loss:0.00011614842702151923\n",
      "train loss:0.0004402336043935912\n",
      "train loss:0.00012142188618060073\n",
      "train loss:5.054237169452946e-05\n",
      "train loss:0.0001050650923391312\n",
      "train loss:0.0016283582235597574\n",
      "train loss:0.00010790110528118048\n",
      "train loss:7.954090739655796e-05\n",
      "train loss:0.0021430851003452337\n",
      "train loss:5.456483963536341e-05\n",
      "train loss:0.0004940140357916235\n",
      "train loss:6.62543008305395e-05\n",
      "train loss:0.001205681906014633\n",
      "train loss:0.00022918227436343337\n",
      "train loss:0.0004180431719362612\n",
      "train loss:0.004654809856069926\n",
      "train loss:0.0003745813151456153\n",
      "train loss:0.003490708383320053\n",
      "train loss:0.0002632125871820944\n",
      "train loss:0.0014590941005480573\n",
      "train loss:0.00037143453433301265\n",
      "train loss:0.0004378226319417347\n",
      "train loss:0.0001601569728652215\n",
      "train loss:0.0002684394075193777\n",
      "train loss:0.003146671236612687\n",
      "train loss:1.4611454833696576e-05\n",
      "train loss:0.003505522905144222\n",
      "train loss:0.00046828136912064006\n",
      "train loss:0.0003162005677518164\n",
      "train loss:0.0011756249748929386\n",
      "train loss:0.0002803372423159891\n",
      "train loss:0.0006382022419772739\n",
      "train loss:0.014186541807055633\n",
      "train loss:0.0016164857782867\n",
      "train loss:0.002671462915940362\n",
      "train loss:0.0004091647394846565\n",
      "train loss:0.0033516234154206044\n",
      "train loss:0.004788799407140652\n",
      "train loss:0.0014725888754545582\n",
      "train loss:0.00021716435209630943\n",
      "train loss:0.0010264959536674329\n",
      "train loss:6.43412898170885e-05\n",
      "train loss:0.00012394870801444238\n",
      "train loss:0.000993271626614986\n",
      "train loss:0.0020012928547606993\n",
      "train loss:0.0004121704729293503\n",
      "train loss:0.0001126312847502517\n",
      "train loss:0.0006873366292102955\n",
      "train loss:0.000194869877930643\n",
      "train loss:6.464583328573169e-05\n",
      "train loss:0.0009528764927975901\n",
      "train loss:0.0003309763027201848\n",
      "train loss:0.00034132284612900597\n",
      "train loss:8.541284174113288e-05\n",
      "train loss:0.0026941738389534647\n",
      "train loss:7.389048365475477e-05\n",
      "train loss:0.0032815775079584387\n",
      "train loss:0.0007069200000043328\n",
      "train loss:0.00020798229316024632\n",
      "train loss:0.00018153858784057794\n",
      "train loss:0.0021351387238959666\n",
      "train loss:9.361699510364988e-05\n",
      "train loss:0.00026976633272893\n",
      "train loss:0.0002534187930385773\n",
      "train loss:0.00043285201139111983\n",
      "train loss:0.000197288819010892\n",
      "train loss:0.0005988177248059198\n",
      "train loss:0.0006131257721404476\n",
      "train loss:0.00019047153484106355\n",
      "train loss:0.000880790567433901\n",
      "train loss:0.0002852240794769704\n",
      "train loss:0.0005639752493216897\n",
      "train loss:0.0011708588978043997\n",
      "train loss:4.8269477644267666e-05\n",
      "train loss:0.001881533125205176\n",
      "train loss:0.003556435030077977\n",
      "train loss:0.00011646510358893011\n",
      "train loss:0.0007158033393161847\n",
      "train loss:0.01911575526092144\n",
      "train loss:0.0010700873596057915\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.00021159242519373417\n",
      "train loss:0.001618703675746568\n",
      "train loss:0.000538978486771331\n",
      "train loss:0.00011412834654670582\n",
      "train loss:0.000937369212063638\n",
      "train loss:0.0002522815639923835\n",
      "train loss:5.7587989320395235e-05\n",
      "train loss:0.0015060783829242952\n",
      "train loss:0.0002044037023643649\n",
      "train loss:0.00044784007655955993\n",
      "train loss:0.0022517201579781362\n",
      "train loss:4.1301220771769806e-05\n",
      "train loss:0.0009286153945003836\n",
      "train loss:1.5070933781700676e-05\n",
      "train loss:0.0029586417217422173\n",
      "train loss:0.00180627609454775\n",
      "train loss:0.0037817739191902604\n",
      "train loss:0.00038425681850037303\n",
      "train loss:6.0225054802481414e-05\n",
      "train loss:9.67690635279217e-05\n",
      "train loss:0.0020363724698249826\n",
      "train loss:1.622290449262783e-05\n",
      "train loss:0.0003290355499545375\n",
      "train loss:0.0002473491522378773\n",
      "train loss:0.00232006084454131\n",
      "train loss:0.0017511506865676807\n",
      "train loss:0.0008627882655402037\n",
      "train loss:6.93600506715839e-05\n",
      "train loss:0.0055394440120296925\n",
      "train loss:0.00029380832299636463\n",
      "train loss:0.012215960108701834\n",
      "train loss:0.0009875669476604664\n",
      "train loss:5.576769577558328e-05\n",
      "train loss:0.005875643538378551\n",
      "train loss:0.0024598843242765534\n",
      "train loss:0.0004451264594176686\n",
      "train loss:0.00034300840229784077\n",
      "train loss:0.0038910581329052746\n",
      "train loss:0.00020906445823981333\n",
      "train loss:0.000660114897545283\n",
      "train loss:0.0009839194346834199\n",
      "train loss:0.0001561774549896062\n",
      "train loss:0.0008345140144085378\n",
      "train loss:0.0036426515553261507\n",
      "train loss:0.0030725964842796133\n",
      "train loss:8.09778312917759e-05\n",
      "train loss:0.00286338041458741\n",
      "train loss:0.00024064206972477633\n",
      "train loss:0.0005631222502526734\n",
      "train loss:0.00038584435263910394\n",
      "train loss:0.0015534571191950152\n",
      "train loss:0.0017282202469697627\n",
      "train loss:0.0007466809452397052\n",
      "train loss:2.2603185234709228e-05\n",
      "train loss:0.0012896899682460963\n",
      "train loss:0.0034256860807526735\n",
      "train loss:0.0008230736094498088\n",
      "train loss:0.0008799849094362765\n",
      "train loss:0.0017503943282654645\n",
      "train loss:0.005121712583546331\n",
      "train loss:0.0007686126718867089\n",
      "train loss:0.002244067721761861\n",
      "train loss:7.888013150641897e-05\n",
      "train loss:0.0004808366622300704\n",
      "train loss:0.0016824215840581444\n",
      "train loss:0.001040276381560381\n",
      "train loss:0.0012393402744416914\n",
      "train loss:0.0019370046842074815\n",
      "train loss:0.0013335093662601675\n",
      "train loss:0.0017236831185534298\n",
      "train loss:0.0007706015386496512\n",
      "train loss:0.0018831590895335122\n",
      "train loss:0.00040344804500765824\n",
      "train loss:0.0011132278228418414\n",
      "train loss:0.00060894962156116\n",
      "train loss:0.0010208381749477879\n",
      "train loss:0.000420778935514226\n",
      "train loss:0.0010340752335043573\n",
      "train loss:0.0006797812252602911\n",
      "train loss:0.00014147852475138425\n",
      "train loss:0.00023720852501477984\n",
      "train loss:0.002548969126827721\n",
      "train loss:0.000260587462509205\n",
      "train loss:0.0020713670887808045\n",
      "train loss:0.00021396486716573416\n",
      "train loss:0.002196669591042718\n",
      "train loss:0.0025263260388089185\n",
      "train loss:0.0011917281763148204\n",
      "train loss:0.002990484150557046\n",
      "train loss:0.0003442134477393751\n",
      "train loss:0.00045626915528578\n",
      "train loss:0.0016631984054344354\n",
      "train loss:0.00016451604415203036\n",
      "train loss:0.0005567651500539163\n",
      "train loss:0.00017954281489115074\n",
      "train loss:0.000957248861269223\n",
      "train loss:0.002930263604829312\n",
      "train loss:0.002678336106910409\n",
      "train loss:0.0002453369862315623\n",
      "train loss:7.945166377986078e-05\n",
      "train loss:3.669022677009782e-05\n",
      "train loss:0.0012788633830970357\n",
      "train loss:0.0003121099205987151\n",
      "train loss:0.00016574495100541323\n",
      "train loss:0.002216658839992206\n",
      "train loss:0.0024983074074107813\n",
      "train loss:0.00042284652934090937\n",
      "train loss:0.0004968178233180165\n",
      "train loss:0.0002999973543397337\n",
      "train loss:0.0011685046882376044\n",
      "train loss:5.669741080791862e-05\n",
      "train loss:0.0006920342679411543\n",
      "train loss:8.989308791963868e-05\n",
      "train loss:0.001450543533199064\n",
      "train loss:0.001352817357628469\n",
      "train loss:0.0009212944801968328\n",
      "train loss:4.867436203204192e-05\n",
      "train loss:0.001298946687556626\n",
      "train loss:0.001077680598351044\n",
      "train loss:0.00024622390106275637\n",
      "train loss:0.002494608662931047\n",
      "train loss:0.0006139514539629801\n",
      "train loss:0.00041974525820355664\n",
      "train loss:0.0016818379759631736\n",
      "train loss:0.002780219068927348\n",
      "train loss:0.0006012538715635514\n",
      "train loss:0.0008776854251910638\n",
      "train loss:0.002533151137510094\n",
      "train loss:3.943014655893233e-05\n",
      "train loss:0.00258317096645535\n",
      "train loss:0.0016554359158813346\n",
      "=== epoch:20, train acc:0.999, test acc:0.985 ===\n",
      "train loss:0.0016050275633367852\n",
      "train loss:0.000723877624084403\n",
      "train loss:0.0014524218359627072\n",
      "train loss:5.866127102987487e-05\n",
      "train loss:0.008325069534650818\n",
      "train loss:0.00031317225973158917\n",
      "train loss:0.0005670181035914278\n",
      "train loss:0.0018659459464366473\n",
      "train loss:0.003546412124507467\n",
      "train loss:0.0013575641866170466\n",
      "train loss:0.010742206090249262\n",
      "train loss:0.0005076317176036041\n",
      "train loss:2.9578846980175137e-05\n",
      "train loss:0.00038437219352653395\n",
      "train loss:0.0030565957981078425\n",
      "train loss:0.006210667241953211\n",
      "train loss:0.0003469845632313743\n",
      "train loss:0.0007744230856294766\n",
      "train loss:0.00016363135551177558\n",
      "train loss:0.0006560819422570342\n",
      "train loss:0.0011915295426716504\n",
      "train loss:0.0009239073672843955\n",
      "train loss:0.0014321738669998507\n",
      "train loss:0.002014302282785555\n",
      "train loss:0.008436009945199684\n",
      "train loss:0.002586057333238634\n",
      "train loss:0.0038697478918549555\n",
      "train loss:0.00019075148871569654\n",
      "train loss:0.008744767830060111\n",
      "train loss:0.0006864114710421375\n",
      "train loss:0.000830664970556388\n",
      "train loss:0.005273143702326929\n",
      "train loss:0.000729647973823626\n",
      "train loss:0.001650093230822556\n",
      "train loss:0.0012489493638323398\n",
      "train loss:0.0018090950873566958\n",
      "train loss:0.003120435759093718\n",
      "train loss:0.0003698846466805587\n",
      "train loss:0.00270712331421052\n",
      "train loss:0.002373340458011501\n",
      "train loss:0.0005996418227605289\n",
      "train loss:0.00022803772240175113\n",
      "train loss:0.0012210080773994588\n",
      "train loss:0.0024567134714147637\n",
      "train loss:0.0006302642475615788\n",
      "train loss:0.0006159345728857815\n",
      "train loss:0.00011137089596381403\n",
      "train loss:0.003375753458744962\n",
      "train loss:0.00036345921601290744\n",
      "train loss:4.0348984165202384e-05\n",
      "train loss:0.0005423239748268059\n",
      "train loss:0.0024113916221566592\n",
      "train loss:0.0015961850240103067\n",
      "train loss:0.0003557528843727512\n",
      "train loss:1.209061218106173e-05\n",
      "train loss:0.0007159690801613144\n",
      "train loss:0.005008807885147888\n",
      "train loss:0.00031061879621056105\n",
      "train loss:0.00016265816660736648\n",
      "train loss:0.0008405421712158771\n",
      "train loss:0.00041756294114212437\n",
      "train loss:0.0035296258321104385\n",
      "train loss:0.0017235025897568532\n",
      "train loss:8.35489486012342e-05\n",
      "train loss:0.0006911123463593484\n",
      "train loss:5.462419624002306e-05\n",
      "train loss:0.000431596435104528\n",
      "train loss:0.00017632921480893792\n",
      "train loss:0.0006585032252127261\n",
      "train loss:0.0022430309179195607\n",
      "train loss:0.001596648955152716\n",
      "train loss:0.0002338818686321521\n",
      "train loss:0.00011252079886112788\n",
      "train loss:0.0009929202835722805\n",
      "train loss:0.006787664689245647\n",
      "train loss:0.0022864427216415695\n",
      "train loss:0.0035425808701749118\n",
      "train loss:0.0003605944910127094\n",
      "train loss:0.001662631047892276\n",
      "train loss:0.001520965458602848\n",
      "train loss:0.00034356432723717494\n",
      "train loss:0.0005576096590028511\n",
      "train loss:0.00034316927925347727\n",
      "train loss:0.0003132604102329725\n",
      "train loss:0.0015266630653658919\n",
      "train loss:0.00013691353290200676\n",
      "train loss:0.0010244468788302287\n",
      "train loss:0.0019497131960396405\n",
      "train loss:0.002017105869928758\n",
      "train loss:0.00024141555896592084\n",
      "train loss:0.0006250946130053611\n",
      "train loss:0.00015702838446652725\n",
      "train loss:0.0014010158816830118\n",
      "train loss:0.0002627593482387584\n",
      "train loss:4.011795451364561e-05\n",
      "train loss:0.00027532280703125036\n",
      "train loss:0.000818812086008712\n",
      "train loss:0.0005487479759186035\n",
      "train loss:4.6413725455111576e-05\n",
      "train loss:0.00042105180729819507\n",
      "train loss:0.0032896204677634435\n",
      "train loss:0.0007641016909146868\n",
      "train loss:0.0018882719182416999\n",
      "train loss:0.0001888575317501782\n",
      "train loss:0.0021953450999028707\n",
      "train loss:0.0018524945338951493\n",
      "train loss:0.0022108935140626356\n",
      "train loss:0.0002603186941223542\n",
      "train loss:0.0015857131038550256\n",
      "train loss:0.0006546521471171271\n",
      "train loss:0.002117877409790752\n",
      "train loss:0.00015806619382665948\n",
      "train loss:0.0009357090482573102\n",
      "train loss:0.00021484470159105116\n",
      "train loss:0.0003838028888000534\n",
      "train loss:0.00012965992547031045\n",
      "train loss:0.001986561628190318\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.004461027228369705\n",
      "train loss:0.00471238057714413\n",
      "train loss:6.717536891398292e-05\n",
      "train loss:0.007065609516994413\n",
      "train loss:0.0001543996887155998\n",
      "train loss:0.0006415291705047274\n",
      "train loss:0.001655468145146709\n",
      "train loss:0.0004415985572310066\n",
      "train loss:0.0002804063970869348\n",
      "train loss:0.0039496184866785735\n",
      "train loss:0.0004634541596739215\n",
      "train loss:0.00010904751140838465\n",
      "train loss:0.0003424229685643586\n",
      "train loss:6.983537804176431e-05\n",
      "train loss:0.01852662518883884\n",
      "train loss:0.00048569241530121575\n",
      "train loss:0.0025832518246571927\n",
      "train loss:0.0022264743731891185\n",
      "train loss:8.071647684216728e-05\n",
      "train loss:0.00037624691460105624\n",
      "train loss:0.0010776262616554936\n",
      "train loss:0.016100104514454483\n",
      "train loss:0.00013269709875050656\n",
      "train loss:0.0034964570723191642\n",
      "train loss:0.0010188653247869695\n",
      "train loss:0.001062703434700922\n",
      "train loss:2.664057171977171e-05\n",
      "train loss:0.00020302664769834743\n",
      "train loss:0.00020610112746236432\n",
      "train loss:0.0006674223320622236\n",
      "train loss:0.004683321083376991\n",
      "train loss:0.005039118577399963\n",
      "train loss:0.0004443588850521342\n",
      "train loss:0.0006357243491841487\n",
      "train loss:0.0013318662488571182\n",
      "train loss:0.0005219987623416648\n",
      "train loss:0.001011315959359884\n",
      "train loss:0.0001506737624142648\n",
      "train loss:0.0006519683797636053\n",
      "train loss:0.0010121047990486734\n",
      "train loss:0.0005552767734559091\n",
      "train loss:0.0044563974738379575\n",
      "train loss:0.002023892101028589\n",
      "train loss:0.003407186239467855\n",
      "train loss:0.00018310041262007852\n",
      "train loss:0.0007611300507962319\n",
      "train loss:0.003992247693642821\n",
      "train loss:0.003749925547538258\n",
      "train loss:0.0015859741190872377\n",
      "train loss:0.002300997180097199\n",
      "train loss:0.0002922678808422093\n",
      "train loss:0.0024207504804902437\n",
      "train loss:0.004492179341231287\n",
      "train loss:0.0007590461471241233\n",
      "train loss:0.0003480317427990761\n",
      "train loss:0.002638881809592593\n",
      "train loss:0.001100093360454337\n",
      "train loss:0.00048704612122155594\n",
      "train loss:0.0018890333267911705\n",
      "train loss:0.00016701889839854458\n",
      "train loss:0.01470190874369397\n",
      "train loss:0.008605874885960136\n",
      "train loss:0.0027736583730962124\n",
      "train loss:0.00029932104938287953\n",
      "train loss:0.0013616802581003493\n",
      "train loss:0.007216591818946559\n",
      "train loss:0.0002652088591946098\n",
      "train loss:0.00021908702720647565\n",
      "train loss:0.0003333822903590744\n",
      "train loss:0.00016733093903821918\n",
      "train loss:0.00014607382154646094\n",
      "train loss:0.00022888853801498058\n",
      "train loss:0.00015885855316250582\n",
      "train loss:0.0012511097227128455\n",
      "train loss:0.00011508515537550199\n",
      "train loss:0.0005203357893819299\n",
      "train loss:0.008635509344009027\n",
      "train loss:0.00031745402640145063\n",
      "train loss:0.023970261395409306\n",
      "train loss:0.0026084851491937023\n",
      "train loss:0.0008010883693961634\n",
      "train loss:0.002249156071746172\n",
      "train loss:0.0011135955704313799\n",
      "train loss:0.00192630902583514\n",
      "train loss:0.0001454356787799228\n",
      "train loss:0.006397044953845509\n",
      "train loss:0.004244899489684172\n",
      "train loss:0.0008337998912474558\n",
      "train loss:0.0003980129037655168\n",
      "train loss:0.000946750762670991\n",
      "train loss:0.004808553248020396\n",
      "train loss:0.00018933720876346456\n",
      "train loss:0.018129596372829765\n",
      "train loss:0.014065649443863322\n",
      "train loss:0.006787600938001824\n",
      "train loss:0.00048639322183144894\n",
      "train loss:0.0004107404665241504\n",
      "train loss:4.9894307508634056e-05\n",
      "train loss:0.00011401485726496555\n",
      "train loss:0.007914445662720766\n",
      "train loss:0.002476549362577481\n",
      "train loss:0.0004978451352907886\n",
      "train loss:0.0022177006245016253\n",
      "train loss:0.0009575087752236722\n",
      "train loss:0.003827552787462413\n",
      "train loss:0.0010373796528614192\n",
      "train loss:0.0024202694691707184\n",
      "train loss:0.0004584633960014016\n",
      "train loss:5.705727775824028e-05\n",
      "train loss:0.0008645763215991232\n",
      "train loss:0.0018836823349001755\n",
      "train loss:0.0033869595739770752\n",
      "train loss:0.00011235981958190351\n",
      "train loss:0.0007724355155124228\n",
      "train loss:0.0009446957861601176\n",
      "train loss:0.003990514007408333\n",
      "train loss:0.00590552669042666\n",
      "train loss:8.41806197477313e-06\n",
      "train loss:0.0003456755107229541\n",
      "train loss:0.00018549590700468797\n",
      "train loss:0.0006284940840534297\n",
      "train loss:0.000673658052633902\n",
      "train loss:0.0010300170259510827\n",
      "train loss:0.001381374281883225\n",
      "train loss:0.0018642860656061372\n",
      "train loss:1.72533973982671e-05\n",
      "train loss:0.00022046104302890528\n",
      "train loss:0.0002235399076591699\n",
      "train loss:0.000587908570436815\n",
      "train loss:0.0011893315556889075\n",
      "train loss:0.0014698970648270157\n",
      "train loss:9.249630622252333e-05\n",
      "train loss:5.407384579555488e-05\n",
      "train loss:0.00039064402714241944\n",
      "train loss:0.00023635447706446395\n",
      "train loss:0.000680113542401157\n",
      "train loss:0.00022307558729912447\n",
      "train loss:0.00030131940110913016\n",
      "train loss:0.002171074468695593\n",
      "train loss:0.011776601897551474\n",
      "train loss:0.0002184116317571071\n",
      "train loss:0.0024071311346181338\n",
      "train loss:0.00012931239821709629\n",
      "train loss:0.0015903844894295316\n",
      "train loss:0.0005322166029891283\n",
      "train loss:0.01977800729474183\n",
      "train loss:0.0015473530869497749\n",
      "train loss:0.0014320550828241547\n",
      "train loss:0.0008814439990876459\n",
      "train loss:0.0002750122409199099\n",
      "train loss:0.0012312438286264029\n",
      "train loss:0.004557960442394751\n",
      "train loss:0.002503592079602024\n",
      "train loss:0.000970843711736686\n",
      "train loss:0.0027976216769052126\n",
      "train loss:0.0011111736315912726\n",
      "train loss:9.335975353265795e-05\n",
      "train loss:0.0011407966029371303\n",
      "train loss:0.0004920580885984143\n",
      "train loss:0.00026769288898344516\n",
      "train loss:2.095232822851345e-05\n",
      "train loss:0.0031176864749196333\n",
      "train loss:0.001919587171779088\n",
      "train loss:0.002317769783718232\n",
      "train loss:0.0009800830495024263\n",
      "train loss:0.000676204167651061\n",
      "train loss:0.008780003159106892\n",
      "train loss:0.0003831362946346665\n",
      "train loss:0.00037073311220592564\n",
      "train loss:0.0005543929708683003\n",
      "train loss:0.0017967356580634191\n",
      "train loss:0.0019409517025072598\n",
      "train loss:0.0005196460832860003\n",
      "train loss:0.0002335790218451648\n",
      "train loss:0.00849724369939128\n",
      "train loss:0.015276320126361684\n",
      "train loss:0.0009110512096789691\n",
      "train loss:0.0016252720217396009\n",
      "train loss:0.0007698264691949761\n",
      "train loss:0.0032075350377052756\n",
      "train loss:0.004860357965835817\n",
      "train loss:0.0014933628996684112\n",
      "train loss:0.014814684544545105\n",
      "train loss:0.0009530227429300045\n",
      "train loss:0.00011356055324720422\n",
      "train loss:0.005558309875157556\n",
      "train loss:0.00039733127643704264\n",
      "train loss:0.0004305796136852937\n",
      "train loss:0.0002670557012095624\n",
      "train loss:0.0015460509512627888\n",
      "train loss:0.003735835409536386\n",
      "train loss:0.0019237038018580519\n",
      "train loss:0.00013484195315830022\n",
      "train loss:0.0002650688897697939\n",
      "train loss:0.0058310963204499435\n",
      "train loss:0.001796153639432105\n",
      "train loss:0.002904155665334162\n",
      "train loss:0.00448822611386403\n",
      "train loss:0.001178844539494956\n",
      "train loss:0.003094749098654025\n",
      "train loss:8.0963866299133e-05\n",
      "train loss:0.0009836438603495186\n",
      "train loss:0.00017401340910303258\n",
      "train loss:0.0027234691107931963\n",
      "train loss:0.0025988951789886034\n",
      "train loss:0.00013863713244239504\n",
      "train loss:0.00841445311594145\n",
      "train loss:0.002803371744217043\n",
      "train loss:0.006005839112029316\n",
      "train loss:0.00041156486133915685\n",
      "train loss:0.0013437982475751737\n",
      "train loss:0.00017700803221703284\n",
      "train loss:0.0005736611694499933\n",
      "train loss:0.0048104255759919\n",
      "train loss:0.0006989921475715597\n",
      "train loss:0.002237106985576331\n",
      "train loss:0.001800500000101606\n",
      "train loss:0.00014640731997987317\n",
      "train loss:0.0007983519794478364\n",
      "train loss:0.0007489895931085092\n",
      "train loss:8.609372670659353e-05\n",
      "train loss:0.002675487073660289\n",
      "train loss:0.002005810668286141\n",
      "train loss:0.0005951898015751691\n",
      "train loss:0.000726420707188055\n",
      "train loss:0.00012969456209972066\n",
      "train loss:0.00011361740459137988\n",
      "train loss:0.0006932883146388758\n",
      "train loss:0.0006611356168784731\n",
      "train loss:0.0022984296456539234\n",
      "train loss:0.005291760508555006\n",
      "train loss:0.00015672214770953943\n",
      "train loss:4.83489670915683e-05\n",
      "train loss:0.00029244143554052894\n",
      "train loss:0.00010877175510554345\n",
      "train loss:0.006545868741553919\n",
      "train loss:0.0015413203632900945\n",
      "train loss:0.0017380222503084733\n",
      "train loss:0.0016735197300426156\n",
      "train loss:0.007807999082169615\n",
      "train loss:0.00047427565753052246\n",
      "train loss:0.00021021391092849903\n",
      "train loss:0.0017207257659385107\n",
      "train loss:0.0030792737885801196\n",
      "train loss:0.0018541819026082912\n",
      "train loss:0.0009821258009239263\n",
      "train loss:3.1299486296558855e-05\n",
      "train loss:3.8438698587060426e-05\n",
      "train loss:0.00035798142651429215\n",
      "train loss:0.006507592246598588\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.0030249818472069057\n",
      "train loss:0.0009662722911014917\n",
      "train loss:0.012264177556857618\n",
      "train loss:0.0012489050614917353\n",
      "train loss:0.0007292571978156965\n",
      "train loss:0.00010512065675950606\n",
      "train loss:0.0003359314999146508\n",
      "train loss:0.002180633812985427\n",
      "train loss:0.0008662327182532157\n",
      "train loss:0.00024152516111145862\n",
      "train loss:3.3724488707595684e-05\n",
      "train loss:0.0011838915964102754\n",
      "train loss:0.0005200065219223077\n",
      "train loss:0.001951855167409273\n",
      "train loss:0.00023833838016543707\n",
      "train loss:0.007307926630312\n",
      "train loss:0.0005349004917313882\n",
      "train loss:0.002899164324856613\n",
      "train loss:0.0029177506293632254\n",
      "train loss:0.0012025128913367487\n",
      "train loss:0.00016274661690835048\n",
      "train loss:0.0018659626867739895\n",
      "train loss:0.00020069888221646765\n",
      "train loss:0.004601395057523751\n",
      "train loss:0.00024520700640985176\n",
      "train loss:0.0032625666021394955\n",
      "train loss:0.0025293284098245016\n",
      "train loss:0.000832627536037395\n",
      "train loss:0.0006581806962247999\n",
      "train loss:0.009518429725551654\n",
      "train loss:0.006608523205704527\n",
      "train loss:0.0002797129573156399\n",
      "train loss:0.0006286617902200919\n",
      "train loss:0.000603790860241492\n",
      "train loss:0.002335266601600553\n",
      "train loss:0.00042434365622223474\n",
      "train loss:0.00020346325677979093\n",
      "train loss:0.0005497459655968397\n",
      "train loss:0.0006238178651965028\n",
      "train loss:0.005427512729753629\n",
      "train loss:0.0014678159382362063\n",
      "train loss:0.0005227408419739481\n",
      "train loss:1.846765048544117e-05\n",
      "train loss:0.0010718681130122692\n",
      "train loss:0.002132305037204825\n",
      "train loss:0.0006891082334243359\n",
      "train loss:2.0207993101579655e-05\n",
      "train loss:0.001901336257891531\n",
      "train loss:0.00041931590603566687\n",
      "train loss:0.0005458808640306386\n",
      "train loss:0.0027983850659471982\n",
      "train loss:0.0011983232435301054\n",
      "train loss:0.0025690085889691723\n",
      "train loss:0.008791835513890005\n",
      "train loss:0.0019077689690141343\n",
      "train loss:0.0015128253126350008\n",
      "train loss:0.002685783618980321\n",
      "train loss:0.001822161110256287\n",
      "train loss:0.0021895124036696426\n",
      "train loss:0.0027574941423806143\n",
      "train loss:0.0009938136065085327\n",
      "train loss:0.00020144600922288348\n",
      "train loss:0.00015594810325829828\n",
      "train loss:0.0012599244189914318\n",
      "train loss:0.0018402745338688706\n",
      "train loss:0.012112108354035277\n",
      "train loss:0.0006296134752238925\n",
      "train loss:0.0012328860212525788\n",
      "train loss:0.00022732675760884824\n",
      "train loss:8.119332653078506e-05\n",
      "train loss:0.00014550480689252078\n",
      "train loss:0.00041038608958931855\n",
      "train loss:0.0012585733350941705\n",
      "train loss:0.003998671550029346\n",
      "train loss:0.0009628772985140353\n",
      "train loss:0.0035936951588214456\n",
      "train loss:0.0009647862755388367\n",
      "train loss:0.00012996865356993735\n",
      "train loss:9.49991888054568e-05\n",
      "train loss:0.0005137321286196056\n",
      "train loss:0.0012373658925877314\n",
      "train loss:0.0005800428984603322\n",
      "train loss:6.417656098440749e-05\n",
      "train loss:0.0005234184437691513\n",
      "train loss:0.001995016424141357\n",
      "train loss:0.0015210734684958846\n",
      "train loss:0.0007010027378711846\n",
      "train loss:0.00015841783274199973\n",
      "train loss:0.000510456583667563\n",
      "train loss:0.0002730341423161429\n",
      "train loss:6.890375102797801e-05\n",
      "train loss:0.0005631955133073203\n",
      "train loss:0.00016266337688833457\n",
      "train loss:6.447688303349104e-05\n",
      "train loss:0.00026373045744282954\n",
      "train loss:0.0016473067040503598\n",
      "train loss:0.00010463406375612027\n",
      "train loss:0.0025158634784253307\n",
      "train loss:0.0015055389622118474\n",
      "train loss:0.0004088735061047805\n",
      "train loss:0.0016829630149726973\n",
      "train loss:0.0032817194320195046\n",
      "train loss:0.00012791026084868224\n",
      "train loss:0.0006498299636400732\n",
      "train loss:0.00025324723304896344\n",
      "train loss:0.00034509207686820144\n",
      "train loss:0.00025613252141600516\n",
      "train loss:8.544896729947763e-05\n",
      "train loss:0.0029399562013048375\n",
      "train loss:0.0002263004746609195\n",
      "train loss:0.001233490459796852\n",
      "train loss:0.0007503824704526529\n",
      "train loss:0.00042348620333758233\n",
      "train loss:0.0008300950630527237\n",
      "train loss:0.002167097716350257\n",
      "train loss:0.00017681936550103936\n",
      "train loss:0.0020743016607766653\n",
      "train loss:9.265501737080935e-05\n",
      "train loss:0.00020546376788947417\n",
      "train loss:0.00042523196022744637\n",
      "train loss:0.00046799735312724744\n",
      "train loss:0.00014108589694648773\n",
      "train loss:0.0026821681793077717\n",
      "train loss:9.559076793780385e-05\n",
      "train loss:0.00014197489463310372\n",
      "train loss:0.0009891601590032051\n",
      "train loss:4.508575486875605e-05\n",
      "train loss:0.00011484049105442087\n",
      "train loss:0.0009092629836090246\n",
      "train loss:0.0006940520770344805\n",
      "train loss:0.0010406325420492457\n",
      "train loss:0.00051913847350133\n",
      "train loss:9.548936776490586e-05\n",
      "train loss:0.0025032454265533216\n",
      "train loss:0.0010121220939712475\n",
      "train loss:0.0007813770466498381\n",
      "train loss:0.001956177472292054\n",
      "train loss:0.059876236316328324\n",
      "train loss:0.0001345510065694374\n",
      "train loss:0.0004937670634229137\n",
      "train loss:0.002975230265992995\n",
      "train loss:0.000624268094721956\n",
      "train loss:0.0006691481183527899\n",
      "train loss:0.0013835476709067756\n",
      "train loss:0.00015791510844978502\n",
      "train loss:0.00044615591347952504\n",
      "train loss:0.0024531795003527295\n",
      "train loss:0.00041534658030096877\n",
      "train loss:0.00030192509395600225\n",
      "train loss:0.00036621411429577674\n",
      "train loss:0.0030247272865835894\n",
      "train loss:0.001039351622424674\n",
      "train loss:0.00013299577626099416\n",
      "train loss:0.0006043019636144325\n",
      "train loss:9.14626932692726e-05\n",
      "train loss:0.0006895665877107647\n",
      "train loss:0.0010071508350628865\n",
      "train loss:0.0005928875169642677\n",
      "train loss:0.00043933799987405897\n",
      "train loss:0.0011576231348483172\n",
      "train loss:0.0013683746105772256\n",
      "train loss:0.0036166005851322736\n",
      "train loss:0.0014491956605271025\n",
      "train loss:0.0005648181052083493\n",
      "train loss:0.0013887312146867725\n",
      "train loss:0.0008629011696472106\n",
      "train loss:0.00018534113925426952\n",
      "train loss:0.0021101464764714077\n",
      "train loss:0.0015204139636649883\n",
      "train loss:0.0006129151206488869\n",
      "train loss:0.0012848666802686883\n",
      "train loss:0.0010998148889012356\n",
      "train loss:0.0004558747983282558\n",
      "train loss:0.000340646223633598\n",
      "train loss:0.0016252559491774033\n",
      "train loss:0.0001361503862809011\n",
      "train loss:0.008214440211823089\n",
      "train loss:0.0013795164534821294\n",
      "train loss:0.00026264445916873496\n",
      "train loss:0.0009794643426118076\n",
      "train loss:0.0003528863885354294\n",
      "train loss:0.0004035573663391256\n",
      "train loss:0.00035837706892486663\n",
      "train loss:0.0008650851935926264\n",
      "train loss:0.0018401159338870471\n",
      "train loss:0.0006769774199885387\n",
      "train loss:0.04308785133337193\n",
      "train loss:0.00010175468848156585\n",
      "train loss:0.0001989318440514859\n",
      "train loss:0.0015171120303528285\n",
      "train loss:0.00040216514960315057\n",
      "train loss:0.0007927513398238061\n",
      "train loss:0.0013315919164064885\n",
      "train loss:0.0006964420022439527\n",
      "train loss:0.0016202318532857788\n",
      "train loss:0.0009357960326961224\n",
      "train loss:0.0023132935624450603\n",
      "train loss:0.0005304618741950984\n",
      "train loss:0.0009681905518057056\n",
      "train loss:0.00014243256453341235\n",
      "train loss:0.0040400029303606574\n",
      "train loss:2.7969048437857847e-05\n",
      "train loss:0.001259260163744618\n",
      "train loss:0.000346074635760832\n",
      "train loss:0.0011972343873788399\n",
      "train loss:0.0007654239657474055\n",
      "train loss:9.894340917007142e-05\n",
      "train loss:0.000982263536171671\n",
      "train loss:8.782553100673189e-05\n",
      "train loss:0.00022170728221087424\n",
      "train loss:0.0003795362746702005\n",
      "train loss:0.003910549516311316\n",
      "train loss:5.457717964614341e-05\n",
      "train loss:0.0004778842391271982\n",
      "train loss:0.00014541309264666104\n",
      "train loss:0.0005022196365702161\n",
      "train loss:0.00012012705954515854\n",
      "train loss:7.731686871641918e-05\n",
      "train loss:8.409159846634907e-05\n",
      "train loss:9.772640363561028e-05\n",
      "train loss:0.001972267527580892\n",
      "train loss:0.0009165037292288323\n",
      "train loss:0.0005247741369836947\n",
      "train loss:0.00012496652832588373\n",
      "train loss:4.299692536155041e-05\n",
      "train loss:0.0006351435398004433\n",
      "train loss:5.273759393078277e-05\n",
      "train loss:0.0017779651056315227\n",
      "train loss:0.00041950446499966314\n",
      "train loss:0.00030654731809393634\n",
      "train loss:0.010189350410795295\n",
      "train loss:0.0012036270373968463\n",
      "=============== Final Test Accuracy ===============\n",
      "test acc:0.9894\n",
      "Saved Network Parameters!\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# coding: utf-8\n",
    "import sys, os\n",
    "sys.path.append(os.pardir)  # 부모 디렉터리의 파일을 가져올 수 있도록 설정\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from dataset.mnist import load_mnist\n",
    "from simple_convnet import SimpleConvNet\n",
    "from common.trainer import Trainer\n",
    "\n",
    "# 데이터 읽기\n",
    "(x_train, t_train), (x_test, t_test) = load_mnist(flatten=False)\n",
    "\n",
    "# 시간이 오래 걸릴 경우 데이터를 줄인다.\n",
    "#x_train, t_train = x_train[:5000], t_train[:5000]\n",
    "#x_test, t_test = x_test[:1000], t_test[:1000]\n",
    "\n",
    "max_epochs = 20\n",
    "\n",
    "network = SimpleConvNet(input_dim=(1,28,28), \n",
    "                        conv_param = {'filter_num': 30, 'filter_size': 5, 'pad': 0, 'stride': 1},\n",
    "                        hidden_size=100, output_size=10, weight_init_std=0.01)\n",
    "                        \n",
    "trainer = Trainer(network, x_train, t_train, x_test, t_test,\n",
    "                  epochs=max_epochs, mini_batch_size=100,\n",
    "                  optimizer='Adam', optimizer_param={'lr': 0.001},\n",
    "                  evaluate_sample_num_per_epoch=1000)\n",
    "trainer.train()\n",
    "\n",
    "# 매개변수 보존\n",
    "network.save_params(\"params.pkl\")\n",
    "print(\"Saved Network Parameters!\")\n",
    "\n",
    "# 그래프 그리기\n",
    "markers = {'train': 'o', 'test': 's'}\n",
    "x = np.arange(max_epochs)\n",
    "plt.plot(x, trainer.train_acc_list, marker='o', label='train', markevery=2)\n",
    "plt.plot(x, trainer.test_acc_list, marker='s', label='test', markevery=2)\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel(\"accuracy\")\n",
    "plt.ylim(0, 1.0)\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.6.1 1번째 층의 가중치 시각화하기\n",
    "- 합성곱 1번째 층의 가중치를 학습 전과 후로 나눠 시각화해봅니다. 이미 학습된 가중치 값(params.pkl)을 읽어서 사용하므로 학습 과정은 생략됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 30 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 30 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# coding: utf-8\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from simple_convnet import SimpleConvNet\n",
    "\n",
    "def filter_show(filters, nx=8, margin=3, scale=10):\n",
    "    \"\"\"\n",
    "    c.f. https://gist.github.com/aidiary/07d530d5e08011832b12#file-draw_weight-py\n",
    "    \"\"\"\n",
    "    FN, C, FH, FW = filters.shape\n",
    "    ny = int(np.ceil(FN / nx))\n",
    "\n",
    "    fig = plt.figure()\n",
    "    fig.subplots_adjust(left=0, right=1, bottom=0, top=1, hspace=0.05, wspace=0.05)\n",
    "\n",
    "    for i in range(FN):\n",
    "        ax = fig.add_subplot(ny, nx, i+1, xticks=[], yticks=[])\n",
    "        ax.imshow(filters[i, 0], cmap=plt.cm.gray_r, interpolation='nearest')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "network = SimpleConvNet()\n",
    "# 무작위(랜덤) 초기화 후의 가중치\n",
    "filter_show(network.params['W1'])\n",
    "\n",
    "# 학습된 가중치\n",
    "network.load_params(\"params.pkl\")\n",
    "filter_show(network.params['W1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aiffel",
   "language": "python",
   "name": "aiffel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
