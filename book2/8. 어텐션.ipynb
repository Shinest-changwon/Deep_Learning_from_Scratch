{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# attention_layer.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coding: utf-8\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "from common.np import *  # import numpy as np\n",
    "from common.layers import Softmax\n",
    "\n",
    "\n",
    "class WeightSum:\n",
    "    def __init__(self):\n",
    "        self.params, self.grads = [], []\n",
    "        self.cache = None\n",
    "\n",
    "    def forward(self, hs, a):\n",
    "        N, T, H = hs.shape\n",
    "\n",
    "        ar = a.reshape(N, T, 1)#.repeat(T, axis=1)\n",
    "        t = hs * ar\n",
    "        c = np.sum(t, axis=1)\n",
    "\n",
    "        self.cache = (hs, ar)\n",
    "        return c\n",
    "\n",
    "    def backward(self, dc):\n",
    "        hs, ar = self.cache\n",
    "        N, T, H = hs.shape\n",
    "        dt = dc.reshape(N, 1, H).repeat(T, axis=1)\n",
    "        dar = dt * hs\n",
    "        dhs = dt * ar\n",
    "        da = np.sum(dar, axis=2)\n",
    "\n",
    "        return dhs, da\n",
    "\n",
    "\n",
    "class AttentionWeight:\n",
    "    def __init__(self):\n",
    "        self.params, self.grads = [], []\n",
    "        self.softmax = Softmax()\n",
    "        self.cache = None\n",
    "\n",
    "    def forward(self, hs, h):\n",
    "        N, T, H = hs.shape\n",
    "\n",
    "        hr = h.reshape(N, 1, H)#.repeat(T, axis=1)\n",
    "        t = hs * hr\n",
    "        s = np.sum(t, axis=2)\n",
    "        a = self.softmax.forward(s)\n",
    "\n",
    "        self.cache = (hs, hr)\n",
    "        return a\n",
    "\n",
    "    def backward(self, da):\n",
    "        hs, hr = self.cache\n",
    "        N, T, H = hs.shape\n",
    "\n",
    "        ds = self.softmax.backward(da)\n",
    "        dt = ds.reshape(N, T, 1).repeat(H, axis=2)\n",
    "        dhs = dt * hr\n",
    "        dhr = dt * hs\n",
    "        dh = np.sum(dhr, axis=1)\n",
    "\n",
    "        return dhs, dh\n",
    "\n",
    "\n",
    "class Attention:\n",
    "    def __init__(self):\n",
    "        self.params, self.grads = [], []\n",
    "        self.attention_weight_layer = AttentionWeight()\n",
    "        self.weight_sum_layer = WeightSum()\n",
    "        self.attention_weight = None\n",
    "\n",
    "    def forward(self, hs, h):\n",
    "        a = self.attention_weight_layer.forward(hs, h)\n",
    "        out = self.weight_sum_layer.forward(hs, a)\n",
    "        self.attention_weight = a\n",
    "        return out\n",
    "\n",
    "    def backward(self, dout):\n",
    "        dhs0, da = self.weight_sum_layer.backward(dout)\n",
    "        dhs1, dh = self.attention_weight_layer.backward(da)\n",
    "        dhs = dhs0 + dhs1\n",
    "        return dhs, dh\n",
    "\n",
    "\n",
    "class TimeAttention:\n",
    "    def __init__(self):\n",
    "        self.params, self.grads = [], []\n",
    "        self.layers = None\n",
    "        self.attention_weights = None\n",
    "\n",
    "    def forward(self, hs_enc, hs_dec):\n",
    "        N, T, H = hs_dec.shape\n",
    "        out = np.empty_like(hs_dec)\n",
    "        self.layers = []\n",
    "        self.attention_weights = []\n",
    "\n",
    "        for t in range(T):\n",
    "            layer = Attention()\n",
    "            out[:, t, :] = layer.forward(hs_enc, hs_dec[:,t,:])\n",
    "            self.layers.append(layer)\n",
    "            self.attention_weights.append(layer.attention_weight)\n",
    "\n",
    "        return out\n",
    "\n",
    "    def backward(self, dout):\n",
    "        N, T, H = dout.shape\n",
    "        dhs_enc = 0\n",
    "        dhs_dec = np.empty_like(dout)\n",
    "\n",
    "        for t in range(T):\n",
    "            layer = self.layers[t]\n",
    "            dhs, dh = layer.backward(dout[:, t, :])\n",
    "            dhs_enc += dhs\n",
    "            dhs_dec[:,t,:] = dh\n",
    "\n",
    "        return dhs_enc, dhs_dec\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# attention_seq2seq.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coding: utf-8\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "from common.time_layers import *\n",
    "# from ch07.seq2seq import Encoder, Seq2seq\n",
    "# from ch08.attention_layer import TimeAttention\n",
    "from common.base_model import BaseModel\n",
    "\n",
    "class Encoder:\n",
    "    def __init__(self, vocab_size, wordvec_size, hidden_size):\n",
    "        V, D, H = vocab_size, wordvec_size, hidden_size\n",
    "        rn = np.random.randn\n",
    "\n",
    "        embed_W = (rn(V, D) / 100).astype('f')\n",
    "        lstm_Wx = (rn(D, 4 * H) / np.sqrt(D)).astype('f')\n",
    "        lstm_Wh = (rn(H, 4 * H) / np.sqrt(H)).astype('f')\n",
    "        lstm_b = np.zeros(4 * H).astype('f')\n",
    "\n",
    "        self.embed = TimeEmbedding(embed_W)\n",
    "        self.lstm = TimeLSTM(lstm_Wx, lstm_Wh, lstm_b, stateful=False)\n",
    "\n",
    "        self.params = self.embed.params + self.lstm.params\n",
    "        self.grads = self.embed.grads + self.lstm.grads\n",
    "        self.hs = None\n",
    "\n",
    "    def forward(self, xs):\n",
    "        xs = self.embed.forward(xs)\n",
    "        hs = self.lstm.forward(xs)\n",
    "        self.hs = hs\n",
    "        return hs[:, -1, :]\n",
    "\n",
    "    def backward(self, dh):\n",
    "        dhs = np.zeros_like(self.hs)\n",
    "        dhs[:, -1, :] = dh\n",
    "\n",
    "        dout = self.lstm.backward(dhs)\n",
    "        dout = self.embed.backward(dout)\n",
    "        return dout\n",
    "\n",
    "\n",
    "class Seq2seq(BaseModel):\n",
    "    def __init__(self, vocab_size, wordvec_size, hidden_size):\n",
    "        V, D, H = vocab_size, wordvec_size, hidden_size\n",
    "        self.encoder = Encoder(V, D, H)\n",
    "        self.decoder = Decoder(V, D, H)\n",
    "        self.softmax = TimeSoftmaxWithLoss()\n",
    "\n",
    "        self.params = self.encoder.params + self.decoder.params\n",
    "        self.grads = self.encoder.grads + self.decoder.grads\n",
    "\n",
    "    def forward(self, xs, ts):\n",
    "        decoder_xs, decoder_ts = ts[:, :-1], ts[:, 1:]\n",
    "\n",
    "        h = self.encoder.forward(xs)\n",
    "        score = self.decoder.forward(decoder_xs, h)\n",
    "        loss = self.softmax.forward(score, decoder_ts)\n",
    "        return loss\n",
    "\n",
    "    def backward(self, dout=1):\n",
    "        dout = self.softmax.backward(dout)\n",
    "        dh = self.decoder.backward(dout)\n",
    "        dout = self.encoder.backward(dh)\n",
    "        return dout\n",
    "\n",
    "    def generate(self, xs, start_id, sample_size):\n",
    "        h = self.encoder.forward(xs)\n",
    "        sampled = self.decoder.generate(h, start_id, sample_size)\n",
    "        return sampled\n",
    "    \n",
    "\n",
    "class AttentionEncoder(Encoder):\n",
    "    def forward(self, xs):\n",
    "        xs = self.embed.forward(xs)\n",
    "        hs = self.lstm.forward(xs)\n",
    "        return hs\n",
    "\n",
    "    def backward(self, dhs):\n",
    "        dout = self.lstm.backward(dhs)\n",
    "        dout = self.embed.backward(dout)\n",
    "        return dout\n",
    "\n",
    "\n",
    "class AttentionDecoder:\n",
    "    def __init__(self, vocab_size, wordvec_size, hidden_size):\n",
    "        V, D, H = vocab_size, wordvec_size, hidden_size\n",
    "        rn = np.random.randn\n",
    "\n",
    "        embed_W = (rn(V, D) / 100).astype('f')\n",
    "        lstm_Wx = (rn(D, 4 * H) / np.sqrt(D)).astype('f')\n",
    "        lstm_Wh = (rn(H, 4 * H) / np.sqrt(H)).astype('f')\n",
    "        lstm_b = np.zeros(4 * H).astype('f')\n",
    "        affine_W = (rn(2*H, V) / np.sqrt(2*H)).astype('f')\n",
    "        affine_b = np.zeros(V).astype('f')\n",
    "\n",
    "        self.embed = TimeEmbedding(embed_W)\n",
    "        self.lstm = TimeLSTM(lstm_Wx, lstm_Wh, lstm_b, stateful=True)\n",
    "        self.attention = TimeAttention()\n",
    "        self.affine = TimeAffine(affine_W, affine_b)\n",
    "        layers = [self.embed, self.lstm, self.attention, self.affine]\n",
    "\n",
    "        self.params, self.grads = [], []\n",
    "        for layer in layers:\n",
    "            self.params += layer.params\n",
    "            self.grads += layer.grads\n",
    "\n",
    "    def forward(self, xs, enc_hs):\n",
    "        h = enc_hs[:,-1]\n",
    "        self.lstm.set_state(h)\n",
    "\n",
    "        out = self.embed.forward(xs)\n",
    "        dec_hs = self.lstm.forward(out)\n",
    "        c = self.attention.forward(enc_hs, dec_hs)\n",
    "        out = np.concatenate((c, dec_hs), axis=2)\n",
    "        score = self.affine.forward(out)\n",
    "\n",
    "        return score\n",
    "\n",
    "    def backward(self, dscore):\n",
    "        dout = self.affine.backward(dscore)\n",
    "        N, T, H2 = dout.shape\n",
    "        H = H2 // 2\n",
    "\n",
    "        dc, ddec_hs0 = dout[:,:,:H], dout[:,:,H:]\n",
    "        denc_hs, ddec_hs1 = self.attention.backward(dc)\n",
    "        ddec_hs = ddec_hs0 + ddec_hs1\n",
    "        dout = self.lstm.backward(ddec_hs)\n",
    "        dh = self.lstm.dh\n",
    "        denc_hs[:, -1] += dh\n",
    "        self.embed.backward(dout)\n",
    "\n",
    "        return denc_hs\n",
    "\n",
    "    def generate(self, enc_hs, start_id, sample_size):\n",
    "        sampled = []\n",
    "        sample_id = start_id\n",
    "        h = enc_hs[:, -1]\n",
    "        self.lstm.set_state(h)\n",
    "\n",
    "        for _ in range(sample_size):\n",
    "            x = np.array([sample_id]).reshape((1, 1))\n",
    "\n",
    "            out = self.embed.forward(x)\n",
    "            dec_hs = self.lstm.forward(out)\n",
    "            c = self.attention.forward(enc_hs, dec_hs)\n",
    "            out = np.concatenate((c, dec_hs), axis=2)\n",
    "            score = self.affine.forward(out)\n",
    "\n",
    "            sample_id = np.argmax(score.flatten())\n",
    "            sampled.append(sample_id)\n",
    "\n",
    "        return sampled\n",
    "\n",
    "\n",
    "class AttentionSeq2seq(Seq2seq):\n",
    "    def __init__(self, vocab_size, wordvec_size, hidden_size):\n",
    "        args = vocab_size, wordvec_size, hidden_size\n",
    "        self.encoder = AttentionEncoder(*args)\n",
    "        self.decoder = AttentionDecoder(*args)\n",
    "        self.softmax = TimeSoftmaxWithLoss()\n",
    "\n",
    "        self.params = self.encoder.params + self.decoder.params\n",
    "        self.grads = self.encoder.grads + self.decoder.grads"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| 에폭 1 |  반복 1 / 351 | 시간 0[s] | 손실 4.08\n",
      "| 에폭 1 |  반복 21 / 351 | 시간 3[s] | 손실 3.09\n",
      "| 에폭 1 |  반복 41 / 351 | 시간 7[s] | 손실 1.90\n",
      "| 에폭 1 |  반복 61 / 351 | 시간 11[s] | 손실 1.72\n",
      "| 에폭 1 |  반복 81 / 351 | 시간 15[s] | 손실 1.46\n",
      "| 에폭 1 |  반복 101 / 351 | 시간 19[s] | 손실 1.19\n",
      "| 에폭 1 |  반복 121 / 351 | 시간 23[s] | 손실 1.14\n",
      "| 에폭 1 |  반복 141 / 351 | 시간 26[s] | 손실 1.09\n",
      "| 에폭 1 |  반복 161 / 351 | 시간 30[s] | 손실 1.06\n",
      "| 에폭 1 |  반복 181 / 351 | 시간 34[s] | 손실 1.04\n",
      "| 에폭 1 |  반복 201 / 351 | 시간 38[s] | 손실 1.03\n",
      "| 에폭 1 |  반복 221 / 351 | 시간 41[s] | 손실 1.02\n",
      "| 에폭 1 |  반복 241 / 351 | 시간 45[s] | 손실 1.02\n",
      "| 에폭 1 |  반복 261 / 351 | 시간 49[s] | 손실 1.01\n",
      "| 에폭 1 |  반복 281 / 351 | 시간 53[s] | 손실 1.00\n",
      "| 에폭 1 |  반복 301 / 351 | 시간 56[s] | 손실 1.00\n",
      "| 에폭 1 |  반복 321 / 351 | 시간 60[s] | 손실 1.00\n",
      "| 에폭 1 |  반복 341 / 351 | 시간 64[s] | 손실 1.00\n",
      "Q 10/15/94                     \n",
      "T 1994-10-15\n",
      "\u001b[91m☒\u001b[0m 1978-08-11\n",
      "---\n",
      "Q thursday, november 13, 2008  \n",
      "T 2008-11-13\n",
      "\u001b[91m☒\u001b[0m 1978-08-11\n",
      "---\n",
      "Q Mar 25, 2003                 \n",
      "T 2003-03-25\n",
      "\u001b[91m☒\u001b[0m 1978-08-11\n",
      "---\n",
      "Q Tuesday, November 22, 2016   \n",
      "T 2016-11-22\n",
      "\u001b[91m☒\u001b[0m 1978-08-11\n",
      "---\n",
      "Q Saturday, July 18, 1970      \n",
      "T 1970-07-18\n",
      "\u001b[91m☒\u001b[0m 1978-08-11\n",
      "---\n",
      "Q october 6, 1992              \n",
      "T 1992-10-06\n",
      "\u001b[91m☒\u001b[0m 1978-08-11\n",
      "---\n",
      "Q 8/23/08                      \n",
      "T 2008-08-23\n",
      "\u001b[91m☒\u001b[0m 1978-08-11\n",
      "---\n",
      "Q 8/30/07                      \n",
      "T 2007-08-30\n",
      "\u001b[91m☒\u001b[0m 1978-08-11\n",
      "---\n",
      "Q 10/28/13                     \n",
      "T 2013-10-28\n",
      "\u001b[91m☒\u001b[0m 1978-08-11\n",
      "---\n",
      "Q sunday, november 6, 2016     \n",
      "T 2016-11-06\n",
      "\u001b[91m☒\u001b[0m 1978-08-11\n",
      "---\n",
      "정확도 0.000%\n",
      "| 에폭 2 |  반복 1 / 351 | 시간 0[s] | 손실 1.00\n",
      "| 에폭 2 |  반복 21 / 351 | 시간 4[s] | 손실 1.00\n",
      "| 에폭 2 |  반복 41 / 351 | 시간 7[s] | 손실 0.99\n",
      "| 에폭 2 |  반복 61 / 351 | 시간 11[s] | 손실 0.99\n",
      "| 에폭 2 |  반복 81 / 351 | 시간 15[s] | 손실 0.99\n",
      "| 에폭 2 |  반복 101 / 351 | 시간 19[s] | 손실 0.99\n",
      "| 에폭 2 |  반복 121 / 351 | 시간 22[s] | 손실 0.99\n",
      "| 에폭 2 |  반복 141 / 351 | 시간 26[s] | 손실 0.98\n",
      "| 에폭 2 |  반복 161 / 351 | 시간 30[s] | 손실 0.98\n",
      "| 에폭 2 |  반복 181 / 351 | 시간 34[s] | 손실 0.97\n",
      "| 에폭 2 |  반복 201 / 351 | 시간 37[s] | 손실 0.95\n",
      "| 에폭 2 |  반복 221 / 351 | 시간 41[s] | 손실 0.94\n",
      "| 에폭 2 |  반복 241 / 351 | 시간 45[s] | 손실 0.90\n",
      "| 에폭 2 |  반복 261 / 351 | 시간 49[s] | 손실 0.83\n",
      "| 에폭 2 |  반복 281 / 351 | 시간 53[s] | 손실 0.74\n",
      "| 에폭 2 |  반복 301 / 351 | 시간 56[s] | 손실 0.66\n",
      "| 에폭 2 |  반복 321 / 351 | 시간 60[s] | 손실 0.58\n",
      "| 에폭 2 |  반복 341 / 351 | 시간 64[s] | 손실 0.47\n",
      "Q 10/15/94                     \n",
      "T 1994-10-15\n",
      "\u001b[92m☑\u001b[0m 1994-10-15\n",
      "---\n",
      "Q thursday, november 13, 2008  \n",
      "T 2008-11-13\n",
      "\u001b[91m☒\u001b[0m 2006-11-13\n",
      "---\n",
      "Q Mar 25, 2003                 \n",
      "T 2003-03-25\n",
      "\u001b[92m☑\u001b[0m 2003-03-25\n",
      "---\n",
      "Q Tuesday, November 22, 2016   \n",
      "T 2016-11-22\n",
      "\u001b[92m☑\u001b[0m 2016-11-22\n",
      "---\n",
      "Q Saturday, July 18, 1970      \n",
      "T 1970-07-18\n",
      "\u001b[92m☑\u001b[0m 1970-07-18\n",
      "---\n",
      "Q october 6, 1992              \n",
      "T 1992-10-06\n",
      "\u001b[92m☑\u001b[0m 1992-10-06\n",
      "---\n",
      "Q 8/23/08                      \n",
      "T 2008-08-23\n",
      "\u001b[92m☑\u001b[0m 2008-08-23\n",
      "---\n",
      "Q 8/30/07                      \n",
      "T 2007-08-30\n",
      "\u001b[91m☒\u001b[0m 2007-08-09\n",
      "---\n",
      "Q 10/28/13                     \n",
      "T 2013-10-28\n",
      "\u001b[91m☒\u001b[0m 1983-10-28\n",
      "---\n",
      "Q sunday, november 6, 2016     \n",
      "T 2016-11-06\n",
      "\u001b[91m☒\u001b[0m 2016-11-08\n",
      "---\n",
      "정확도 51.460%\n",
      "| 에폭 3 |  반복 1 / 351 | 시간 0[s] | 손실 0.35\n",
      "| 에폭 3 |  반복 21 / 351 | 시간 3[s] | 손실 0.30\n",
      "| 에폭 3 |  반복 41 / 351 | 시간 7[s] | 손실 0.21\n",
      "| 에폭 3 |  반복 61 / 351 | 시간 11[s] | 손실 0.14\n",
      "| 에폭 3 |  반복 81 / 351 | 시간 14[s] | 손실 0.09\n",
      "| 에폭 3 |  반복 101 / 351 | 시간 18[s] | 손실 0.07\n",
      "| 에폭 3 |  반복 121 / 351 | 시간 22[s] | 손실 0.05\n",
      "| 에폭 3 |  반복 141 / 351 | 시간 25[s] | 손실 0.04\n",
      "| 에폭 3 |  반복 161 / 351 | 시간 29[s] | 손실 0.03\n",
      "| 에폭 3 |  반복 181 / 351 | 시간 33[s] | 손실 0.03\n",
      "| 에폭 3 |  반복 201 / 351 | 시간 36[s] | 손실 0.02\n",
      "| 에폭 3 |  반복 221 / 351 | 시간 40[s] | 손실 0.02\n",
      "| 에폭 3 |  반복 241 / 351 | 시간 44[s] | 손실 0.02\n",
      "| 에폭 3 |  반복 261 / 351 | 시간 47[s] | 손실 0.01\n",
      "| 에폭 3 |  반복 281 / 351 | 시간 51[s] | 손실 0.01\n",
      "| 에폭 3 |  반복 301 / 351 | 시간 55[s] | 손실 0.01\n",
      "| 에폭 3 |  반복 321 / 351 | 시간 59[s] | 손실 0.01\n",
      "| 에폭 3 |  반복 341 / 351 | 시간 62[s] | 손실 0.01\n",
      "Q 10/15/94                     \n",
      "T 1994-10-15\n",
      "\u001b[92m☑\u001b[0m 1994-10-15\n",
      "---\n",
      "Q thursday, november 13, 2008  \n",
      "T 2008-11-13\n",
      "\u001b[92m☑\u001b[0m 2008-11-13\n",
      "---\n",
      "Q Mar 25, 2003                 \n",
      "T 2003-03-25\n",
      "\u001b[92m☑\u001b[0m 2003-03-25\n",
      "---\n",
      "Q Tuesday, November 22, 2016   \n",
      "T 2016-11-22\n",
      "\u001b[92m☑\u001b[0m 2016-11-22\n",
      "---\n",
      "Q Saturday, July 18, 1970      \n",
      "T 1970-07-18\n",
      "\u001b[92m☑\u001b[0m 1970-07-18\n",
      "---\n",
      "Q october 6, 1992              \n",
      "T 1992-10-06\n",
      "\u001b[92m☑\u001b[0m 1992-10-06\n",
      "---\n",
      "Q 8/23/08                      \n",
      "T 2008-08-23\n",
      "\u001b[92m☑\u001b[0m 2008-08-23\n",
      "---\n",
      "Q 8/30/07                      \n",
      "T 2007-08-30\n",
      "\u001b[92m☑\u001b[0m 2007-08-30\n",
      "---\n",
      "Q 10/28/13                     \n",
      "T 2013-10-28\n",
      "\u001b[92m☑\u001b[0m 2013-10-28\n",
      "---\n",
      "Q sunday, november 6, 2016     \n",
      "T 2016-11-06\n",
      "\u001b[92m☑\u001b[0m 2016-11-06\n",
      "---\n",
      "정확도 99.900%\n",
      "| 에폭 4 |  반복 1 / 351 | 시간 0[s] | 손실 0.01\n",
      "| 에폭 4 |  반복 21 / 351 | 시간 3[s] | 손실 0.01\n",
      "| 에폭 4 |  반복 41 / 351 | 시간 7[s] | 손실 0.01\n",
      "| 에폭 4 |  반복 61 / 351 | 시간 11[s] | 손실 0.01\n",
      "| 에폭 4 |  반복 81 / 351 | 시간 14[s] | 손실 0.01\n",
      "| 에폭 4 |  반복 101 / 351 | 시간 18[s] | 손실 0.01\n",
      "| 에폭 4 |  반복 121 / 351 | 시간 22[s] | 손실 0.00\n",
      "| 에폭 4 |  반복 141 / 351 | 시간 26[s] | 손실 0.01\n",
      "| 에폭 4 |  반복 161 / 351 | 시간 29[s] | 손실 0.00\n",
      "| 에폭 4 |  반복 181 / 351 | 시간 33[s] | 손실 0.00\n",
      "| 에폭 4 |  반복 201 / 351 | 시간 37[s] | 손실 0.00\n",
      "| 에폭 4 |  반복 221 / 351 | 시간 40[s] | 손실 0.00\n",
      "| 에폭 4 |  반복 241 / 351 | 시간 44[s] | 손실 0.00\n",
      "| 에폭 4 |  반복 261 / 351 | 시간 48[s] | 손실 0.00\n",
      "| 에폭 4 |  반복 281 / 351 | 시간 51[s] | 손실 0.01\n",
      "| 에폭 4 |  반복 301 / 351 | 시간 55[s] | 손실 0.00\n",
      "| 에폭 4 |  반복 321 / 351 | 시간 59[s] | 손실 0.00\n",
      "| 에폭 4 |  반복 341 / 351 | 시간 62[s] | 손실 0.00\n",
      "Q 10/15/94                     \n",
      "T 1994-10-15\n",
      "\u001b[92m☑\u001b[0m 1994-10-15\n",
      "---\n",
      "Q thursday, november 13, 2008  \n",
      "T 2008-11-13\n",
      "\u001b[92m☑\u001b[0m 2008-11-13\n",
      "---\n",
      "Q Mar 25, 2003                 \n",
      "T 2003-03-25\n",
      "\u001b[92m☑\u001b[0m 2003-03-25\n",
      "---\n",
      "Q Tuesday, November 22, 2016   \n",
      "T 2016-11-22\n",
      "\u001b[92m☑\u001b[0m 2016-11-22\n",
      "---\n",
      "Q Saturday, July 18, 1970      \n",
      "T 1970-07-18\n",
      "\u001b[92m☑\u001b[0m 1970-07-18\n",
      "---\n",
      "Q october 6, 1992              \n",
      "T 1992-10-06\n",
      "\u001b[92m☑\u001b[0m 1992-10-06\n",
      "---\n",
      "Q 8/23/08                      \n",
      "T 2008-08-23\n",
      "\u001b[92m☑\u001b[0m 2008-08-23\n",
      "---\n",
      "Q 8/30/07                      \n",
      "T 2007-08-30\n",
      "\u001b[92m☑\u001b[0m 2007-08-30\n",
      "---\n",
      "Q 10/28/13                     \n",
      "T 2013-10-28\n",
      "\u001b[92m☑\u001b[0m 2013-10-28\n",
      "---\n",
      "Q sunday, november 6, 2016     \n",
      "T 2016-11-06\n",
      "\u001b[92m☑\u001b[0m 2016-11-06\n",
      "---\n",
      "정확도 99.900%\n",
      "| 에폭 5 |  반복 1 / 351 | 시간 0[s] | 손실 0.00\n",
      "| 에폭 5 |  반복 21 / 351 | 시간 3[s] | 손실 0.00\n",
      "| 에폭 5 |  반복 41 / 351 | 시간 7[s] | 손실 0.00\n",
      "| 에폭 5 |  반복 61 / 351 | 시간 11[s] | 손실 0.00\n",
      "| 에폭 5 |  반복 81 / 351 | 시간 15[s] | 손실 0.00\n",
      "| 에폭 5 |  반복 101 / 351 | 시간 18[s] | 손실 0.00\n",
      "| 에폭 5 |  반복 121 / 351 | 시간 22[s] | 손실 0.00\n",
      "| 에폭 5 |  반복 141 / 351 | 시간 26[s] | 손실 0.00\n",
      "| 에폭 5 |  반복 161 / 351 | 시간 29[s] | 손실 0.00\n",
      "| 에폭 5 |  반복 181 / 351 | 시간 33[s] | 손실 0.00\n",
      "| 에폭 5 |  반복 201 / 351 | 시간 37[s] | 손실 0.00\n",
      "| 에폭 5 |  반복 221 / 351 | 시간 40[s] | 손실 0.00\n",
      "| 에폭 5 |  반복 241 / 351 | 시간 44[s] | 손실 0.00\n",
      "| 에폭 5 |  반복 261 / 351 | 시간 48[s] | 손실 0.00\n",
      "| 에폭 5 |  반복 281 / 351 | 시간 51[s] | 손실 0.00\n",
      "| 에폭 5 |  반복 301 / 351 | 시간 55[s] | 손실 0.00\n",
      "| 에폭 5 |  반복 321 / 351 | 시간 59[s] | 손실 0.00\n",
      "| 에폭 5 |  반복 341 / 351 | 시간 62[s] | 손실 0.00\n",
      "Q 10/15/94                     \n",
      "T 1994-10-15\n",
      "\u001b[92m☑\u001b[0m 1994-10-15\n",
      "---\n",
      "Q thursday, november 13, 2008  \n",
      "T 2008-11-13\n",
      "\u001b[92m☑\u001b[0m 2008-11-13\n",
      "---\n",
      "Q Mar 25, 2003                 \n",
      "T 2003-03-25\n",
      "\u001b[92m☑\u001b[0m 2003-03-25\n",
      "---\n",
      "Q Tuesday, November 22, 2016   \n",
      "T 2016-11-22\n",
      "\u001b[92m☑\u001b[0m 2016-11-22\n",
      "---\n",
      "Q Saturday, July 18, 1970      \n",
      "T 1970-07-18\n",
      "\u001b[92m☑\u001b[0m 1970-07-18\n",
      "---\n",
      "Q october 6, 1992              \n",
      "T 1992-10-06\n",
      "\u001b[92m☑\u001b[0m 1992-10-06\n",
      "---\n",
      "Q 8/23/08                      \n",
      "T 2008-08-23\n",
      "\u001b[92m☑\u001b[0m 2008-08-23\n",
      "---\n",
      "Q 8/30/07                      \n",
      "T 2007-08-30\n",
      "\u001b[92m☑\u001b[0m 2007-08-30\n",
      "---\n",
      "Q 10/28/13                     \n",
      "T 2013-10-28\n",
      "\u001b[92m☑\u001b[0m 2013-10-28\n",
      "---\n",
      "Q sunday, november 6, 2016     \n",
      "T 2016-11-06\n",
      "\u001b[92m☑\u001b[0m 2016-11-06\n",
      "---\n",
      "정확도 99.920%\n",
      "| 에폭 6 |  반복 1 / 351 | 시간 0[s] | 손실 0.00\n",
      "| 에폭 6 |  반복 21 / 351 | 시간 3[s] | 손실 0.00\n",
      "| 에폭 6 |  반복 41 / 351 | 시간 7[s] | 손실 0.00\n",
      "| 에폭 6 |  반복 61 / 351 | 시간 11[s] | 손실 0.00\n",
      "| 에폭 6 |  반복 81 / 351 | 시간 14[s] | 손실 0.00\n",
      "| 에폭 6 |  반복 101 / 351 | 시간 18[s] | 손실 0.00\n",
      "| 에폭 6 |  반복 121 / 351 | 시간 22[s] | 손실 0.00\n",
      "| 에폭 6 |  반복 141 / 351 | 시간 25[s] | 손실 0.00\n",
      "| 에폭 6 |  반복 161 / 351 | 시간 29[s] | 손실 0.00\n",
      "| 에폭 6 |  반복 181 / 351 | 시간 33[s] | 손실 0.00\n",
      "| 에폭 6 |  반복 201 / 351 | 시간 36[s] | 손실 0.00\n",
      "| 에폭 6 |  반복 221 / 351 | 시간 40[s] | 손실 0.00\n",
      "| 에폭 6 |  반복 241 / 351 | 시간 44[s] | 손실 0.00\n",
      "| 에폭 6 |  반복 261 / 351 | 시간 47[s] | 손실 0.00\n",
      "| 에폭 6 |  반복 281 / 351 | 시간 51[s] | 손실 0.00\n",
      "| 에폭 6 |  반복 301 / 351 | 시간 55[s] | 손실 0.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| 에폭 6 |  반복 321 / 351 | 시간 58[s] | 손실 0.00\n",
      "| 에폭 6 |  반복 341 / 351 | 시간 62[s] | 손실 0.00\n",
      "Q 10/15/94                     \n",
      "T 1994-10-15\n",
      "\u001b[92m☑\u001b[0m 1994-10-15\n",
      "---\n",
      "Q thursday, november 13, 2008  \n",
      "T 2008-11-13\n",
      "\u001b[92m☑\u001b[0m 2008-11-13\n",
      "---\n",
      "Q Mar 25, 2003                 \n",
      "T 2003-03-25\n",
      "\u001b[92m☑\u001b[0m 2003-03-25\n",
      "---\n",
      "Q Tuesday, November 22, 2016   \n",
      "T 2016-11-22\n",
      "\u001b[92m☑\u001b[0m 2016-11-22\n",
      "---\n",
      "Q Saturday, July 18, 1970      \n",
      "T 1970-07-18\n",
      "\u001b[92m☑\u001b[0m 1970-07-18\n",
      "---\n",
      "Q october 6, 1992              \n",
      "T 1992-10-06\n",
      "\u001b[92m☑\u001b[0m 1992-10-06\n",
      "---\n",
      "Q 8/23/08                      \n",
      "T 2008-08-23\n",
      "\u001b[92m☑\u001b[0m 2008-08-23\n",
      "---\n",
      "Q 8/30/07                      \n",
      "T 2007-08-30\n",
      "\u001b[92m☑\u001b[0m 2007-08-30\n",
      "---\n",
      "Q 10/28/13                     \n",
      "T 2013-10-28\n",
      "\u001b[92m☑\u001b[0m 2013-10-28\n",
      "---\n",
      "Q sunday, november 6, 2016     \n",
      "T 2016-11-06\n",
      "\u001b[92m☑\u001b[0m 2016-11-06\n",
      "---\n",
      "정확도 99.920%\n",
      "| 에폭 7 |  반복 1 / 351 | 시간 0[s] | 손실 0.00\n",
      "| 에폭 7 |  반복 21 / 351 | 시간 3[s] | 손실 0.00\n",
      "| 에폭 7 |  반복 41 / 351 | 시간 7[s] | 손실 0.00\n",
      "| 에폭 7 |  반복 61 / 351 | 시간 11[s] | 손실 0.00\n",
      "| 에폭 7 |  반복 81 / 351 | 시간 14[s] | 손실 0.00\n",
      "| 에폭 7 |  반복 101 / 351 | 시간 18[s] | 손실 0.00\n",
      "| 에폭 7 |  반복 121 / 351 | 시간 22[s] | 손실 0.00\n",
      "| 에폭 7 |  반복 141 / 351 | 시간 25[s] | 손실 0.00\n",
      "| 에폭 7 |  반복 161 / 351 | 시간 29[s] | 손실 0.00\n",
      "| 에폭 7 |  반복 181 / 351 | 시간 33[s] | 손실 0.00\n",
      "| 에폭 7 |  반복 201 / 351 | 시간 36[s] | 손실 0.00\n",
      "| 에폭 7 |  반복 221 / 351 | 시간 40[s] | 손실 0.00\n",
      "| 에폭 7 |  반복 241 / 351 | 시간 44[s] | 손실 0.00\n",
      "| 에폭 7 |  반복 261 / 351 | 시간 47[s] | 손실 0.00\n",
      "| 에폭 7 |  반복 281 / 351 | 시간 51[s] | 손실 0.00\n",
      "| 에폭 7 |  반복 301 / 351 | 시간 55[s] | 손실 0.00\n",
      "| 에폭 7 |  반복 321 / 351 | 시간 58[s] | 손실 0.00\n",
      "| 에폭 7 |  반복 341 / 351 | 시간 62[s] | 손실 0.00\n",
      "Q 10/15/94                     \n",
      "T 1994-10-15\n",
      "\u001b[92m☑\u001b[0m 1994-10-15\n",
      "---\n",
      "Q thursday, november 13, 2008  \n",
      "T 2008-11-13\n",
      "\u001b[92m☑\u001b[0m 2008-11-13\n",
      "---\n",
      "Q Mar 25, 2003                 \n",
      "T 2003-03-25\n",
      "\u001b[92m☑\u001b[0m 2003-03-25\n",
      "---\n",
      "Q Tuesday, November 22, 2016   \n",
      "T 2016-11-22\n",
      "\u001b[92m☑\u001b[0m 2016-11-22\n",
      "---\n",
      "Q Saturday, July 18, 1970      \n",
      "T 1970-07-18\n",
      "\u001b[92m☑\u001b[0m 1970-07-18\n",
      "---\n",
      "Q october 6, 1992              \n",
      "T 1992-10-06\n",
      "\u001b[92m☑\u001b[0m 1992-10-06\n",
      "---\n",
      "Q 8/23/08                      \n",
      "T 2008-08-23\n",
      "\u001b[92m☑\u001b[0m 2008-08-23\n",
      "---\n",
      "Q 8/30/07                      \n",
      "T 2007-08-30\n",
      "\u001b[92m☑\u001b[0m 2007-08-30\n",
      "---\n",
      "Q 10/28/13                     \n",
      "T 2013-10-28\n",
      "\u001b[92m☑\u001b[0m 2013-10-28\n",
      "---\n",
      "Q sunday, november 6, 2016     \n",
      "T 2016-11-06\n",
      "\u001b[92m☑\u001b[0m 2016-11-06\n",
      "---\n",
      "정확도 99.920%\n",
      "| 에폭 8 |  반복 1 / 351 | 시간 0[s] | 손실 0.00\n",
      "| 에폭 8 |  반복 21 / 351 | 시간 3[s] | 손실 0.00\n",
      "| 에폭 8 |  반복 41 / 351 | 시간 7[s] | 손실 0.00\n",
      "| 에폭 8 |  반복 61 / 351 | 시간 11[s] | 손실 0.00\n",
      "| 에폭 8 |  반복 81 / 351 | 시간 14[s] | 손실 0.00\n",
      "| 에폭 8 |  반복 101 / 351 | 시간 18[s] | 손실 0.00\n",
      "| 에폭 8 |  반복 121 / 351 | 시간 22[s] | 손실 0.00\n",
      "| 에폭 8 |  반복 141 / 351 | 시간 25[s] | 손실 0.00\n",
      "| 에폭 8 |  반복 161 / 351 | 시간 29[s] | 손실 0.00\n",
      "| 에폭 8 |  반복 181 / 351 | 시간 33[s] | 손실 0.00\n",
      "| 에폭 8 |  반복 201 / 351 | 시간 36[s] | 손실 0.00\n",
      "| 에폭 8 |  반복 221 / 351 | 시간 40[s] | 손실 0.00\n",
      "| 에폭 8 |  반복 241 / 351 | 시간 44[s] | 손실 0.00\n",
      "| 에폭 8 |  반복 261 / 351 | 시간 47[s] | 손실 0.00\n",
      "| 에폭 8 |  반복 281 / 351 | 시간 51[s] | 손실 0.00\n",
      "| 에폭 8 |  반복 301 / 351 | 시간 55[s] | 손실 0.00\n",
      "| 에폭 8 |  반복 321 / 351 | 시간 58[s] | 손실 0.00\n",
      "| 에폭 8 |  반복 341 / 351 | 시간 62[s] | 손실 0.00\n",
      "Q 10/15/94                     \n",
      "T 1994-10-15\n",
      "\u001b[92m☑\u001b[0m 1994-10-15\n",
      "---\n",
      "Q thursday, november 13, 2008  \n",
      "T 2008-11-13\n",
      "\u001b[92m☑\u001b[0m 2008-11-13\n",
      "---\n",
      "Q Mar 25, 2003                 \n",
      "T 2003-03-25\n",
      "\u001b[92m☑\u001b[0m 2003-03-25\n",
      "---\n",
      "Q Tuesday, November 22, 2016   \n",
      "T 2016-11-22\n",
      "\u001b[92m☑\u001b[0m 2016-11-22\n",
      "---\n",
      "Q Saturday, July 18, 1970      \n",
      "T 1970-07-18\n",
      "\u001b[92m☑\u001b[0m 1970-07-18\n",
      "---\n",
      "Q october 6, 1992              \n",
      "T 1992-10-06\n",
      "\u001b[92m☑\u001b[0m 1992-10-06\n",
      "---\n",
      "Q 8/23/08                      \n",
      "T 2008-08-23\n",
      "\u001b[92m☑\u001b[0m 2008-08-23\n",
      "---\n",
      "Q 8/30/07                      \n",
      "T 2007-08-30\n",
      "\u001b[92m☑\u001b[0m 2007-08-30\n",
      "---\n",
      "Q 10/28/13                     \n",
      "T 2013-10-28\n",
      "\u001b[92m☑\u001b[0m 2013-10-28\n",
      "---\n",
      "Q sunday, november 6, 2016     \n",
      "T 2016-11-06\n",
      "\u001b[92m☑\u001b[0m 2016-11-06\n",
      "---\n",
      "정확도 99.960%\n",
      "| 에폭 9 |  반복 1 / 351 | 시간 0[s] | 손실 0.00\n",
      "| 에폭 9 |  반복 21 / 351 | 시간 3[s] | 손실 0.00\n",
      "| 에폭 9 |  반복 41 / 351 | 시간 7[s] | 손실 0.00\n",
      "| 에폭 9 |  반복 61 / 351 | 시간 11[s] | 손실 0.00\n",
      "| 에폭 9 |  반복 81 / 351 | 시간 14[s] | 손실 0.00\n",
      "| 에폭 9 |  반복 101 / 351 | 시간 18[s] | 손실 0.00\n",
      "| 에폭 9 |  반복 121 / 351 | 시간 22[s] | 손실 0.00\n",
      "| 에폭 9 |  반복 141 / 351 | 시간 25[s] | 손실 0.00\n",
      "| 에폭 9 |  반복 161 / 351 | 시간 29[s] | 손실 0.00\n",
      "| 에폭 9 |  반복 181 / 351 | 시간 33[s] | 손실 0.00\n",
      "| 에폭 9 |  반복 201 / 351 | 시간 36[s] | 손실 0.00\n",
      "| 에폭 9 |  반복 221 / 351 | 시간 40[s] | 손실 0.00\n",
      "| 에폭 9 |  반복 241 / 351 | 시간 44[s] | 손실 0.00\n",
      "| 에폭 9 |  반복 261 / 351 | 시간 47[s] | 손실 0.00\n",
      "| 에폭 9 |  반복 281 / 351 | 시간 51[s] | 손실 0.00\n",
      "| 에폭 9 |  반복 301 / 351 | 시간 55[s] | 손실 0.00\n",
      "| 에폭 9 |  반복 321 / 351 | 시간 58[s] | 손실 0.00\n",
      "| 에폭 9 |  반복 341 / 351 | 시간 62[s] | 손실 0.00\n",
      "Q 10/15/94                     \n",
      "T 1994-10-15\n",
      "\u001b[92m☑\u001b[0m 1994-10-15\n",
      "---\n",
      "Q thursday, november 13, 2008  \n",
      "T 2008-11-13\n",
      "\u001b[92m☑\u001b[0m 2008-11-13\n",
      "---\n",
      "Q Mar 25, 2003                 \n",
      "T 2003-03-25\n",
      "\u001b[92m☑\u001b[0m 2003-03-25\n",
      "---\n",
      "Q Tuesday, November 22, 2016   \n",
      "T 2016-11-22\n",
      "\u001b[92m☑\u001b[0m 2016-11-22\n",
      "---\n",
      "Q Saturday, July 18, 1970      \n",
      "T 1970-07-18\n",
      "\u001b[92m☑\u001b[0m 1970-07-18\n",
      "---\n",
      "Q october 6, 1992              \n",
      "T 1992-10-06\n",
      "\u001b[92m☑\u001b[0m 1992-10-06\n",
      "---\n",
      "Q 8/23/08                      \n",
      "T 2008-08-23\n",
      "\u001b[92m☑\u001b[0m 2008-08-23\n",
      "---\n",
      "Q 8/30/07                      \n",
      "T 2007-08-30\n",
      "\u001b[92m☑\u001b[0m 2007-08-30\n",
      "---\n",
      "Q 10/28/13                     \n",
      "T 2013-10-28\n",
      "\u001b[92m☑\u001b[0m 2013-10-28\n",
      "---\n",
      "Q sunday, november 6, 2016     \n",
      "T 2016-11-06\n",
      "\u001b[92m☑\u001b[0m 2016-11-06\n",
      "---\n",
      "정확도 99.960%\n",
      "| 에폭 10 |  반복 1 / 351 | 시간 0[s] | 손실 0.00\n",
      "| 에폭 10 |  반복 21 / 351 | 시간 3[s] | 손실 0.00\n",
      "| 에폭 10 |  반복 41 / 351 | 시간 7[s] | 손실 0.00\n",
      "| 에폭 10 |  반복 61 / 351 | 시간 11[s] | 손실 0.00\n",
      "| 에폭 10 |  반복 81 / 351 | 시간 14[s] | 손실 0.00\n",
      "| 에폭 10 |  반복 101 / 351 | 시간 18[s] | 손실 0.00\n",
      "| 에폭 10 |  반복 121 / 351 | 시간 22[s] | 손실 0.00\n",
      "| 에폭 10 |  반복 141 / 351 | 시간 25[s] | 손실 0.00\n",
      "| 에폭 10 |  반복 161 / 351 | 시간 29[s] | 손실 0.00\n",
      "| 에폭 10 |  반복 181 / 351 | 시간 33[s] | 손실 0.00\n",
      "| 에폭 10 |  반복 201 / 351 | 시간 36[s] | 손실 0.00\n",
      "| 에폭 10 |  반복 221 / 351 | 시간 40[s] | 손실 0.00\n",
      "| 에폭 10 |  반복 241 / 351 | 시간 44[s] | 손실 0.00\n",
      "| 에폭 10 |  반복 261 / 351 | 시간 47[s] | 손실 0.00\n",
      "| 에폭 10 |  반복 281 / 351 | 시간 51[s] | 손실 0.00\n",
      "| 에폭 10 |  반복 301 / 351 | 시간 55[s] | 손실 0.00\n",
      "| 에폭 10 |  반복 321 / 351 | 시간 58[s] | 손실 0.00\n",
      "| 에폭 10 |  반복 341 / 351 | 시간 62[s] | 손실 0.00\n",
      "Q 10/15/94                     \n",
      "T 1994-10-15\n",
      "\u001b[92m☑\u001b[0m 1994-10-15\n",
      "---\n",
      "Q thursday, november 13, 2008  \n",
      "T 2008-11-13\n",
      "\u001b[92m☑\u001b[0m 2008-11-13\n",
      "---\n",
      "Q Mar 25, 2003                 \n",
      "T 2003-03-25\n",
      "\u001b[92m☑\u001b[0m 2003-03-25\n",
      "---\n",
      "Q Tuesday, November 22, 2016   \n",
      "T 2016-11-22\n",
      "\u001b[92m☑\u001b[0m 2016-11-22\n",
      "---\n",
      "Q Saturday, July 18, 1970      \n",
      "T 1970-07-18\n",
      "\u001b[92m☑\u001b[0m 1970-07-18\n",
      "---\n",
      "Q october 6, 1992              \n",
      "T 1992-10-06\n",
      "\u001b[92m☑\u001b[0m 1992-10-06\n",
      "---\n",
      "Q 8/23/08                      \n",
      "T 2008-08-23\n",
      "\u001b[92m☑\u001b[0m 2008-08-23\n",
      "---\n",
      "Q 8/30/07                      \n",
      "T 2007-08-30\n",
      "\u001b[92m☑\u001b[0m 2007-08-30\n",
      "---\n",
      "Q 10/28/13                     \n",
      "T 2013-10-28\n",
      "\u001b[92m☑\u001b[0m 2013-10-28\n",
      "---\n",
      "Q sunday, november 6, 2016     \n",
      "T 2016-11-06\n",
      "\u001b[92m☑\u001b[0m 2016-11-06\n",
      "---\n",
      "정확도 99.980%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aiffel0042/anaconda3/envs/aiffel/lib/python3.7/site-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 50640 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "/home/aiffel0042/anaconda3/envs/aiffel/lib/python3.7/site-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 54253 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "/home/aiffel0042/anaconda3/envs/aiffel/lib/python3.7/site-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 51221 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "/home/aiffel0042/anaconda3/envs/aiffel/lib/python3.7/site-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 54869 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "/home/aiffel0042/anaconda3/envs/aiffel/lib/python3.7/site-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 46020 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "/home/aiffel0042/anaconda3/envs/aiffel/lib/python3.7/site-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 50640 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "/home/aiffel0042/anaconda3/envs/aiffel/lib/python3.7/site-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 54253 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "/home/aiffel0042/anaconda3/envs/aiffel/lib/python3.7/site-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 51221 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "/home/aiffel0042/anaconda3/envs/aiffel/lib/python3.7/site-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 54869 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "/home/aiffel0042/anaconda3/envs/aiffel/lib/python3.7/site-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 46020 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# coding: utf-8\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "sys.path.append('../ch07')\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from dataset import sequence\n",
    "from common.optimizer import Adam\n",
    "from common.trainer import Trainer\n",
    "from common.util import eval_seq2seq\n",
    "# from attention_seq2seq import AttentionSeq2seq\n",
    "# from ch07.seq2seq import Seq2seq\n",
    "# from ch07.peeky_seq2seq import PeekySeq2seq\n",
    "\n",
    "\n",
    "# 데이터 읽기\n",
    "(x_train, t_train), (x_test, t_test) = sequence.load_data('date.txt')\n",
    "char_to_id, id_to_char = sequence.get_vocab()\n",
    "\n",
    "# 입력 문장 반전\n",
    "x_train, x_test = x_train[:, ::-1], x_test[:, ::-1]\n",
    "\n",
    "# 하이퍼파라미터 설정\n",
    "vocab_size = len(char_to_id)\n",
    "wordvec_size = 16\n",
    "hidden_size = 256\n",
    "batch_size = 128\n",
    "max_epoch = 10\n",
    "max_grad = 5.0\n",
    "\n",
    "model = AttentionSeq2seq(vocab_size, wordvec_size, hidden_size)\n",
    "# model = Seq2seq(vocab_size, wordvec_size, hidden_size)\n",
    "# model = PeekySeq2seq(vocab_size, wordvec_size, hidden_size)\n",
    "\n",
    "optimizer = Adam()\n",
    "trainer = Trainer(model, optimizer)\n",
    "\n",
    "acc_list = []\n",
    "for epoch in range(max_epoch):\n",
    "    trainer.fit(x_train, t_train, max_epoch=1,\n",
    "                batch_size=batch_size, max_grad=max_grad)\n",
    "\n",
    "    correct_num = 0\n",
    "    for i in range(len(x_test)):\n",
    "        question, correct = x_test[[i]], t_test[[i]]\n",
    "        verbose = i < 10\n",
    "        correct_num += eval_seq2seq(model, question, correct,\n",
    "                                    id_to_char, verbose, is_reverse=True)\n",
    "\n",
    "    acc = float(correct_num) / len(x_test)\n",
    "    acc_list.append(acc)\n",
    "    print('정확도 %.3f%%' % (acc * 100))\n",
    "\n",
    "\n",
    "model.save_params()\n",
    "\n",
    "# 그래프 그리기\n",
    "x = np.arange(len(acc_list))\n",
    "plt.plot(x, acc_list, marker='o')\n",
    "plt.xlabel('에폭')\n",
    "plt.ylabel('정확도')\n",
    "plt.ylim(-0.05, 1.05)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# visualize_attention.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# coding: utf-8\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "import numpy as np\n",
    "from dataset import sequence\n",
    "import matplotlib.pyplot as plt\n",
    "# from attention_seq2seq import AttentionSeq2seq\n",
    "\n",
    "\n",
    "(x_train, t_train), (x_test, t_test) = \\\n",
    "    sequence.load_data('date.txt')\n",
    "char_to_id, id_to_char = sequence.get_vocab()\n",
    "\n",
    "# 입력 문장 반전\n",
    "x_train, x_test = x_train[:, ::-1], x_test[:, ::-1]\n",
    "\n",
    "vocab_size = len(char_to_id)\n",
    "wordvec_size = 16\n",
    "hidden_size = 256\n",
    "\n",
    "model = AttentionSeq2seq(vocab_size, wordvec_size, hidden_size)\n",
    "model.load_params()\n",
    "\n",
    "_idx = 0\n",
    "def visualize(attention_map, row_labels, column_labels):\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.pcolor(attention_map, cmap=plt.cm.Greys_r, vmin=0.0, vmax=1.0)\n",
    "\n",
    "    ax.patch.set_facecolor('black')\n",
    "    ax.set_yticks(np.arange(attention_map.shape[0])+0.5, minor=False)\n",
    "    ax.set_xticks(np.arange(attention_map.shape[1])+0.5, minor=False)\n",
    "    ax.invert_yaxis()\n",
    "    ax.set_xticklabels(row_labels, minor=False)\n",
    "    ax.set_yticklabels(column_labels, minor=False)\n",
    "\n",
    "    global _idx\n",
    "    _idx += 1\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "np.random.seed(1984)\n",
    "for _ in range(5):\n",
    "    idx = [np.random.randint(0, len(x_test))]\n",
    "    x = x_test[idx]\n",
    "    t = t_test[idx]\n",
    "\n",
    "    model.forward(x, t)\n",
    "    d = model.decoder.attention.attention_weights\n",
    "    d = np.array(d)\n",
    "    attention_map = d.reshape(d.shape[0], d.shape[2])\n",
    "\n",
    "    # 출력하기 위해 반전\n",
    "    attention_map = attention_map[:,::-1]\n",
    "    x = x[:,::-1]\n",
    "\n",
    "    row_labels = [id_to_char[i] for i in x[0]]\n",
    "    column_labels = [id_to_char[i] for i in t[0]]\n",
    "    column_labels = column_labels[1:]\n",
    "\n",
    "    visualize(attention_map, row_labels, column_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aiffel",
   "language": "python",
   "name": "aiffel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
